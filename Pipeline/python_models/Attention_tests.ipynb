{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from braindecode.models import EEGConformer\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import importlib\n",
    "import Spatial_attention_model\n",
    "importlib.reload(Spatial_attention_model)\n",
    "from Spatial_attention_model import ShallowAttentionNet\n",
    "from shallow_laurits import ShallowFBCSPNet\n",
    "from torchinfo import summary\n",
    "from weight_init import init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowAttentionNet(\n",
       "  (temporal): Conv2d(1, 10, kernel_size=(1, 25), stride=(1, 1))\n",
       "  (spatial_att): SpatialAttention(\n",
       "    (conv): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (batch_norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): AvgPool2d(kernel_size=(1, 20), stride=(1, 20), padding=0)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=960, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_chans = 32\n",
    "n_classes = 3\n",
    "input_window_samples = 400\n",
    "model = ShallowAttentionNet(in_chans,n_classes,input_window_samples)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowAttentionNet(\n",
      "  (temporal): Conv2d(1, 10, kernel_size=(1, 25), stride=(1, 1))\n",
      "  (spatial_att): SpatialAttention(\n",
      "    (conv): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (batch_norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): AvgPool2d(kernel_size=(1, 20), stride=(1, 20), padding=0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=960, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "ShallowAttentionNet                      [2, 32, 400]              [2, 3]                    --                        --\n",
       "├─Conv2d: 1-1                            [2, 1, 32, 400]           [2, 10, 32, 376]          260                       [1, 25]\n",
       "├─SpatialAttention: 1-2                  [2, 10, 32, 376]          [2, 10, 32, 75]           --                        --\n",
       "│    └─Conv2d: 2-1                       [2, 10, 32, 376]          [2, 10, 32, 376]          100                       [1, 1]\n",
       "│    └─MaxPool2d: 2-2                    [2, 10, 32, 376]          [2, 10, 32, 75]           --                        [1, 5]\n",
       "├─BatchNorm2d: 1-3                       [2, 10, 32, 75]           [2, 10, 32, 75]           20                        --\n",
       "├─AvgPool2d: 1-4                         [2, 10, 32, 75]           [2, 10, 32, 3]            --                        [1, 20]\n",
       "├─Dropout: 1-5                           [2, 10, 32, 3]            [2, 10, 32, 3]            --                        --\n",
       "├─Linear: 1-6                            [2, 960]                  [2, 3]                    2,883                     --\n",
       "============================================================================================================================================\n",
       "Total params: 3,263\n",
       "Trainable params: 3,263\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 8.67\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 4.23\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 4.35\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(2, 32, 400),col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

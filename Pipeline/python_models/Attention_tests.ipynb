{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from braindecode.models import EEGConformer\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import importlib\n",
    "import Attention_temporal_model\n",
    "importlib.reload(Attention_temporal_model)\n",
    "from Attention_temporal_model import ShallowAttentionNet\n",
    "from shallow_laurits import ShallowFBCSPNet\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 22\n",
    "n_classes = 4\n",
    "input_window_samples = 1125\n",
    "model = ShallowAttentionNet(in_chans,n_classes,input_window_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowAttentionNet(\n",
      "  (mini_pool): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)\n",
      "  (temporal_attention): TemporalAttention(\n",
      "    (query): Conv1d(562, 562, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (key): Conv1d(562, 562, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (value): Conv1d(562, 562, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (out_conv): Conv1d(562, 562, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (spatial): Conv2d(1, 22, kernel_size=(22, 1), stride=(1, 1))\n",
      "  (batch_norm): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): AvgPool2d(kernel_size=(1, 50), stride=(1, 50), padding=0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): LazyLinear(in_features=0, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([2, 562, 22])\n",
      "torch.Size([2, 562, 22])\n",
      "torch.Size([2, 562, 22])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "ShallowAttentionNet                      [2, 22, 1125]             [2, 4]                    --                        --\n",
       "├─AvgPool2d: 1-1                         [2, 1, 22, 1125]          [2, 1, 22, 562]           --                        [1, 2]\n",
       "├─TemporalAttention: 1-2                 [2, 1, 22, 562]           [2, 1, 22, 562]           1                         --\n",
       "│    └─Conv1d: 2-1                       [2, 562, 22]              [2, 562, 22]              315,844                   [1]\n",
       "│    └─Conv1d: 2-2                       [2, 562, 22]              [2, 562, 22]              315,844                   [1]\n",
       "│    └─Conv1d: 2-3                       [2, 562, 22]              [2, 562, 22]              315,844                   [1]\n",
       "│    └─Conv1d: 2-4                       [2, 562, 22]              [2, 562, 22]              315,844                   [1]\n",
       "├─Conv2d: 1-3                            [2, 1, 22, 562]           [2, 22, 1, 562]           506                       [22, 1]\n",
       "├─BatchNorm2d: 1-4                       [2, 22, 1, 562]           [2, 22, 1, 562]           44                        --\n",
       "├─AvgPool2d: 1-5                         [2, 22, 1, 562]           [2, 22, 1, 11]            --                        [1, 50]\n",
       "├─Dropout: 1-6                           [2, 242]                  [2, 242]                  --                        --\n",
       "├─Linear: 1-7                            [2, 242]                  [2, 4]                    972                       --\n",
       "============================================================================================================================================\n",
       "Total params: 1,264,899\n",
       "Trainable params: 1,264,899\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 56.16\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 1.19\n",
       "Params size (MB): 5.06\n",
       "Estimated Total Size (MB): 6.44\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(2, 22, 1125),col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

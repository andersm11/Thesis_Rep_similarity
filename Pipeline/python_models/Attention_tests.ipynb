{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from braindecode.models import EEGConformer\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import importlib\n",
    "import Attention_FIRST_model\n",
    "importlib.reload(Attention_FIRST_model)\n",
    "from Attention_FIRST_model import ShallowAttentionNet\n",
    "from shallow_laurits import ShallowFBCSPNet\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 22\n",
    "n_classes = 4\n",
    "input_window_samples = 1125\n",
    "model = ShallowAttentionNet(in_chans,n_classes,input_window_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowAttentionNet(\n",
      "  (spatial_att): SpatialAttention(\n",
      "    (query): Linear(in_features=22, out_features=22, bias=False)\n",
      "    (key): Linear(in_features=22, out_features=22, bias=False)\n",
      "    (value): Linear(in_features=22, out_features=22, bias=False)\n",
      "    (out_linear): Linear(in_features=22, out_features=22, bias=False)\n",
      "  )\n",
      "  (temporal): Conv2d(1, 10, kernel_size=(1, 25), stride=(1, 1))\n",
      "  (batch_norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): AvgPool2d(kernel_size=(1, 100), stride=(1, 100), padding=0)\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      "  (fc): LazyLinear(in_features=0, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after unsqueeze: torch.Size([2, 1, 22, 1125])\n",
      "torch.Size([2, 22, 1125])\n",
      "torch.Size([2, 1125, 22])\n",
      "torch.Size([2, 1125, 22])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "ShallowAttentionNet                      [2, 22, 1125]             [2, 4]                    --                        --\n",
       "├─SpatialAttention: 1-1                  [2, 1, 22, 1125]          [2, 1, 22, 1125]          1                         --\n",
       "│    └─Linear: 2-1                       [2, 1125, 22]             [2, 1125, 22]             484                       --\n",
       "│    └─Linear: 2-2                       [2, 1125, 22]             [2, 1125, 22]             484                       --\n",
       "│    └─Linear: 2-3                       [2, 1125, 22]             [2, 1125, 22]             484                       --\n",
       "│    └─Linear: 2-4                       [2, 1125, 22]             [2, 1125, 22]             484                       --\n",
       "├─Conv2d: 1-2                            [2, 1, 22, 1125]          [2, 10, 22, 1101]         260                       [1, 25]\n",
       "├─BatchNorm2d: 1-3                       [2, 10, 22, 1101]         [2, 10, 22, 1101]         20                        --\n",
       "├─AvgPool2d: 1-4                         [2, 10, 22, 1101]         [2, 10, 22, 11]           --                        [1, 100]\n",
       "├─Dropout: 1-5                           [2, 2420]                 [2, 2420]                 --                        --\n",
       "├─Linear: 1-6                            [2, 2420]                 [2, 4]                    9,684                     --\n",
       "============================================================================================================================================\n",
       "Total params: 11,901\n",
       "Trainable params: 11,901\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 12.62\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 9.34\n",
       "Params size (MB): 0.05\n",
       "Estimated Total Size (MB): 9.58\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(2, 22, 1125),col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

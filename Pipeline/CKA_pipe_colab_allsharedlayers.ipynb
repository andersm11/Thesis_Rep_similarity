{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4dbbfa4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dbbfa4a",
        "outputId": "9812b6e0-0cab-4c7d-e454-728184624312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab. Checking required libraries...\n",
            "All required libraries are already installed.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "import subprocess\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def install_if_colab():\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Running in Google Colab. Checking required libraries...\")\n",
        "\n",
        "        packages = [\"moabb\", \"braindecode\", \"torch_geometric\"]  # Add required libraries\n",
        "        missing_packages = [pkg for pkg in packages if importlib.util.find_spec(pkg) is None]\n",
        "\n",
        "        if missing_packages:\n",
        "            print(f\"Installing missing libraries: {', '.join(missing_packages)}\")\n",
        "            !pip install {\" \".join(missing_packages)}\n",
        "        else:\n",
        "            print(\"All required libraries are already installed.\")\n",
        "    else:\n",
        "        print(\"Not running in Google Colab. No installation needed.\")\n",
        "\n",
        "install_if_colab()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "604ea1ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "604ea1ed",
        "outputId": "cc6fc66c-bd27-4aaf-fec7-f7b5ab763ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a6f02081",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6f02081",
        "outputId": "a4278658-f9b6-4c9a-9d36-608cce8b9819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  models.zip\n",
            "replace models/ShallowAttentionNet/ShallowAttentionNet_51_44552222.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "   creating: models/ShallowLSTM/\n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_1.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_10.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_2.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_3.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_4.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_5.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_6.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_7.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_8.pth  \n",
            "  inflating: models/ShallowLSTM/ShallowLSTM_52_9.pth  \n",
            "   creating: models/ShallowRNNNet/\n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_58_12223111.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_58_12223111_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_58_809890.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_58_809890_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_59_44552222.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_59_44552222_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_100300.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_100300_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_47456655.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_47456655_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_91111222.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_91111222_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_99999.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_60_99999_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_182726.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_182726_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_4788347.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_4788347_state.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_77766666.pth  \n",
            "  inflating: models/ShallowRNNNet/ShallowRNNNet_61_77766666_state.pth  \n"
          ]
        }
      ],
      "source": [
        "!unzip models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05e81e17",
      "metadata": {
        "id": "05e81e17"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "model_direc = \"models\"\n",
        "activation_direc = \"activations\"\n",
        "kernel_direc = \"kernels\"\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a59a5c08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a59a5c08",
        "outputId": "5e323b2e-d496-4fa2-e490-7523dbd76cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([22353, 32, 400])\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "X = torch.load(path+'EEG_data/emotion_test_set.pt')\n",
        "X = [sublist[0] for sublist in X]  # Extract the first tensor in each tuple\n",
        "X = torch.stack(X).to(device) # Stack the tensors into a single tensor\n",
        "\n",
        "print(X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r models/ShallowRNNNet/"
      ],
      "metadata": {
        "id": "JVQptbB_6O1l"
      },
      "id": "JVQptbB_6O1l",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a87851",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08a87851",
        "outputId": "8239c2b4-82b2-41c5-e9a1-7d042f0c7caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file: ShallowSGCNNet_59_809890.pth\n",
            "Input data is on device: cuda:0\n",
            "model is on device: cuda:0\n",
            "saving: temporal_batch_1.pt\n",
            "saving: sgconv_batch_1.pt\n",
            "saving: pool_batch_1.pt\n",
            "saving: fc_batch_1.pt\n",
            "saving: temporal_batch_2.pt\n",
            "saving: sgconv_batch_2.pt\n",
            "saving: pool_batch_2.pt\n",
            "saving: fc_batch_2.pt\n",
            "saving: temporal_batch_3.pt\n",
            "saving: sgconv_batch_3.pt\n",
            "saving: pool_batch_3.pt\n",
            "saving: fc_batch_3.pt\n",
            "saving: temporal_batch_4.pt\n",
            "saving: sgconv_batch_4.pt\n",
            "saving: pool_batch_4.pt\n",
            "saving: fc_batch_4.pt\n",
            "saving: temporal_batch_5.pt\n",
            "saving: sgconv_batch_5.pt\n",
            "saving: pool_batch_5.pt\n",
            "saving: fc_batch_5.pt\n",
            "saving: temporal_batch_6.pt\n",
            "saving: sgconv_batch_6.pt\n",
            "saving: pool_batch_6.pt\n",
            "saving: fc_batch_6.pt\n",
            "saving: temporal_batch_7.pt\n",
            "saving: sgconv_batch_7.pt\n",
            "saving: pool_batch_7.pt\n",
            "saving: fc_batch_7.pt\n",
            "saving: temporal_batch_8.pt\n",
            "saving: sgconv_batch_8.pt\n",
            "saving: pool_batch_8.pt\n",
            "saving: fc_batch_8.pt\n",
            "saving: temporal_batch_9.pt\n",
            "saving: sgconv_batch_9.pt\n",
            "saving: pool_batch_9.pt\n",
            "saving: fc_batch_9.pt\n",
            "saving: temporal_batch_10.pt\n",
            "saving: sgconv_batch_10.pt\n",
            "saving: pool_batch_10.pt\n",
            "saving: fc_batch_10.pt\n",
            "saving: temporal_batch_11.pt\n",
            "saving: sgconv_batch_11.pt\n",
            "saving: pool_batch_11.pt\n",
            "saving: fc_batch_11.pt\n",
            "saving: temporal_batch_12.pt\n",
            "saving: sgconv_batch_12.pt\n",
            "saving: pool_batch_12.pt\n",
            "saving: fc_batch_12.pt\n",
            "saving: temporal_batch_13.pt\n",
            "saving: sgconv_batch_13.pt\n",
            "saving: pool_batch_13.pt\n",
            "saving: fc_batch_13.pt\n",
            "saving: temporal_batch_14.pt\n",
            "saving: sgconv_batch_14.pt\n",
            "saving: pool_batch_14.pt\n",
            "saving: fc_batch_14.pt\n",
            "saving: temporal_batch_15.pt\n",
            "saving: sgconv_batch_15.pt\n",
            "saving: pool_batch_15.pt\n",
            "saving: fc_batch_15.pt\n",
            "saving: temporal_batch_16.pt\n",
            "saving: sgconv_batch_16.pt\n",
            "saving: pool_batch_16.pt\n",
            "saving: fc_batch_16.pt\n",
            "saving: temporal_batch_17.pt\n",
            "saving: sgconv_batch_17.pt\n",
            "saving: pool_batch_17.pt\n",
            "saving: fc_batch_17.pt\n",
            "saving: temporal_batch_18.pt\n",
            "saving: sgconv_batch_18.pt\n",
            "saving: pool_batch_18.pt\n",
            "saving: fc_batch_18.pt\n",
            "saving: temporal_batch_19.pt\n",
            "saving: sgconv_batch_19.pt\n",
            "saving: pool_batch_19.pt\n",
            "saving: fc_batch_19.pt\n",
            "saving: temporal_batch_20.pt\n",
            "saving: sgconv_batch_20.pt\n",
            "saving: pool_batch_20.pt\n",
            "saving: fc_batch_20.pt\n",
            "saving: temporal_batch_21.pt\n",
            "saving: sgconv_batch_21.pt\n",
            "saving: pool_batch_21.pt\n",
            "saving: fc_batch_21.pt\n",
            "saving: temporal_batch_22.pt\n",
            "saving: sgconv_batch_22.pt\n",
            "saving: pool_batch_22.pt\n",
            "saving: fc_batch_22.pt\n",
            "saving: temporal_batch_23.pt\n",
            "saving: sgconv_batch_23.pt\n",
            "saving: pool_batch_23.pt\n",
            "saving: fc_batch_23.pt\n",
            "saving: temporal_batch_24.pt\n",
            "saving: sgconv_batch_24.pt\n",
            "saving: pool_batch_24.pt\n",
            "saving: fc_batch_24.pt\n",
            "saving: temporal_batch_25.pt\n",
            "saving: sgconv_batch_25.pt\n",
            "saving: pool_batch_25.pt\n",
            "saving: fc_batch_25.pt\n",
            "saving: temporal_batch_26.pt\n",
            "saving: sgconv_batch_26.pt\n",
            "saving: pool_batch_26.pt\n",
            "saving: fc_batch_26.pt\n",
            "saving: temporal_batch_27.pt\n",
            "saving: sgconv_batch_27.pt\n",
            "saving: pool_batch_27.pt\n",
            "saving: fc_batch_27.pt\n",
            "saving: temporal_batch_28.pt\n",
            "saving: sgconv_batch_28.pt\n",
            "saving: pool_batch_28.pt\n",
            "saving: fc_batch_28.pt\n",
            "saving: temporal_batch_29.pt\n",
            "saving: sgconv_batch_29.pt\n",
            "saving: pool_batch_29.pt\n",
            "saving: fc_batch_29.pt\n",
            "saving: temporal_batch_30.pt\n",
            "saving: sgconv_batch_30.pt\n",
            "saving: pool_batch_30.pt\n",
            "saving: fc_batch_30.pt\n",
            "saving: temporal_batch_31.pt\n",
            "saving: sgconv_batch_31.pt\n",
            "saving: pool_batch_31.pt\n",
            "saving: fc_batch_31.pt\n",
            "saving: temporal_batch_32.pt\n",
            "saving: sgconv_batch_32.pt\n",
            "saving: pool_batch_32.pt\n",
            "saving: fc_batch_32.pt\n",
            "saving: temporal_batch_33.pt\n",
            "saving: sgconv_batch_33.pt\n",
            "saving: pool_batch_33.pt\n",
            "saving: fc_batch_33.pt\n",
            "saving: temporal_batch_34.pt\n",
            "saving: sgconv_batch_34.pt\n",
            "saving: pool_batch_34.pt\n",
            "saving: fc_batch_34.pt\n",
            "saving: temporal_batch_35.pt\n"
          ]
        }
      ],
      "source": [
        "import CKA_functions\n",
        "importlib.reload(CKA_functions)\n",
        "from CKA_functions import compute_all_model_kernels,compute_all_model_CKA,load_model_metadata,plot_cka_heatmaps\n",
        "from CKA_functions import load_dataset,fix_dataset_shape,compute_cross_model_cka,display_cka_matrix,compute_multi_model_kernels,display_differences_matrix_og\n",
        "from CKA_functions import compose_heat_matrix\n",
        "layer_names=[\"sgconv\",\"spatial\",\"spatial_att\",\"temporal\",\"fc\",\"pool\"]\n",
        "batch_size = 288\n",
        "n_batches = 4\n",
        "compute_all_model_kernels(model_direc,\n",
        "                            activation_direc,\n",
        "                            kernel_direc,X,\n",
        "                            layer_names=layer_names,\n",
        "                            batch_size=batch_size,\n",
        "                            n_batches=n_batches,\n",
        "                          device=device)\n",
        "# plot_cka_heatmaps(\"../cka_results\",\"../kernels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QMEU_7CNRVIG",
      "metadata": {
        "id": "QMEU_7CNRVIG"
      },
      "outputs": [],
      "source": [
        "from CKA_functions import compute_all_model_CKA\n",
        "compute_all_model_CKA(kernel_direc,\"cka_results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OF_TkQhi5QKj"
      },
      "id": "OF_TkQhi5QKj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Vbwzg32ZhZ",
        "outputId": "5c3c5935-cc02-4a9f-9ae4-70e41730e962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab. Checking required libraries...\n",
            "Installing missing libraries: moabb, braindecode, torch_geometric\n",
            "Collecting moabb\n",
            "  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting braindecode\n",
            "  Downloading braindecode-0.8.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (6.0.2)\n",
            "Collecting coverage<8.0.0,>=7.0.1 (from moabb)\n",
            "  Downloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting edfio<0.5.0,>=0.4.2 (from moabb)\n",
            "  Downloading edfio-0.4.8-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting edflib-python<2.0.0,>=1.0.6 (from moabb)\n",
            "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.13.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.10.0)\n",
            "Collecting memory-profiler<0.62.0,>=0.61.0 (from moabb)\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting mne<2.0.0,>=1.7.0 (from moabb)\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting mne-bids>=0.14 (from moabb)\n",
            "  Downloading mne_bids-0.16.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting numpy<2.0,>=1.22 (from moabb)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.2.2)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.8.2)\n",
            "Collecting pyriemann<0.8,>=0.7 (from moabb)\n",
            "  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.32.3)\n",
            "Collecting scikit-learn<1.6 (from moabb)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.14.1)\n",
            "Collecting seaborn<0.13.0,>=0.12.1 (from moabb)\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (4.67.1)\n",
            "Collecting urllib3<2.0.0,>=1.26.15 (from moabb)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skorch (from braindecode)\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from braindecode) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from braindecode) (0.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.4.2)\n",
            "Collecting torchinfo (from braindecode)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting docstring-inheritance (from braindecode)\n",
            "  Downloading docstring_inheritance-2.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->braindecode)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->braindecode)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->braindecode)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->braindecode)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->braindecode)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->braindecode)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->braindecode) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.17.0)\n",
            "Downloading moabb-1.2.0-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braindecode-0.8.1-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.2/165.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.0/244.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edfio-0.4.8-py3-none-any.whl (27 kB)\n",
            "Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne_bids-0.16.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docstring_inheritance-2.2.2-py3-none-any.whl (24 kB)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: urllib3, torchinfo, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, memory-profiler, docstring-inheritance, coverage, nvidia-cusparse-cu12, nvidia-cudnn-cu12, edflib-python, edfio, torch_geometric, scikit-learn, nvidia-cusolver-cu12, skorch, seaborn, pyriemann, mne, mne-bids, braindecode, moabb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.2\n",
            "    Uninstalling seaborn-0.13.2:\n",
            "      Successfully uninstalled seaborn-0.13.2\n",
            "Successfully installed braindecode-0.8.1 coverage-7.8.0 docstring-inheritance-2.2.2 edfio-0.4.8 edflib-python-1.0.8 memory-profiler-0.61.0 mne-1.9.0 mne-bids-0.16.0 moabb-1.2.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyriemann-0.7 scikit-learn-1.5.2 seaborn-0.12.2 skorch-1.1.0 torch_geometric-2.6.1 torchinfo-1.8.0 urllib3-1.26.20\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "def install_if_colab():\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Running in Google Colab. Checking required libraries...\")\n",
        "\n",
        "        packages = [\"moabb\", \"braindecode\",\"torch_geometric\"]  # Add required libraries\n",
        "        missing_packages = [pkg for pkg in packages if importlib.util.find_spec(pkg) is None]\n",
        "\n",
        "        if missing_packages:\n",
        "            print(f\"Installing missing libraries: {', '.join(missing_packages)}\")\n",
        "            !pip install {\" \".join(missing_packages)}\n",
        "        else:\n",
        "            print(\"All required libraries are already installed.\")\n",
        "    else:\n",
        "        print(\"Not running in Google Colab. No installation needed.\")\n",
        "\n",
        "install_if_colab()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_sHCnT22v9k",
        "outputId": "529e3f15-b3a7-4b8b-9e6c-ce2671e03b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "ZsDMRz4zbXOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1osynJth26to"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "train_set = torch.load(path+'EEG_data/emotion_train_set.pt')\n",
        "test_set = torch.load(path+'EEG_data/emotion_test_set.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xba9vjnO2Zhg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#from shallow_fbcsp import ShallowFBCSPNet\n",
        "from braindecode.util import set_random_seeds\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
        "device = \"cuda\" if cuda else \"cpu\"\n",
        "if cuda:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed = 282828\n",
        "set_random_seeds(seed=seed, cuda=cuda)\n",
        "\n",
        "n_classes = 3\n",
        "classes = list(range(n_classes))\n",
        "# Extract number of chans and time steps from dataset\n",
        "n_channels = 32\n",
        "input_window_samples = 400\n",
        "\n",
        "print(\"n_classes: \", n_classes)\n",
        "print(\"n_channels:\", n_channels)\n",
        "print(\"input_window_samples size:\", input_window_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3wPzn3X2Zhh"
      },
      "outputs": [],
      "source": [
        "#from models_fbscp import CollapsedShallowNet\n",
        "# The ShallowFBCSPNet is a `nn.Sequential` model\n",
        "import importlib\n",
        "import SGCN\n",
        "importlib.reload(SGCN)\n",
        "from SGCN import ShallowSGCNNet\n",
        "from weight_init import init_weights\n",
        "from CKA_functions import adjacency_matrix_motion,adjacency_matrix_distance_motion\n",
        "from CKA_functions import adjacency_matrix_FACED,adjacency_matrix_distance_FACED\n",
        "adj_m,pos = adjacency_matrix_FACED()\n",
        "#print(adj_m)\n",
        "adj_dis_m, dm = adjacency_matrix_distance_FACED(pos,delta=5)\n",
        "dm\n",
        "torch_tensor = torch.from_numpy(dm)\n",
        "edge_weight = torch_tensor.reshape(-1)\n",
        "print(edge_weight.shape)\n",
        "\n",
        "model = ShallowSGCNNet(n_channels,n_classes,input_window_samples,edge_weight)\n",
        "\n",
        "# Display torchinfo table describing the model\n",
        "print(model)\n",
        "\n",
        "# Send model to GPU\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDl5hBP4DonW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Eii9TH2Zhi"
      },
      "outputs": [],
      "source": [
        "# splitted = windows_dataset.split(\"session\")\n",
        "# train_set = splitted['0train']  # Session train\n",
        "# test_set = splitted['1test']  # Session evaluation\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.optim.lr_scheduler import LRScheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#lr = 1e-4\n",
        "#weight_decay = 1e-4\n",
        "#batch_size = 64\n",
        "#n_epochs = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlgtbF-r2Zhj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "# Define a method for training one epoch\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "        dataloader: DataLoader, model: Module,edge_index, loss_fn, optimizer,\n",
        "        scheduler: LRScheduler, epoch: int, device, print_batch_stats=True\n",
        "):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss, correct = 0, 0\n",
        "\n",
        "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader),\n",
        "                        disable=not print_batch_stats)\n",
        "\n",
        "    for batch_idx, (X, y, _) in progress_bar:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        #print(y)\n",
        "        #print(X.shape)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X,edge_index)\n",
        "\n",
        "\n",
        "        #print(y.shape)\n",
        "        #print(pred.shape)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()  # update the model weights\n",
        "        optimizer.zero_grad()\n",
        "        #print(loss.item())\n",
        "        #print(loss)\n",
        "        #print(train_loss)\n",
        "        train_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        #if print_batch_stats:\n",
        "        #    progress_bar.set_description(\n",
        "        #        f\"Epoch {epoch}/{n_epochs}, \"\n",
        "        #        f\"Batch {batch_idx + 1}/{len(dataloader)}, \"\n",
        "        #        f\"Loss: {loss.item():.6f}\"\n",
        "        #    )\n",
        "\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    correct /= len(dataloader.dataset)\n",
        "    return train_loss / len(dataloader), correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1S-1vTK2Zhk"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(dataloader: DataLoader, model: torch.nn.Module,edge_index, loss_fn, print_batch_stats=True):\n",
        "    device = next(model.parameters()).device  # Get model device\n",
        "    size = len(dataloader.dataset)\n",
        "    n_batches = len(dataloader)\n",
        "    model.eval()  # Switch to evaluation mode\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Initialize dictionaries for per-class tracking\n",
        "    class_correct = defaultdict(int)\n",
        "    class_total = defaultdict(int)\n",
        "\n",
        "    # Lists to store true and predicted labels for confusion matrix\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    if print_batch_stats:\n",
        "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    else:\n",
        "        progress_bar = enumerate(dataloader)\n",
        "\n",
        "    for batch_idx, (X, y, _) in progress_bar:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X,edge_index)\n",
        "        batch_loss = loss_fn(pred, y).item()\n",
        "\n",
        "        test_loss += batch_loss\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        # Store predictions and true labels for confusion matrix\n",
        "        all_preds.append(pred.argmax(1).cpu())\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "        # Compute per-class accuracy\n",
        "        preds_labels = pred.argmax(1)\n",
        "        for label, pred_label in zip(y, preds_labels):\n",
        "            class_total[label.item()] += 1\n",
        "            class_correct[label.item()] += (label == pred_label).item()\n",
        "\n",
        "        if print_batch_stats:\n",
        "            progress_bar.set_description(\n",
        "                f\"Batch {batch_idx + 1}/{len(dataloader)}, Loss: {batch_loss:.6f}\"\n",
        "            )\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "\n",
        "    # Compute per-class accuracy\n",
        "    class_accuracies = {\n",
        "        cls: (class_correct[cls] / class_total[cls]) * 100 if class_total[cls] > 0 else 0\n",
        "        for cls in class_total\n",
        "    }\n",
        "\n",
        "    # Compute overall accuracy\n",
        "    test_loss /= n_batches\n",
        "    overall_accuracy = (correct / size) * 100\n",
        "\n",
        "    # Print per-class accuracy\n",
        "    print(\"\\nClass-wise Accuracy:\")\n",
        "    for cls, acc in class_accuracies.items():\n",
        "        print(f\"  Class {cls}: {acc:.2f}%\")\n",
        "\n",
        "    print(f\"Test Accuracy: {overall_accuracy:.1f}%, Test Loss: {test_loss:.6f}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    return test_loss, overall_accuracy, class_accuracies, all_preds, all_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI5GEmbX4vG6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_e_index(dm):\n",
        "  threshold = 0  # Adjust as needed\n",
        "\n",
        "  source_nodes = []\n",
        "  target_nodes = []\n",
        "\n",
        "  # Iterate over all elements in the distance matrix, including self-loops and duplicates\n",
        "  for i in range(dm.shape[0]):\n",
        "      for j in range(dm.shape[1]):  # Iterate over all pairs, including (i, i)\n",
        "          if dm[i, j] >= threshold:  # If the distance meets the condition\n",
        "              source_nodes.append(i)  # Source node\n",
        "              target_nodes.append(j)  # Target node\n",
        "\n",
        "  # Create the edge_index tensor\n",
        "  edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long).to(device)\n",
        "  return edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDUBctmi2Zhl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "seeds = [99999]#],182726,91111222,44552222,12223111,100300,47456655,4788347,77766666,809890]\n",
        "for _seed in seeds:\n",
        "    seed = _seed\n",
        "    set_random_seeds(seed=seed, cuda=cuda)\n",
        "    adj_m,pos = adjacency_matrix_FACED()\n",
        "    #print(adj_m)\n",
        "    adj_dis_m, dm = adjacency_matrix_distance_FACED(pos,delta=5)\n",
        "    dm\n",
        "    torch_tensor = torch.from_numpy(dm)\n",
        "    edge_weight = torch_tensor.reshape(-1)\n",
        "    print(edge_weight.shape)\n",
        "    model = ShallowSGCNNet(\n",
        "        n_chans=n_channels,\n",
        "        n_outputs=n_classes,\n",
        "        n_times=input_window_samples,\n",
        "        edge_weights=edge_weight\n",
        "    )\n",
        "\n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    edge_index = get_e_index(dm)\n",
        "    # Initialize Weights & Biases\n",
        "    wandb.init(project=\"Master Thesis\", name=f\"{model.__class__.__name__} {seed}\")\n",
        "    model.apply(init_weights)\n",
        "    # Define hyperparameters\n",
        "    lr = 1e-3\n",
        "    weight_decay = 1e-4\n",
        "    batch_size = 64  # Start with 124\n",
        "    n_epochs = 100\n",
        "\n",
        "    final_acc = 0.0\n",
        "\n",
        "    # Log hyperparameters to wandb\n",
        "    wandb.config.update({\n",
        "        \"learning_rate\": lr,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": n_epochs\n",
        "    })\n",
        "\n",
        "    # Define optimizer and scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs - 1)\n",
        "\n",
        "    # Define loss function\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "    # Initialize lists to store all predictions & targets\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(f\"Epoch {epoch}/{n_epochs}: \", end=\"\")\n",
        "\n",
        "        train_loss, train_accuracy = train_one_epoch(\n",
        "            train_loader, model,edge_index, loss_fn, optimizer, scheduler, epoch, device\n",
        "        )\n",
        "\n",
        "        test_loss, test_accuracy, class_accuracies, batch_preds, batch_targets = test_model(test_loader, model,edge_index, loss_fn)\n",
        "        final_acc = test_accuracy\n",
        "\n",
        "        # Store predictions & labels for confusion matrix\n",
        "        all_preds.extend(batch_preds)\n",
        "        all_targets.extend(batch_targets)\n",
        "\n",
        "        # Print class-wise accuracy\n",
        "        print(\"\\nClass-wise Accuracy:\")\n",
        "        for class_idx, acc in class_accuracies.items():\n",
        "            print(f\"  Class {class_idx}: {acc:.2f}%\")\n",
        "\n",
        "        adj_matrix = model.rgnn.edge_weights.detach().cpu().numpy().reshape(22,22)\n",
        "\n",
        "        # Create a plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        cax = ax.matshow(adj_matrix, cmap='viridis', interpolation='nearest',vmin=0, vmax=1)  # Adjust color map\n",
        "        fig.colorbar(cax)\n",
        "\n",
        "        # Save the adjacency matrix as an image (not as a graph)\n",
        "        plt.tight_layout()\n",
        "        img_path = f\"adj_matrix_epoch_{epoch}.png\"\n",
        "        plt.savefig(img_path)\n",
        "        plt.close()\n",
        "\n",
        "        # Log results to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_accuracy * 100,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_accuracy\": test_accuracy,\n",
        "            \"learning_rate\": scheduler.get_last_lr()[0],\n",
        "            **{f\"class_{class_idx}_accuracy\": acc for class_idx, acc in class_accuracies.items()},\n",
        "            \"adj_matrix\": wandb.Image(img_path),\n",
        "        })\n",
        "\n",
        "        print(\n",
        "            f\"Train Accuracy: {100 * train_accuracy:.2f}%, \"\n",
        "            f\"Average Train Loss: {train_loss:.6f}, \"\n",
        "            f\"Test Accuracy: {test_accuracy:.2f}%, \"\n",
        "            f\"Average Test Loss: {test_loss:.6f}\\n\"\n",
        "        )\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    # Save predictions & true labels for later use (confusion matrix)\n",
        "    wandb.log({\"all_preds\": all_preds.tolist(), \"all_targets\": all_targets.tolist()})\n",
        "    wandb.finish()\n",
        "\n",
        "    # Assuming 'model' is your trained Braindecode model\n",
        "    print(seed)\n",
        "    torch.save(model, f\"{model.__class__.__name__}_{math.ceil(final_acc)}_{seed}.pth\")\n",
        "    torch.save(model.state_dict(), f\"{model.__class__.__name__}_{math.ceil(final_acc)}_{seed}_state.pth\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EeozMvYlqbs"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "source_dir = \"./\"  # Root directory where .pth files are stored\n",
        "dest_dir = f\"/content/drive/My Drive/pth_backups/{model.__class__.__name__}\"  # Destination in Google Drive\n",
        "\n",
        "# Ensure destination directory exists\n",
        "os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "# Find and move all .pth files\n",
        "for file_name in os.listdir(source_dir):\n",
        "    if file_name.endswith(\".pth\"):\n",
        "        src_path = os.path.join(source_dir, file_name)\n",
        "        dest_path = os.path.join(dest_dir, file_name)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\"Moved: {file_name} -> {dest_path}\")\n",
        "\n",
        "print(\"All .pth files have been moved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r25kGBA32Zhm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oTC35YwpAzQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shallow_fbcsp import ShallowFBCSPNet\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from scipy import signal\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X):\n",
    "    \"\"\"Computes the linear kernel matrix for X.\"\"\"\n",
    "    return torch.matmul(X,X.T)  # Dot product\n",
    "\n",
    "def centering_matrix(K):\n",
    "    \"\"\"Apply centering to the kernel matrix.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    H = torch.eye(n) - (1.0 / n) * torch.ones((n, n), device=K.device)\n",
    "    return H @ K @ H  # Centered kernel matrix\n",
    "\n",
    "def compute_hsic(K_x, K_y):\n",
    "    \"\"\"\n",
    "    Computes the Hilbert-Schmidt Independence Criterion (HSIC).\n",
    "    \n",
    "    Parameters:\n",
    "    - X: (n_samples, n_features_X) numpy array\n",
    "    - Y: (n_samples, n_features_Y) numpy array\n",
    "    - kernel_X: function to compute the kernel matrix for X\n",
    "    - kernel_Y: function to compute the kernel matrix for Y\n",
    "    \n",
    "    Returns:\n",
    "    - HSIC value (float)\n",
    "    \"\"\"\n",
    "    K_x_centered = centering_matrix(K_x)\n",
    "    K_y_centered = centering_matrix(K_y)\n",
    "    hsic_value = np.trace(K_x_centered @ K_y_centered) / ((K_x.shape[0] - 1) ** 2)\n",
    "    return hsic_value\n",
    "  \n",
    "def compute_CKA(K_x,K_y):\n",
    "  \"\"\"\n",
    "  compute CKA between two X,Y activations\n",
    "  \n",
    "  Parameters:\n",
    "  - X: (n_samples, x_features)\n",
    "  - Y: (n_samples, y_features)\n",
    "  - kernel_X: kernel for X\n",
    "  - kernel_Y: kernel for Y  \n",
    "  \"\"\"\n",
    "  HSIC_KL = compute_hsic(K_x,K_y) \n",
    "  HSIC_KK = compute_hsic(K_x,K_x)\n",
    "  HSIC_LL = compute_hsic(K_y,K_y)\n",
    "  numerator = HSIC_KL\n",
    "  denominator = math.sqrt(HSIC_KK * HSIC_LL)\n",
    "  return(numerator/denominator).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "in_chans = 22\n",
    "n_classes = 4\n",
    "n_channels = 22\n",
    "input_window_samples = 1000\n",
    "# Load two models for comparison\n",
    "model= torch.load(\"Shallow/Shallow_model_1.pth\",weights_only = False,map_location=torch.device('cpu'))\n",
    "model2 =ShallowFBCSPNet(in_chans, n_classes, input_window_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShallowFBCSPNet(\n",
      "  (temporal): Conv2d(1, 40, kernel_size=(1, 25), stride=(1, 1))\n",
      "  (spatial): Conv2d(40, 40, kernel_size=(22, 1), stride=(1, 1))\n",
      "  (pool): AvgPool2d(kernel_size=(1, 200), stride=(1, 200), padding=0)\n",
      "  (batch_norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=160, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Datasets/test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.conv_time.weight.device)  # Check the device of the conv_time layer\n",
    "#print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 22, 1125])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X = torch.stack([torch.from_numpy(test_set[i][0]) for i in range(len(test_set))])\n",
    "X = signal.resample(X.numpy(), 1000)\n",
    "X = torch.tensor(X)\n",
    "total_samples = X.shape[0]\n",
    "print(X.shape)  # Verify the tensor shape\n",
    "print(type(X))  # Should output <class 'torch.Tensor'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import signal\n",
    "\n",
    "# Assuming test_set is already loaded\n",
    "X = torch.stack([torch.from_numpy(test_set[i][0]) for i in range(len(test_set))])\n",
    "\n",
    "# Resample each sample along the time axis (dim=2)\n",
    "resampled_X = []\n",
    "for i in range(X.shape[0]):  # Loop over the number of samples (1000)\n",
    "    sample = X[i].numpy()  # Convert to NumPy for resampling\n",
    "    resampled_sample = signal.resample(sample, 1000, axis=-1)  # Resample to 1000 time points\n",
    "    resampled_X.append(torch.tensor(resampled_sample))  # Convert back to torch tensor\n",
    "\n",
    "# Stack the resampled samples back into a tensor\n",
    "X_resampled = torch.stack(resampled_X)\n",
    "\n",
    "print(X_resampled.shape)  # Should be [1000, 22, 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_844\\838504088.py:54: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
      "  extract_model_activations(model, X.T, output_dir=\"Datasets/Shallow_activations/model1/\", batch_size=1125, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: temporal_batch_1.pt\n",
      "saving: spatial_batch_1.pt\n",
      "saving: batch_norm_batch_1.pt\n",
      "saving: pool_batch_1.pt\n",
      "saving: dropout_batch_1.pt\n",
      "saving: fc_batch_1.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "def extract_model_activations(model, input_tensor, output_dir, batch_size=128, device='cuda'):\n",
    "    # Make sure the model is on the correct device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "        \n",
    "    # Make sure the input tensor is also on the same device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    activations = OrderedDict()\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks for specific layers\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == \"temporal\" or name == \"spatial\" or name == \"pool\" or name == \"dropout\" or name == \"batch_norm\" or name == \"dropout\" or name == \"fc\":  # Modify as per your layer names\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "        if \"weight\" in name: \n",
    "            print(f\"{name} weight shape: {param.shape}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, input_tensor.shape[0], batch_size):\n",
    "            batch = input_tensor[i:i + batch_size]  # Select current batch\n",
    "            batch = batch.to(device)  # Make sure the batch is on the correct device\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            _ = model(batch)  \n",
    "\n",
    "            # Save activations after each batch\n",
    "            for name, activation in activations.items():\n",
    "                batch_idx = i // batch_size + 1  # This determines the batch number\n",
    "                print(f\"saving: {name}_batch_{batch_idx}.pt\")\n",
    "                torch.save(activation, os.path.join(output_dir, f\"{name}_batch_{batch_idx}.pt\"))\n",
    "            \n",
    "            # Clear activations list after saving\n",
    "            activations.clear()\n",
    "            torch.cuda.empty_cache()  # Optional: Clear GPU memory after each batch\n",
    "\n",
    "\n",
    "# Call the function with the correct device:\n",
    "# Assuming 'model' is your model and 'X' is the input tensor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "extract_model_activations(model, X.T, output_dir=\"Datasets/Shallow_activations/model1/\", batch_size=1125, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2592, 22, 1000])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.conv_time.weight.device)  # Check the device of the conv_time layer\n",
    "#print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_model_activations(model,X,output_dir=\"Datasets/activations/model1/\",batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_model_activations(model2,X,output_dir=\"Datasets/activations/model4/\",batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length = torch.load(f\"Datasets/activations/model1/conv_time_batch_{3}.pt\")\n",
    "#print(length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spatial', 'pool', 'dropout', 'batch_norm', 'dropout', 'fc']\n",
      "['spatial', 'pool', 'dropout', 'batch_norm', 'dropout', 'fc']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "del X\n",
    "# Use OrderedDict to preserve the order of layer names\n",
    "layer_names_model1 = [\"spatial\",\"pool\",\"dropout\",\"batch_norm\", \"dropout\",\"fc\"]\n",
    "layer_names_model2 = layer_names_model1\n",
    "\n",
    "\n",
    "print(layer_names_model1)\n",
    "print(layer_names_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m batch_nr \u001b[38;5;241m=\u001b[39m total_samples \u001b[38;5;241m/\u001b[39m\u001b[43mbatch_size\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "batch_nr = total_samples /batch_size\n",
    "\n",
    "#batch_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_kernel_full_highmem(layer, batch_nr, model_number):\n",
    "    \"\"\"Computes the linear kernel for all samples at once.\"\"\"\n",
    "    \n",
    "\n",
    "    activations_list = []\n",
    "    \n",
    "    for batch_idx in range(1, math.ceil(batch_nr+1)):\n",
    "        print(f\"\\rLoading batch {batch_idx} for {layer} in model {model_number}\", end='', flush=True)\n",
    "        \n",
    "\n",
    "        batch_activations = torch.load(f\"Datasets/activations/model{model_number}/{layer}_batch_{batch_idx}.pt\")\n",
    "        batch_activations = batch_activations.reshape(batch_activations.shape[0], -1)  # Flatten\n",
    "        \n",
    "        activations_list.append(batch_activations)\n",
    "    \n",
    "    all_activations = torch.cat(activations_list, dim=0)\n",
    "    print(\"\\nFinal Activations Shape:\", all_activations.shape)\n",
    "\n",
    "    full_kernel = torch.matmul(all_activations, all_activations.T)\n",
    "\n",
    "    return full_kernel\n",
    "\n",
    "# model_1_kernels = OrderedDict()\n",
    "# model_2_kernels = OrderedDict()\n",
    "\n",
    "# for layer in layer_names_model1:\n",
    "#     model_1_kernels[layer] = compute_kernel_full_highmem(layer, batch_nr,1)\n",
    "# for layer in layer_names_model2:\n",
    "#     model_2_kernels[layer] = compute_kernel_full_highmem(layer,batch_nr,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1= torch.load(\"Collapsed_Shallow/braindecode_model_temponly_1.pth\",weights_only = False,map_location=torch.device('cpu'))\n",
    "#model2= torch.load(\"Collapsed_Shallow/braindecode_model_temponly_2.pth\",weights_only = False,map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading batches 1-2 for spatial in model 1torch.Size([1125, 39040]) torch.Size([1125, 39040])\n",
      "None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1000) must match the existing size (1125) at non-singleton dimension 1.  Target sizes: [1000, 1000].  Tensor sizes: [1125, 1125]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 84\u001b[0m\n\u001b[0;32m     80\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1125\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m### Takes 51 Min and 15 sec. Shallow\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m### Takes 3 Min and 25 sec with Collapsed Shallow\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m### Takes      \u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m model_1_kernels \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_full_kernels_shallow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_names_model\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_names_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m model_2_kernels \u001b[38;5;241m=\u001b[39m compute_full_kernels_shallow(layer_names_model,\u001b[38;5;241m2\u001b[39m, layer_names_model, \u001b[38;5;241m9\u001b[39m,total_samples,batch_size,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     86\u001b[0m model_3_kernels \u001b[38;5;241m=\u001b[39m compute_full_kernels_shallow(layer_names_model,\u001b[38;5;241m3\u001b[39m, layer_names_model, \u001b[38;5;241m9\u001b[39m,total_samples,batch_size,\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 68\u001b[0m, in \u001b[0;36mcompute_full_kernels_shallow\u001b[1;34m(layer_names_model1, model_number, layer_names_model2, batch_nr, total_samples, batch_size, n_batches)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Compute kernels for model 1\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layer_names_model1:\n\u001b[1;32m---> 68\u001b[0m     model_1_kernels[layer] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_kernel_full_lowmem_shallow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Compute kernels for model 2\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#for layer in layer_names_model1:\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#    model_2_kernels[layer] = compute_kernel_full_lowmem(layer, batch_nr, 1, total_samples,batch_size,n_batches)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_1_kernels\n",
      "Cell \u001b[1;32mIn[17], line 51\u001b[0m, in \u001b[0;36mcompute_kernel_full_lowmem_shallow\u001b[1;34m(layer, batch_nr, model_number, total_samples, batch_size, n_batches, use_cuda)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mprint\u001b[39m(batch_activations\u001b[38;5;241m.\u001b[39mshape, batch_activations_transpose\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m     50\u001b[0m kernel_block \u001b[38;5;241m=\u001b[39m batch_activations \u001b[38;5;241m@\u001b[39m batch_activations_transpose\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 51\u001b[0m full_kernel[start_idx_col:end_idx_col, start_idx_row:end_idx_row] \u001b[38;5;241m=\u001b[39m kernel_block\n\u001b[0;32m     52\u001b[0m full_kernel[start_idx_row:end_idx_row, start_idx_col:end_idx_col] \u001b[38;5;241m=\u001b[39m kernel_block\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Use symmetry\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#print(f\"full_kernel slice shape: [{start_idx_col}:{end_idx_col}, {start_idx_row}:{end_idx_row}]\")\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#print(f\"Expected shape: [{end_idx_col - start_idx_col}, {end_idx_row - start_idx_row}]\")\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#print(f\"kernel_block shape: {kernel_block.shape}\")\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1000) must match the existing size (1125) at non-singleton dimension 1.  Target sizes: [1000, 1000].  Tensor sizes: [1125, 1125]"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_kernel_full_lowmem_shallow(layer, batch_nr, model_number, total_samples, batch_size, n_batches=1, use_cuda=False):\n",
    "    \"\"\"Computes the full kernel matrix in batches efficiently using matrix multiplication.\"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    full_kernel = torch.zeros((total_samples, total_samples), dtype=torch.float32, device=device)\n",
    "    \n",
    "    for batch_idx in range(1, math.ceil(math.ceil(batch_nr) / n_batches) + 1):\n",
    "        print(f\"\\rLoading batches {batch_idx * n_batches - (n_batches - 1)}-{batch_idx * n_batches} for {layer} in model {model_number}\", \n",
    "              end='', flush=True)\n",
    "\n",
    "        batch_activations_list = []\n",
    "        start_idx_col = (batch_idx - 1) * batch_size * n_batches\n",
    "        end_idx_col = min(start_idx_col + batch_size * n_batches, total_samples)  \n",
    "\n",
    "        # Load multiple batches at once\n",
    "        for sub_batch in range(n_batches):\n",
    "            batch_file_idx = (batch_idx - 1) * n_batches + sub_batch + 1\n",
    "            if batch_file_idx > math.ceil(batch_nr):\n",
    "                break\n",
    "            batch_activations = torch.load(\n",
    "                f\"Datasets/Shallow_activations/model{model_number}/{layer}_batch_{batch_file_idx}.pt\"\n",
    "            ).to(device)\n",
    "            batch_activations_list.append(batch_activations.reshape(batch_activations.shape[0], -1))\n",
    "\n",
    "        if not batch_activations_list:\n",
    "            continue\n",
    "\n",
    "        batch_activations = torch.cat(batch_activations_list, dim=0)  # Merge batches\n",
    "\n",
    "        for batch_idx2 in range(1, math.ceil(math.ceil(batch_nr) / n_batches) + 2):\n",
    "            batch_activations_transpose_list = []\n",
    "            start_idx_row = (batch_idx2 - 1) * batch_size * n_batches\n",
    "            end_idx_row = min(start_idx_row + batch_size * n_batches, total_samples)\n",
    "\n",
    "            # Load multiple batches at once\n",
    "            for sub_batch2 in range(n_batches):\n",
    "                batch_file_idx2 = (batch_idx2 - 1) * n_batches + sub_batch2 + 1\n",
    "                if batch_file_idx2 > math.ceil(batch_nr):\n",
    "                    break\n",
    "                batch_activations_transpose = torch.load(\n",
    "                    f\"Datasets/Shallow_activations/model{model_number}/{layer}_batch_{batch_file_idx2}.pt\").to(device)\n",
    "                batch_activations_transpose_list.append(batch_activations_transpose.reshape(batch_activations_transpose.shape[0], -1))\n",
    "\n",
    "            if not batch_activations_transpose_list:\n",
    "                continue\n",
    "\n",
    "            batch_activations_transpose = torch.cat(batch_activations_transpose_list, dim=0)\n",
    "            print(print(batch_activations.shape, batch_activations_transpose.shape))\n",
    "            kernel_block = batch_activations @ batch_activations_transpose.T\n",
    "            full_kernel[start_idx_col:end_idx_col, start_idx_row:end_idx_row] = kernel_block\n",
    "            full_kernel[start_idx_row:end_idx_row, start_idx_col:end_idx_col] = kernel_block.T  # Use symmetry\n",
    "            #print(f\"full_kernel slice shape: [{start_idx_col}:{end_idx_col}, {start_idx_row}:{end_idx_row}]\")\n",
    "            #print(f\"Expected shape: [{end_idx_col - start_idx_col}, {end_idx_row - start_idx_row}]\")\n",
    "            #print(f\"kernel_block shape: {kernel_block.shape}\")\n",
    "\n",
    "\n",
    "    return full_kernel.cpu()\n",
    "\n",
    "\n",
    "def compute_full_kernels_shallow(layer_names_model1,model_number, layer_names_model2, batch_nr, total_samples,batch_size,n_batches):\n",
    "    \"\"\"Computes the kernels for both models.\"\"\"\n",
    "    model_1_kernels = {}\n",
    "    model_2_kernels = {}\n",
    "\n",
    "    # Compute kernels for model 1\n",
    "    for layer in layer_names_model1:\n",
    "        model_1_kernels[layer] = compute_kernel_full_lowmem_shallow(layer, batch_nr, model_number, total_samples,batch_size,n_batches)\n",
    "\n",
    "    # Compute kernels for model 2\n",
    "    #for layer in layer_names_model1:\n",
    "    #    model_2_kernels[layer] = compute_kernel_full_lowmem(layer, batch_nr, 1, total_samples,batch_size,n_batches)\n",
    "\n",
    "    return model_1_kernels\n",
    "\n",
    "model_1_kernels = OrderedDict()\n",
    "#model_2_kernels = OrderedDict()\n",
    "layer_names_model = layer_names_model1 \n",
    "\n",
    "batch_size = 1125\n",
    "### Takes 51 Min and 15 sec. Shallow\n",
    "### Takes 3 Min and 25 sec with Collapsed Shallow\n",
    "### Takes      \n",
    "model_1_kernels = compute_full_kernels_shallow(layer_names_model,1, layer_names_model, 1,total_samples,batch_size,2)\n",
    "model_2_kernels = compute_full_kernels_shallow(layer_names_model,2, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_3_kernels = compute_full_kernels_shallow(layer_names_model,3, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_4_kernels = compute_full_kernels_shallow(layer_names_model,4, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_5_kernels = compute_full_kernels_shallow(layer_names_model,5, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_6_kernels = compute_full_kernels_shallow(layer_names_model,6, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_7_kernels = compute_full_kernels_shallow(layer_names_model,7, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_8_kernels = compute_full_kernels_shallow(layer_names_model,8, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_9_kernels = compute_full_kernels_shallow(layer_names_model,9, layer_names_model, 9,total_samples,batch_size,2)\n",
    "model_10_kernels = compute_full_kernels_shallow(layer_names_model,10, layer_names_model, 9,total_samples,batch_size,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8125 1 1000 128 2\n",
      "Loading batches 1-2 for spatial in model 1"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Shape mismatch in transposed activations: 256 != 232",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_kernels\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Now, let's compute the kernels for models 1 to 10\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m model_1_kernels \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_full_kernels_conformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_names_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 87\u001b[0m, in \u001b[0;36mcompute_full_kernels_conformer\u001b[1;34m(layer_names_model, model_number, batch_nr, total_samples, batch_size, n_batches)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_nr, model_number, total_samples, batch_size, n_batches)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layer_names_model:\n\u001b[1;32m---> 87\u001b[0m     model_kernels[layer] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_kernel_full_lowmem_conformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kernels\n",
      "Cell \u001b[1;32mIn[51], line 66\u001b[0m, in \u001b[0;36mcompute_kernel_full_lowmem_conformer\u001b[1;34m(layer, batch_nr, model_number, total_samples, batch_size, n_batches, use_cuda)\u001b[0m\n\u001b[0;32m     63\u001b[0m batch_activations_transpose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch_activations_transpose_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Ensure correct shape for transposed activations\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch_activations_transpose\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m end_idx_row \u001b[38;5;241m-\u001b[39m start_idx_row, \\\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch in transposed activations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_activations_transpose\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx_row\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_idx_row\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Compute the kernel block by multiplying the activations and their transpose\u001b[39;00m\n\u001b[0;32m     70\u001b[0m kernel_block \u001b[38;5;241m=\u001b[39m batch_activations \u001b[38;5;241m@\u001b[39m batch_activations_transpose\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mAssertionError\u001b[0m: Shape mismatch in transposed activations: 256 != 232"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def compute_kernel_full_lowmem_conformer(layer, batch_nr, model_number, total_samples, batch_size, n_batches=1, use_cuda=False):\n",
    "    \"\"\"Computes the full kernel matrix efficiently using matrix multiplication in low memory.\"\"\"\n",
    "\n",
    "    # Select the device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize the full kernel matrix with zeros\n",
    "    full_kernel = torch.zeros((total_samples, total_samples), dtype=torch.float32, device=device)\n",
    "\n",
    "    # Loop through batches to load the activations and compute the kernel matrix\n",
    "    for batch_idx in range(1, math.ceil(batch_nr / n_batches) + 1):\n",
    "        print(f\"\\rLoading batches {batch_idx * n_batches - (n_batches - 1)}-{batch_idx * n_batches} for {layer} in model {model_number}\",\n",
    "              end='', flush=True)\n",
    "\n",
    "        batch_activations_list = []\n",
    "        start_idx_col = (batch_idx - 1) * batch_size * n_batches\n",
    "        end_idx_col = min(start_idx_col + batch_size * n_batches, total_samples)\n",
    "\n",
    "        # Load multiple batches at once\n",
    "        for sub_batch in range(n_batches):\n",
    "            batch_file_idx = (batch_idx - 1) * n_batches + sub_batch + 1\n",
    "            if batch_file_idx > math.ceil(batch_nr):\n",
    "                break\n",
    "            # Corrected file path, replace the layer name and model number properly\n",
    "            batch_activations = torch.load(\n",
    "                f\"Datasets/Conformer_activations/model{model_number}/{layer}_batch_{batch_file_idx}.pt\"\n",
    "            ).to(device)\n",
    "            batch_activations_list.append(batch_activations.reshape(batch_activations.shape[0], -1))\n",
    "\n",
    "        if not batch_activations_list:\n",
    "            continue\n",
    "\n",
    "        # Concatenate all batch activations\n",
    "        batch_activations = torch.cat(batch_activations_list, dim=0)  # Merge batches\n",
    "\n",
    "        # Ensure correct shape for activations\n",
    "        assert batch_activations.shape[0] == end_idx_col - start_idx_col, \\\n",
    "            f\"Shape mismatch in batch activations: {batch_activations.shape[0]} != {end_idx_col - start_idx_col}\"\n",
    "\n",
    "        # Loop through rows and compute the kernel matrix blocks\n",
    "        for batch_idx2 in range(1, math.ceil(batch_nr / n_batches) + 2):\n",
    "            batch_activations_transpose_list = []\n",
    "            start_idx_row = (batch_idx2 - 1) * batch_size * n_batches\n",
    "            end_idx_row = min(start_idx_row + batch_size * n_batches, total_samples)\n",
    "\n",
    "            # Load multiple batches for transposed activations\n",
    "            for sub_batch2 in range(n_batches):\n",
    "                batch_file_idx2 = (batch_idx2 - 1) * n_batches + sub_batch2 + 1\n",
    "                if batch_file_idx2 > math.ceil(batch_nr):\n",
    "                    break\n",
    "                # Corrected file path, replace the layer name and model number properly\n",
    "                batch_activations_transpose = torch.load(\n",
    "                    f\"Datasets/Conformer_activations/model{model_number}/{layer}_batch_{batch_file_idx2}.pt\").to(device)\n",
    "                batch_activations_transpose_list.append(batch_activations_transpose.reshape(batch_activations_transpose.shape[0], -1))\n",
    "\n",
    "            if not batch_activations_transpose_list:\n",
    "                continue\n",
    "\n",
    "            # Concatenate all batch transposed activations\n",
    "            batch_activations_transpose = torch.cat(batch_activations_transpose_list, dim=0)\n",
    "\n",
    "            # Ensure correct shape for transposed activations\n",
    "            assert batch_activations_transpose.shape[0] == end_idx_row - start_idx_row, \\\n",
    "                f\"Shape mismatch in transposed activations: {batch_activations_transpose.shape[0]} != {end_idx_row - start_idx_row}\"\n",
    "\n",
    "            # Compute the kernel block by multiplying the activations and their transpose\n",
    "            kernel_block = batch_activations @ batch_activations_transpose.T\n",
    "\n",
    "            # Compute the kernel block shape to match the target\n",
    "            kernel_block = kernel_block[:end_idx_row - start_idx_row, :end_idx_col - start_idx_col]\n",
    "\n",
    "            # Store the kernel block in the appropriate positions in the full kernel matrix\n",
    "            full_kernel[start_idx_col:end_idx_col, start_idx_row:end_idx_row] = kernel_block\n",
    "            full_kernel[start_idx_row:end_idx_row, start_idx_col:end_idx_col] = kernel_block.T  # Ensure symmetry\n",
    "\n",
    "    # Return the final kernel matrix on the CPU (after computation)\n",
    "    return full_kernel.cpu()\n",
    "\n",
    "# Example for computing kernels for multiple models\n",
    "def compute_full_kernels_conformer(layer_names_model, model_number, batch_nr, total_samples, batch_size, n_batches):\n",
    "    model_kernels = {}\n",
    "    print(batch_nr, model_number, total_samples, batch_size, n_batches)\n",
    "    for layer in layer_names_model:\n",
    "        model_kernels[layer] = compute_kernel_full_lowmem_conformer(\n",
    "            layer, batch_nr, model_number, total_samples, batch_size, n_batches, use_cuda=True\n",
    "        )\n",
    "    return model_kernels\n",
    "\n",
    "# Now, let's compute the kernels for models 1 to 10\n",
    "model_1_kernels = compute_full_kernels_conformer(layer_names_model, 1, batch_nr, total_samples, batch_size, 2)\n",
    "# Repeat for other models (model_2_kernels, model_3_kernels, etc.)\n",
    "\n",
    "\n",
    "# Now, let's compute the kernels for models 1 to 10\n",
    "\n",
    "#model_1_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 1, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_2_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 2, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_3_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 3, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_4_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 4, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_5_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 5, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_6_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 6, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_7_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 7, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_8_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 8, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_9_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 9, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "#model_10_kernels = compute_kernel_full_lowmem_conformer(layer_names_model, 10, layer_names_model, batch_nr, total_samples, batch_size, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_kernel_full_lowmem_conformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m layer_names_model \u001b[38;5;241m=\u001b[39m layer_names_model1 \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m### Takes 51 Min and 15 sec. Shallow\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m### Takes 3 Min and 25 sec with Collapsed Shallow\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m### Takes      \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model_1_kernels \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_kernel_full_lowmem_conformer\u001b[49m(layer_names_model,\u001b[38;5;241m1\u001b[39m, layer_names_model, batch_nr,total_samples,batch_size,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      9\u001b[0m model_2_kernels \u001b[38;5;241m=\u001b[39m compute_kernel_full_lowmem_conformer(layer_names_model,\u001b[38;5;241m2\u001b[39m, layer_names_model, batch_nr,total_samples,batch_size,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m model_3_kernels \u001b[38;5;241m=\u001b[39m compute_kernel_full_lowmem_conformer(layer_names_model,\u001b[38;5;241m3\u001b[39m, layer_names_model, batch_nr,total_samples,batch_size,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_kernel_full_lowmem_conformer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#model_1_kernels = OrderedDict()\n",
    "#model_2_kernels = OrderedDict()\n",
    "layer_names_model = layer_names_model1 \n",
    "\n",
    "### Takes 51 Min and 15 sec. Shallow\n",
    "### Takes 3 Min and 25 sec with Collapsed Shallow\n",
    "### Takes      \n",
    "model_1_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,1, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_2_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,2, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_3_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,3, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_4_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,4, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_5_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,5, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_6_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,6, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_7_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,7, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_8_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,8, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_9_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,9, layer_names_model, batch_nr,total_samples,batch_size,2)\n",
    "model_10_kernels = compute_kernel_full_lowmem_conformer(layer_names_model,10, layer_names_model, batch_nr,total_samples,batch_size,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel so far:  0\n",
      "Kernel so far:  1\n",
      "Kernel so far:  2\n",
      "Kernel so far:  3\n",
      "Kernel so far:  4\n",
      "Kernel so far:  5\n",
      "Kernel so far:  6\n",
      "Kernel so far:  7\n",
      "Kernel so far:  8\n",
      "Kernel so far:  9\n",
      "0\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9577751450461506\n",
      "1\n",
      "CKA('spatio_temporal', 'pool'): 0.09200776530371468\n",
      "2\n",
      "CKA('spatio_temporal', 'dropout'): 0.09200776530371468\n",
      "3\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8998336166596254\n",
      "4\n",
      "CKA('pool', 'spatio_temporal'): 0.09362888506528227\n",
      "5\n",
      "CKA('pool', 'pool'): 0.9630113502600708\n",
      "6\n",
      "CKA('pool', 'dropout'): 0.9630113502600708\n",
      "7\n",
      "CKA('pool', 'batch_norm'): 0.23843014691919598\n",
      "8\n",
      "CKA('dropout', 'spatio_temporal'): 0.09362888506528227\n",
      "9\n",
      "CKA('dropout', 'pool'): 0.9630113502600708\n",
      "10\n",
      "CKA('dropout', 'dropout'): 0.9630113502600708\n",
      "11\n",
      "CKA('dropout', 'batch_norm'): 0.23843014691919598\n",
      "12\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.944752016193784\n",
      "13\n",
      "CKA('batch_norm', 'pool'): 0.25041350201115536\n",
      "14\n",
      "CKA('batch_norm', 'dropout'): 0.25041350201115536\n",
      "15\n",
      "CKA('batch_norm', 'batch_norm'): 0.9546428161540992\n",
      "16\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9367487728585835\n",
      "17\n",
      "CKA('spatio_temporal', 'pool'): 0.09148924725530883\n",
      "18\n",
      "CKA('spatio_temporal', 'dropout'): 0.09148924725530883\n",
      "19\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8680458123322484\n",
      "20\n",
      "CKA('pool', 'spatio_temporal'): 0.09456038256418826\n",
      "21\n",
      "CKA('pool', 'pool'): 0.930068765818612\n",
      "22\n",
      "CKA('pool', 'dropout'): 0.930068765818612\n",
      "23\n",
      "CKA('pool', 'batch_norm'): 0.2311813878244847\n",
      "24\n",
      "CKA('dropout', 'spatio_temporal'): 0.09456038256418826\n",
      "25\n",
      "CKA('dropout', 'pool'): 0.930068765818612\n",
      "26\n",
      "CKA('dropout', 'dropout'): 0.930068765818612\n",
      "27\n",
      "CKA('dropout', 'batch_norm'): 0.2311813878244847\n",
      "28\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.935665353453236\n",
      "29\n",
      "CKA('batch_norm', 'pool'): 0.24558951194845938\n",
      "30\n",
      "CKA('batch_norm', 'dropout'): 0.24558951194845938\n",
      "31\n",
      "CKA('batch_norm', 'batch_norm'): 0.9314250466866979\n",
      "32\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9209797640128842\n",
      "33\n",
      "CKA('spatio_temporal', 'pool'): 0.09016236968159255\n",
      "34\n",
      "CKA('spatio_temporal', 'dropout'): 0.09016236968159255\n",
      "35\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8467919964952226\n",
      "36\n",
      "CKA('pool', 'spatio_temporal'): 0.09554129325382002\n",
      "37\n",
      "CKA('pool', 'pool'): 0.9027475831906789\n",
      "38\n",
      "CKA('pool', 'dropout'): 0.9027475831906789\n",
      "39\n",
      "CKA('pool', 'batch_norm'): 0.228416616331321\n",
      "40\n",
      "CKA('dropout', 'spatio_temporal'): 0.09554129325382002\n",
      "41\n",
      "CKA('dropout', 'pool'): 0.9027475831906789\n",
      "42\n",
      "CKA('dropout', 'dropout'): 0.9027475831906789\n",
      "43\n",
      "CKA('dropout', 'batch_norm'): 0.228416616331321\n",
      "44\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9263946759475923\n",
      "45\n",
      "CKA('batch_norm', 'pool'): 0.24034573113570704\n",
      "46\n",
      "CKA('batch_norm', 'dropout'): 0.24034573113570704\n",
      "47\n",
      "CKA('batch_norm', 'batch_norm'): 0.913336575909173\n",
      "48\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9057816990583215\n",
      "49\n",
      "CKA('spatio_temporal', 'pool'): 0.08865958832160305\n",
      "50\n",
      "CKA('spatio_temporal', 'dropout'): 0.08865958832160305\n",
      "51\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8277045711510785\n",
      "52\n",
      "CKA('pool', 'spatio_temporal'): 0.09592800134599268\n",
      "53\n",
      "CKA('pool', 'pool'): 0.8761915263166281\n",
      "54\n",
      "CKA('pool', 'dropout'): 0.8761915263166281\n",
      "55\n",
      "CKA('pool', 'batch_norm'): 0.22563532294425265\n",
      "56\n",
      "CKA('dropout', 'spatio_temporal'): 0.09592800134599268\n",
      "57\n",
      "CKA('dropout', 'pool'): 0.8761915263166281\n",
      "58\n",
      "CKA('dropout', 'dropout'): 0.8761915263166281\n",
      "59\n",
      "CKA('dropout', 'batch_norm'): 0.22563532294425265\n",
      "60\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9169094667866969\n",
      "61\n",
      "CKA('batch_norm', 'pool'): 0.2350529359362049\n",
      "62\n",
      "CKA('batch_norm', 'dropout'): 0.2350529359362049\n",
      "63\n",
      "CKA('batch_norm', 'batch_norm'): 0.897894119256687\n",
      "64\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.8953900497257549\n",
      "65\n",
      "CKA('spatio_temporal', 'pool'): 0.08772133798319905\n",
      "66\n",
      "CKA('spatio_temporal', 'dropout'): 0.08772133798319905\n",
      "67\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8164108415405074\n",
      "68\n",
      "CKA('pool', 'spatio_temporal'): 0.09620322136534352\n",
      "69\n",
      "CKA('pool', 'pool'): 0.8594254360863478\n",
      "70\n",
      "CKA('pool', 'dropout'): 0.8594254360863478\n",
      "71\n",
      "CKA('pool', 'batch_norm'): 0.2249354141509907\n",
      "72\n",
      "CKA('dropout', 'spatio_temporal'): 0.09620322136534352\n",
      "73\n",
      "CKA('dropout', 'pool'): 0.8594254360863478\n",
      "74\n",
      "CKA('dropout', 'dropout'): 0.8594254360863478\n",
      "75\n",
      "CKA('dropout', 'batch_norm'): 0.2249354141509907\n",
      "76\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9092649560637045\n",
      "77\n",
      "CKA('batch_norm', 'pool'): 0.23162573493719973\n",
      "78\n",
      "CKA('batch_norm', 'dropout'): 0.23162573493719973\n",
      "79\n",
      "CKA('batch_norm', 'batch_norm'): 0.887654803287987\n",
      "80\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.8825826565497926\n",
      "81\n",
      "CKA('spatio_temporal', 'pool'): 0.0863119732379496\n",
      "82\n",
      "CKA('spatio_temporal', 'dropout'): 0.0863119732379496\n",
      "83\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8044662113941644\n",
      "84\n",
      "CKA('pool', 'spatio_temporal'): 0.09650805262900923\n",
      "85\n",
      "CKA('pool', 'pool'): 0.8406569107932124\n",
      "86\n",
      "CKA('pool', 'dropout'): 0.8406569107932124\n",
      "87\n",
      "CKA('pool', 'batch_norm'): 0.22400190350191065\n",
      "88\n",
      "CKA('dropout', 'spatio_temporal'): 0.09650805262900923\n",
      "89\n",
      "CKA('dropout', 'pool'): 0.8406569107932124\n",
      "90\n",
      "CKA('dropout', 'dropout'): 0.8406569107932124\n",
      "91\n",
      "CKA('dropout', 'batch_norm'): 0.22400190350191065\n",
      "92\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9010415137703485\n",
      "93\n",
      "CKA('batch_norm', 'pool'): 0.22739719096528957\n",
      "94\n",
      "CKA('batch_norm', 'dropout'): 0.22739719096528957\n",
      "95\n",
      "CKA('batch_norm', 'batch_norm'): 0.877640424653325\n",
      "96\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.8771340461191419\n",
      "97\n",
      "CKA('spatio_temporal', 'pool'): 0.08538778337387876\n",
      "98\n",
      "CKA('spatio_temporal', 'dropout'): 0.08538778337387876\n",
      "99\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.7982800494713442\n",
      "100\n",
      "CKA('pool', 'spatio_temporal'): 0.09684296970291012\n",
      "101\n",
      "CKA('pool', 'pool'): 0.829510859039004\n",
      "102\n",
      "CKA('pool', 'dropout'): 0.829510859039004\n",
      "103\n",
      "CKA('pool', 'batch_norm'): 0.22403708133374595\n",
      "104\n",
      "CKA('dropout', 'spatio_temporal'): 0.09684296970291012\n",
      "105\n",
      "CKA('dropout', 'pool'): 0.829510859039004\n",
      "106\n",
      "CKA('dropout', 'dropout'): 0.829510859039004\n",
      "107\n",
      "CKA('dropout', 'batch_norm'): 0.22403708133374595\n",
      "108\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.8975082089722097\n",
      "109\n",
      "CKA('batch_norm', 'pool'): 0.22472544555126142\n",
      "110\n",
      "CKA('batch_norm', 'dropout'): 0.22472544555126142\n",
      "111\n",
      "CKA('batch_norm', 'batch_norm'): 0.8718641927297534\n",
      "112\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.8681119650565666\n",
      "113\n",
      "CKA('spatio_temporal', 'pool'): 0.08509225606220099\n",
      "114\n",
      "CKA('spatio_temporal', 'dropout'): 0.08509225606220099\n",
      "115\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.7897505422748569\n",
      "116\n",
      "CKA('pool', 'spatio_temporal'): 0.0973197630738304\n",
      "117\n",
      "CKA('pool', 'pool'): 0.8145325701231986\n",
      "118\n",
      "CKA('pool', 'dropout'): 0.8145325701231986\n",
      "119\n",
      "CKA('pool', 'batch_norm'): 0.22273068864888676\n",
      "120\n",
      "CKA('dropout', 'spatio_temporal'): 0.0973197630738304\n",
      "121\n",
      "CKA('dropout', 'pool'): 0.8145325701231986\n",
      "122\n",
      "CKA('dropout', 'dropout'): 0.8145325701231986\n",
      "123\n",
      "CKA('dropout', 'batch_norm'): 0.22273068864888676\n",
      "124\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.8915262190466512\n",
      "125\n",
      "CKA('batch_norm', 'pool'): 0.222172907419416\n",
      "126\n",
      "CKA('batch_norm', 'dropout'): 0.222172907419416\n",
      "127\n",
      "CKA('batch_norm', 'batch_norm'): 0.8642715955796171\n",
      "128\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.8614767251134197\n",
      "129\n",
      "CKA('spatio_temporal', 'pool'): 0.08434063442057772\n",
      "130\n",
      "CKA('spatio_temporal', 'dropout'): 0.08434063442057772\n",
      "131\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.782467635542978\n",
      "132\n",
      "CKA('pool', 'spatio_temporal'): 0.09725689061608886\n",
      "133\n",
      "CKA('pool', 'pool'): 0.8004295094574141\n",
      "134\n",
      "CKA('pool', 'dropout'): 0.8004295094574141\n",
      "135\n",
      "CKA('pool', 'batch_norm'): 0.22173426220541897\n",
      "136\n",
      "CKA('dropout', 'spatio_temporal'): 0.09725689061608886\n",
      "137\n",
      "CKA('dropout', 'pool'): 0.8004295094574141\n",
      "138\n",
      "CKA('dropout', 'dropout'): 0.8004295094574141\n",
      "139\n",
      "CKA('dropout', 'batch_norm'): 0.22173426220541897\n",
      "140\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.8869098049090345\n",
      "141\n",
      "CKA('batch_norm', 'pool'): 0.21932935968075915\n",
      "142\n",
      "CKA('batch_norm', 'dropout'): 0.21932935968075915\n",
      "143\n",
      "CKA('batch_norm', 'batch_norm'): 0.8577093044133839\n",
      "144\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9934359732247555\n",
      "145\n",
      "CKA('spatio_temporal', 'pool'): 0.09751008173632977\n",
      "146\n",
      "CKA('spatio_temporal', 'dropout'): 0.09751008173632977\n",
      "147\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9359138665602219\n",
      "148\n",
      "CKA('pool', 'spatio_temporal'): 0.09870784823361864\n",
      "149\n",
      "CKA('pool', 'pool'): 0.9893405414042861\n",
      "150\n",
      "CKA('pool', 'dropout'): 0.9893405414042861\n",
      "151\n",
      "CKA('pool', 'batch_norm'): 0.24496644461955372\n",
      "152\n",
      "CKA('dropout', 'spatio_temporal'): 0.09870784823361864\n",
      "153\n",
      "CKA('dropout', 'pool'): 0.9893405414042861\n",
      "154\n",
      "CKA('dropout', 'dropout'): 0.9893405414042861\n",
      "155\n",
      "CKA('dropout', 'batch_norm'): 0.24496644461955372\n",
      "156\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.958364404882928\n",
      "157\n",
      "CKA('batch_norm', 'pool'): 0.24826514792016316\n",
      "158\n",
      "CKA('batch_norm', 'dropout'): 0.24826514792016316\n",
      "159\n",
      "CKA('batch_norm', 'batch_norm'): 0.9922242683122275\n",
      "160\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9839272698893686\n",
      "161\n",
      "CKA('spatio_temporal', 'pool'): 0.09665969227066559\n",
      "162\n",
      "CKA('spatio_temporal', 'dropout'): 0.09665969227066559\n",
      "163\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9194678910955498\n",
      "164\n",
      "CKA('pool', 'spatio_temporal'): 0.10015067066948695\n",
      "165\n",
      "CKA('pool', 'pool'): 0.9736355608624994\n",
      "166\n",
      "CKA('pool', 'dropout'): 0.9736355608624994\n",
      "167\n",
      "CKA('pool', 'batch_norm'): 0.2443490846719084\n",
      "168\n",
      "CKA('dropout', 'spatio_temporal'): 0.10015067066948695\n",
      "169\n",
      "CKA('dropout', 'pool'): 0.9736355608624994\n",
      "170\n",
      "CKA('dropout', 'dropout'): 0.9736355608624994\n",
      "171\n",
      "CKA('dropout', 'batch_norm'): 0.2443490846719084\n",
      "172\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9565935545404927\n",
      "173\n",
      "CKA('batch_norm', 'pool'): 0.2456416076412739\n",
      "174\n",
      "CKA('batch_norm', 'dropout'): 0.2456416076412739\n",
      "175\n",
      "CKA('batch_norm', 'batch_norm'): 0.980800539000699\n",
      "176\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.972944277196141\n",
      "177\n",
      "CKA('spatio_temporal', 'pool'): 0.09554674793594028\n",
      "178\n",
      "CKA('spatio_temporal', 'dropout'): 0.09554674793594028\n",
      "179\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9034367553058881\n",
      "180\n",
      "CKA('pool', 'spatio_temporal'): 0.10096459534051054\n",
      "181\n",
      "CKA('pool', 'pool'): 0.955528676806605\n",
      "182\n",
      "CKA('pool', 'dropout'): 0.955528676806605\n",
      "183\n",
      "CKA('pool', 'batch_norm'): 0.24320905980880853\n",
      "184\n",
      "CKA('dropout', 'spatio_temporal'): 0.10096459534051054\n",
      "185\n",
      "CKA('dropout', 'pool'): 0.955528676806605\n",
      "186\n",
      "CKA('dropout', 'dropout'): 0.955528676806605\n",
      "187\n",
      "CKA('dropout', 'batch_norm'): 0.24320905980880853\n",
      "188\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.953618892784291\n",
      "189\n",
      "CKA('batch_norm', 'pool'): 0.24240567418208506\n",
      "190\n",
      "CKA('batch_norm', 'dropout'): 0.24240567418208506\n",
      "191\n",
      "CKA('batch_norm', 'batch_norm'): 0.9691480861768416\n",
      "192\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9646929633033322\n",
      "193\n",
      "CKA('spatio_temporal', 'pool'): 0.0947876133341424\n",
      "194\n",
      "CKA('spatio_temporal', 'dropout'): 0.0947876133341424\n",
      "195\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8935081465671341\n",
      "196\n",
      "CKA('pool', 'spatio_temporal'): 0.10144021392062381\n",
      "197\n",
      "CKA('pool', 'pool'): 0.942937873744377\n",
      "198\n",
      "CKA('pool', 'dropout'): 0.942937873744377\n",
      "199\n",
      "CKA('pool', 'batch_norm'): 0.24342475397745228\n",
      "200\n",
      "CKA('dropout', 'spatio_temporal'): 0.10144021392062381\n",
      "201\n",
      "CKA('dropout', 'pool'): 0.942937873744377\n",
      "202\n",
      "CKA('dropout', 'dropout'): 0.942937873744377\n",
      "203\n",
      "CKA('dropout', 'batch_norm'): 0.24342475397745228\n",
      "204\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9484249480155009\n",
      "205\n",
      "CKA('batch_norm', 'pool'): 0.2400238206308392\n",
      "206\n",
      "CKA('batch_norm', 'dropout'): 0.2400238206308392\n",
      "207\n",
      "CKA('batch_norm', 'batch_norm'): 0.9604220744794287\n",
      "208\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.955731574268084\n",
      "209\n",
      "CKA('spatio_temporal', 'pool'): 0.09356864779157045\n",
      "210\n",
      "CKA('spatio_temporal', 'dropout'): 0.09356864779157045\n",
      "211\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8837682262052645\n",
      "212\n",
      "CKA('pool', 'spatio_temporal'): 0.10199458844997616\n",
      "213\n",
      "CKA('pool', 'pool'): 0.9286102963012668\n",
      "214\n",
      "CKA('pool', 'dropout'): 0.9286102963012668\n",
      "215\n",
      "CKA('pool', 'batch_norm'): 0.24354035440151411\n",
      "216\n",
      "CKA('dropout', 'spatio_temporal'): 0.10199458844997616\n",
      "217\n",
      "CKA('dropout', 'pool'): 0.9286102963012668\n",
      "218\n",
      "CKA('dropout', 'dropout'): 0.9286102963012668\n",
      "219\n",
      "CKA('dropout', 'batch_norm'): 0.24354035440151411\n",
      "220\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9443067967697075\n",
      "221\n",
      "CKA('batch_norm', 'pool'): 0.2369225970731858\n",
      "222\n",
      "CKA('batch_norm', 'dropout'): 0.2369225970731858\n",
      "223\n",
      "CKA('batch_norm', 'batch_norm'): 0.9523803346718531\n",
      "224\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9499919327867464\n",
      "225\n",
      "CKA('spatio_temporal', 'pool'): 0.09265988964344701\n",
      "226\n",
      "CKA('spatio_temporal', 'dropout'): 0.09265988964344701\n",
      "227\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8765959437306704\n",
      "228\n",
      "CKA('pool', 'spatio_temporal'): 0.10239797513287273\n",
      "229\n",
      "CKA('pool', 'pool'): 0.9190634710138806\n",
      "230\n",
      "CKA('pool', 'dropout'): 0.9190634710138806\n",
      "231\n",
      "CKA('pool', 'batch_norm'): 0.24402968225673188\n",
      "232\n",
      "CKA('dropout', 'spatio_temporal'): 0.10239797513287273\n",
      "233\n",
      "CKA('dropout', 'pool'): 0.9190634710138806\n",
      "234\n",
      "CKA('dropout', 'dropout'): 0.9190634710138806\n",
      "235\n",
      "CKA('dropout', 'batch_norm'): 0.24402968225673188\n",
      "236\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9418679655377415\n",
      "237\n",
      "CKA('batch_norm', 'pool'): 0.23469140743496547\n",
      "238\n",
      "CKA('batch_norm', 'dropout'): 0.23469140743496547\n",
      "239\n",
      "CKA('batch_norm', 'batch_norm'): 0.9458539595755288\n",
      "240\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9425744040597144\n",
      "241\n",
      "CKA('spatio_temporal', 'pool'): 0.09246248761757901\n",
      "242\n",
      "CKA('spatio_temporal', 'dropout'): 0.09246248761757901\n",
      "243\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8685967180473749\n",
      "244\n",
      "CKA('pool', 'spatio_temporal'): 0.10301181138706908\n",
      "245\n",
      "CKA('pool', 'pool'): 0.9067165358228826\n",
      "246\n",
      "CKA('pool', 'dropout'): 0.9067165358228826\n",
      "247\n",
      "CKA('pool', 'batch_norm'): 0.243295937160318\n",
      "248\n",
      "CKA('dropout', 'spatio_temporal'): 0.10301181138706908\n",
      "249\n",
      "CKA('dropout', 'pool'): 0.9067165358228826\n",
      "250\n",
      "CKA('dropout', 'dropout'): 0.9067165358228826\n",
      "251\n",
      "CKA('dropout', 'batch_norm'): 0.243295937160318\n",
      "252\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9385008532193292\n",
      "253\n",
      "CKA('batch_norm', 'pool'): 0.2328801165494775\n",
      "254\n",
      "CKA('batch_norm', 'dropout'): 0.2328801165494775\n",
      "255\n",
      "CKA('batch_norm', 'batch_norm'): 0.9391837416797472\n",
      "256\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9367357062550931\n",
      "257\n",
      "CKA('spatio_temporal', 'pool'): 0.09187320538815823\n",
      "258\n",
      "CKA('spatio_temporal', 'dropout'): 0.09187320538815823\n",
      "259\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8617611803537363\n",
      "260\n",
      "CKA('pool', 'spatio_temporal'): 0.10304650971519631\n",
      "261\n",
      "CKA('pool', 'pool'): 0.8951137115286135\n",
      "262\n",
      "CKA('pool', 'dropout'): 0.8951137115286135\n",
      "263\n",
      "CKA('pool', 'batch_norm'): 0.24294362310049175\n",
      "264\n",
      "CKA('dropout', 'spatio_temporal'): 0.10304650971519631\n",
      "265\n",
      "CKA('dropout', 'pool'): 0.8951137115286135\n",
      "266\n",
      "CKA('dropout', 'dropout'): 0.8951137115286135\n",
      "267\n",
      "CKA('dropout', 'batch_norm'): 0.24294362310049175\n",
      "268\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9348106902799368\n",
      "269\n",
      "CKA('batch_norm', 'pool'): 0.2307654541500079\n",
      "270\n",
      "CKA('batch_norm', 'dropout'): 0.2307654541500079\n",
      "271\n",
      "CKA('batch_norm', 'batch_norm'): 0.9331042869373052\n",
      "272\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9968779191100762\n",
      "273\n",
      "CKA('spatio_temporal', 'pool'): 0.09938514392902537\n",
      "274\n",
      "CKA('spatio_temporal', 'dropout'): 0.09938514392902537\n",
      "275\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.940234717626299\n",
      "276\n",
      "CKA('pool', 'spatio_temporal'): 0.10172859092496124\n",
      "277\n",
      "CKA('pool', 'pool'): 0.995454342023753\n",
      "278\n",
      "CKA('pool', 'dropout'): 0.995454342023753\n",
      "279\n",
      "CKA('pool', 'batch_norm'): 0.24995185550829066\n",
      "280\n",
      "CKA('dropout', 'spatio_temporal'): 0.10172859092496124\n",
      "281\n",
      "CKA('dropout', 'pool'): 0.995454342023753\n",
      "282\n",
      "CKA('dropout', 'dropout'): 0.995454342023753\n",
      "283\n",
      "CKA('dropout', 'batch_norm'): 0.24995185550829066\n",
      "284\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9558236381248617\n",
      "285\n",
      "CKA('batch_norm', 'pool'): 0.24800212773652539\n",
      "286\n",
      "CKA('batch_norm', 'dropout'): 0.24800212773652539\n",
      "287\n",
      "CKA('batch_norm', 'batch_norm'): 0.9962393500036196\n",
      "288\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9910326668083943\n",
      "289\n",
      "CKA('spatio_temporal', 'pool'): 0.09854068867819647\n",
      "290\n",
      "CKA('spatio_temporal', 'dropout'): 0.09854068867819647\n",
      "291\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9281821324130374\n",
      "292\n",
      "CKA('pool', 'spatio_temporal'): 0.1028549135301921\n",
      "293\n",
      "CKA('pool', 'pool'): 0.9864325322364111\n",
      "294\n",
      "CKA('pool', 'dropout'): 0.9864325322364111\n",
      "295\n",
      "CKA('pool', 'batch_norm'): 0.25040596880732524\n",
      "296\n",
      "CKA('dropout', 'spatio_temporal'): 0.1028549135301921\n",
      "297\n",
      "CKA('dropout', 'pool'): 0.9864325322364111\n",
      "298\n",
      "CKA('dropout', 'dropout'): 0.9864325322364111\n",
      "299\n",
      "CKA('dropout', 'batch_norm'): 0.25040596880732524\n",
      "300\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.957867103069086\n",
      "301\n",
      "CKA('batch_norm', 'pool'): 0.24640930107014744\n",
      "302\n",
      "CKA('batch_norm', 'dropout'): 0.24640930107014744\n",
      "303\n",
      "CKA('batch_norm', 'batch_norm'): 0.9900239506077751\n",
      "304\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9856083806039336\n",
      "305\n",
      "CKA('spatio_temporal', 'pool'): 0.09789335130414033\n",
      "306\n",
      "CKA('spatio_temporal', 'dropout'): 0.09789335130414033\n",
      "307\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.920275458117843\n",
      "308\n",
      "CKA('pool', 'spatio_temporal'): 0.10348302910703726\n",
      "309\n",
      "CKA('pool', 'pool'): 0.9782438920625401\n",
      "310\n",
      "CKA('pool', 'dropout'): 0.9782438920625401\n",
      "311\n",
      "CKA('pool', 'batch_norm'): 0.2514488591422823\n",
      "312\n",
      "CKA('dropout', 'spatio_temporal'): 0.10348302910703726\n",
      "313\n",
      "CKA('dropout', 'pool'): 0.9782438920625401\n",
      "314\n",
      "CKA('dropout', 'dropout'): 0.9782438920625401\n",
      "315\n",
      "CKA('dropout', 'batch_norm'): 0.2514488591422823\n",
      "316\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9553672997252773\n",
      "317\n",
      "CKA('batch_norm', 'pool'): 0.2448373378221497\n",
      "318\n",
      "CKA('batch_norm', 'dropout'): 0.2448373378221497\n",
      "319\n",
      "CKA('batch_norm', 'batch_norm'): 0.984081216200954\n",
      "320\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9793190816407393\n",
      "321\n",
      "CKA('spatio_temporal', 'pool'): 0.09677397115373192\n",
      "322\n",
      "CKA('spatio_temporal', 'dropout'): 0.09677397115373192\n",
      "323\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9123026978330059\n",
      "324\n",
      "CKA('pool', 'spatio_temporal'): 0.10419212622570767\n",
      "325\n",
      "CKA('pool', 'pool'): 0.9686160454691073\n",
      "326\n",
      "CKA('pool', 'dropout'): 0.9686160454691073\n",
      "327\n",
      "CKA('pool', 'batch_norm'): 0.25247591168735123\n",
      "328\n",
      "CKA('dropout', 'spatio_temporal'): 0.10419212622570767\n",
      "329\n",
      "CKA('dropout', 'pool'): 0.9686160454691073\n",
      "330\n",
      "CKA('dropout', 'dropout'): 0.9686160454691073\n",
      "331\n",
      "CKA('dropout', 'batch_norm'): 0.25247591168735123\n",
      "332\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9538987961145687\n",
      "333\n",
      "CKA('batch_norm', 'pool'): 0.24257108347573886\n",
      "334\n",
      "CKA('batch_norm', 'dropout'): 0.24257108347573886\n",
      "335\n",
      "CKA('batch_norm', 'batch_norm'): 0.978283495719271\n",
      "336\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9746817019726353\n",
      "337\n",
      "CKA('spatio_temporal', 'pool'): 0.0958926306241771\n",
      "338\n",
      "CKA('spatio_temporal', 'dropout'): 0.0958926306241771\n",
      "339\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9060475007028951\n",
      "340\n",
      "CKA('pool', 'spatio_temporal'): 0.10468378324502324\n",
      "341\n",
      "CKA('pool', 'pool'): 0.9614859621066669\n",
      "342\n",
      "CKA('pool', 'dropout'): 0.9614859621066669\n",
      "343\n",
      "CKA('pool', 'batch_norm'): 0.25347670635326\n",
      "344\n",
      "CKA('dropout', 'spatio_temporal'): 0.10468378324502324\n",
      "345\n",
      "CKA('dropout', 'pool'): 0.9614859621066669\n",
      "346\n",
      "CKA('dropout', 'dropout'): 0.9614859621066669\n",
      "347\n",
      "CKA('dropout', 'batch_norm'): 0.25347670635326\n",
      "348\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9529919704570755\n",
      "349\n",
      "CKA('batch_norm', 'pool'): 0.24077458376061506\n",
      "350\n",
      "CKA('batch_norm', 'dropout'): 0.24077458376061506\n",
      "351\n",
      "CKA('batch_norm', 'batch_norm'): 0.9731281830641638\n",
      "352\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9689937966435193\n",
      "353\n",
      "CKA('spatio_temporal', 'pool'): 0.0957659425667096\n",
      "354\n",
      "CKA('spatio_temporal', 'dropout'): 0.0957659425667096\n",
      "355\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8990292360652095\n",
      "356\n",
      "CKA('pool', 'spatio_temporal'): 0.10540809339460443\n",
      "357\n",
      "CKA('pool', 'pool'): 0.9520531151483245\n",
      "358\n",
      "CKA('pool', 'dropout'): 0.9520531151483245\n",
      "359\n",
      "CKA('pool', 'batch_norm'): 0.2533054484379539\n",
      "360\n",
      "CKA('dropout', 'spatio_temporal'): 0.10540809339460443\n",
      "361\n",
      "CKA('dropout', 'pool'): 0.9520531151483245\n",
      "362\n",
      "CKA('dropout', 'dropout'): 0.9520531151483245\n",
      "363\n",
      "CKA('dropout', 'batch_norm'): 0.2533054484379539\n",
      "364\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9515072701578134\n",
      "365\n",
      "CKA('batch_norm', 'pool'): 0.2395122478770404\n",
      "366\n",
      "CKA('batch_norm', 'dropout'): 0.2395122478770404\n",
      "367\n",
      "CKA('batch_norm', 'batch_norm'): 0.9677838641203245\n",
      "368\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9644210242794508\n",
      "369\n",
      "CKA('spatio_temporal', 'pool'): 0.09526921323525936\n",
      "370\n",
      "CKA('spatio_temporal', 'dropout'): 0.09526921323525936\n",
      "371\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.8932506136246127\n",
      "372\n",
      "CKA('pool', 'spatio_temporal'): 0.1055309803817079\n",
      "373\n",
      "CKA('pool', 'pool'): 0.9431079029399542\n",
      "374\n",
      "CKA('pool', 'dropout'): 0.9431079029399542\n",
      "375\n",
      "CKA('pool', 'batch_norm'): 0.2534992735934722\n",
      "376\n",
      "CKA('dropout', 'spatio_temporal'): 0.1055309803817079\n",
      "377\n",
      "CKA('dropout', 'pool'): 0.9431079029399542\n",
      "378\n",
      "CKA('dropout', 'dropout'): 0.9431079029399542\n",
      "379\n",
      "CKA('dropout', 'batch_norm'): 0.2534992735934722\n",
      "380\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9491318656620312\n",
      "381\n",
      "CKA('batch_norm', 'pool'): 0.23791730383583598\n",
      "382\n",
      "CKA('batch_norm', 'dropout'): 0.23791730383583598\n",
      "383\n",
      "CKA('batch_norm', 'batch_norm'): 0.9628507481727335\n",
      "384\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9976020198264749\n",
      "385\n",
      "CKA('spatio_temporal', 'pool'): 0.10069966881950454\n",
      "386\n",
      "CKA('spatio_temporal', 'dropout'): 0.10069966881950454\n",
      "387\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9405608192918063\n",
      "388\n",
      "CKA('pool', 'spatio_temporal'): 0.10267190251100498\n",
      "389\n",
      "CKA('pool', 'pool'): 0.9967440543742258\n",
      "390\n",
      "CKA('pool', 'dropout'): 0.9967440543742258\n",
      "391\n",
      "CKA('pool', 'batch_norm'): 0.2522925223753134\n",
      "392\n",
      "CKA('dropout', 'spatio_temporal'): 0.10267190251100498\n",
      "393\n",
      "CKA('dropout', 'pool'): 0.9967440543742258\n",
      "394\n",
      "CKA('dropout', 'dropout'): 0.9967440543742258\n",
      "395\n",
      "CKA('dropout', 'batch_norm'): 0.2522925223753134\n",
      "396\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9548785483803174\n",
      "397\n",
      "CKA('batch_norm', 'pool'): 0.2502372598557878\n",
      "398\n",
      "CKA('batch_norm', 'dropout'): 0.2502372598557878\n",
      "399\n",
      "CKA('batch_norm', 'batch_norm'): 0.9975200221170732\n",
      "400\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9945724321384841\n",
      "401\n",
      "CKA('spatio_temporal', 'pool'): 0.10012326443407507\n",
      "402\n",
      "CKA('spatio_temporal', 'dropout'): 0.10012326443407507\n",
      "403\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9344652858072613\n",
      "404\n",
      "CKA('pool', 'spatio_temporal'): 0.10338861852458407\n",
      "405\n",
      "CKA('pool', 'pool'): 0.9922835566981938\n",
      "406\n",
      "CKA('pool', 'dropout'): 0.9922835566981938\n",
      "407\n",
      "CKA('pool', 'batch_norm'): 0.2539890211729054\n",
      "408\n",
      "CKA('dropout', 'spatio_temporal'): 0.10338861852458407\n",
      "409\n",
      "CKA('dropout', 'pool'): 0.9922835566981938\n",
      "410\n",
      "CKA('dropout', 'dropout'): 0.9922835566981938\n",
      "411\n",
      "CKA('dropout', 'batch_norm'): 0.2539890211729054\n",
      "412\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9544420840745695\n",
      "413\n",
      "CKA('batch_norm', 'pool'): 0.24928105702545167\n",
      "414\n",
      "CKA('batch_norm', 'dropout'): 0.24928105702545167\n",
      "415\n",
      "CKA('batch_norm', 'batch_norm'): 0.9941926245836903\n",
      "416\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9904452814819067\n",
      "417\n",
      "CKA('spatio_temporal', 'pool'): 0.09906785948020384\n",
      "418\n",
      "CKA('spatio_temporal', 'dropout'): 0.09906785948020384\n",
      "419\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9279404828166661\n",
      "420\n",
      "CKA('pool', 'spatio_temporal'): 0.10418732576401948\n",
      "421\n",
      "CKA('pool', 'pool'): 0.9860612138658328\n",
      "422\n",
      "CKA('pool', 'dropout'): 0.9860612138658328\n",
      "423\n",
      "CKA('pool', 'batch_norm'): 0.2556413270702657\n",
      "424\n",
      "CKA('dropout', 'spatio_temporal'): 0.10418732576401948\n",
      "425\n",
      "CKA('dropout', 'pool'): 0.9860612138658328\n",
      "426\n",
      "CKA('dropout', 'dropout'): 0.9860612138658328\n",
      "427\n",
      "CKA('dropout', 'batch_norm'): 0.2556413270702657\n",
      "428\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.954779224504958\n",
      "429\n",
      "CKA('batch_norm', 'pool'): 0.2475688905431297\n",
      "430\n",
      "CKA('batch_norm', 'dropout'): 0.2475688905431297\n",
      "431\n",
      "CKA('batch_norm', 'batch_norm'): 0.9902906159670093\n",
      "432\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9870640577670201\n",
      "433\n",
      "CKA('spatio_temporal', 'pool'): 0.09820021118626132\n",
      "434\n",
      "CKA('spatio_temporal', 'dropout'): 0.09820021118626132\n",
      "435\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9226155755101859\n",
      "436\n",
      "CKA('pool', 'spatio_temporal'): 0.10472929717727557\n",
      "437\n",
      "CKA('pool', 'pool'): 0.980936086297225\n",
      "438\n",
      "CKA('pool', 'dropout'): 0.980936086297225\n",
      "439\n",
      "CKA('pool', 'batch_norm'): 0.25702688564774084\n",
      "440\n",
      "CKA('dropout', 'spatio_temporal'): 0.10472929717727557\n",
      "441\n",
      "CKA('dropout', 'pool'): 0.980936086297225\n",
      "442\n",
      "CKA('dropout', 'dropout'): 0.980936086297225\n",
      "443\n",
      "CKA('dropout', 'batch_norm'): 0.25702688564774084\n",
      "444\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9550644970514958\n",
      "445\n",
      "CKA('batch_norm', 'pool'): 0.24609494558912\n",
      "446\n",
      "CKA('batch_norm', 'dropout'): 0.24609494558912\n",
      "447\n",
      "CKA('batch_norm', 'batch_norm'): 0.9864212791622973\n",
      "448\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9826509300408138\n",
      "449\n",
      "CKA('spatio_temporal', 'pool'): 0.09811725867253594\n",
      "450\n",
      "CKA('spatio_temporal', 'dropout'): 0.09811725867253594\n",
      "451\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9164220837865257\n",
      "452\n",
      "CKA('pool', 'spatio_temporal'): 0.10550560496271032\n",
      "453\n",
      "CKA('pool', 'pool'): 0.9738622754544184\n",
      "454\n",
      "CKA('pool', 'dropout'): 0.9738622754544184\n",
      "455\n",
      "CKA('pool', 'batch_norm'): 0.2572818866131634\n",
      "456\n",
      "CKA('dropout', 'spatio_temporal'): 0.10550560496271032\n",
      "457\n",
      "CKA('dropout', 'pool'): 0.9738622754544184\n",
      "458\n",
      "CKA('dropout', 'dropout'): 0.9738622754544184\n",
      "459\n",
      "CKA('dropout', 'batch_norm'): 0.2572818866131634\n",
      "460\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9548847957998147\n",
      "461\n",
      "CKA('batch_norm', 'pool'): 0.24521789981097336\n",
      "462\n",
      "CKA('batch_norm', 'dropout'): 0.24521789981097336\n",
      "463\n",
      "CKA('batch_norm', 'batch_norm'): 0.9823263731697454\n",
      "464\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9790303575031828\n",
      "465\n",
      "CKA('spatio_temporal', 'pool'): 0.0976716675403724\n",
      "466\n",
      "CKA('spatio_temporal', 'dropout'): 0.0976716675403724\n",
      "467\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9114012892914976\n",
      "468\n",
      "CKA('pool', 'spatio_temporal'): 0.1056818785709867\n",
      "469\n",
      "CKA('pool', 'pool'): 0.966915240336928\n",
      "470\n",
      "CKA('pool', 'dropout'): 0.966915240336928\n",
      "471\n",
      "CKA('pool', 'batch_norm'): 0.25786171265139957\n",
      "472\n",
      "CKA('dropout', 'spatio_temporal'): 0.1056818785709867\n",
      "473\n",
      "CKA('dropout', 'pool'): 0.966915240336928\n",
      "474\n",
      "CKA('dropout', 'dropout'): 0.966915240336928\n",
      "475\n",
      "CKA('dropout', 'batch_norm'): 0.25786171265139957\n",
      "476\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9533481884829413\n",
      "477\n",
      "CKA('batch_norm', 'pool'): 0.24395921381117103\n",
      "478\n",
      "CKA('batch_norm', 'dropout'): 0.24395921381117103\n",
      "479\n",
      "CKA('batch_norm', 'batch_norm'): 0.9782844950303169\n",
      "480\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9985302720824829\n",
      "481\n",
      "CKA('spatio_temporal', 'pool'): 0.10165993139502076\n",
      "482\n",
      "CKA('spatio_temporal', 'dropout'): 0.10165993139502076\n",
      "483\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9445002641815906\n",
      "484\n",
      "CKA('pool', 'spatio_temporal'): 0.10296072897395993\n",
      "485\n",
      "CKA('pool', 'pool'): 0.9982369800025095\n",
      "486\n",
      "CKA('pool', 'dropout'): 0.9982369800025095\n",
      "487\n",
      "CKA('pool', 'batch_norm'): 0.2549290596173163\n",
      "488\n",
      "CKA('dropout', 'spatio_temporal'): 0.10296072897395993\n",
      "489\n",
      "CKA('dropout', 'pool'): 0.9982369800025095\n",
      "490\n",
      "CKA('dropout', 'dropout'): 0.9982369800025095\n",
      "491\n",
      "CKA('dropout', 'batch_norm'): 0.2549290596173163\n",
      "492\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.950215721078396\n",
      "493\n",
      "CKA('batch_norm', 'pool'): 0.25225978492924683\n",
      "494\n",
      "CKA('batch_norm', 'dropout'): 0.25225978492924683\n",
      "495\n",
      "CKA('batch_norm', 'batch_norm'): 0.9983392373953317\n",
      "496\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.996296606298696\n",
      "497\n",
      "CKA('spatio_temporal', 'pool'): 0.10066709273302211\n",
      "498\n",
      "CKA('spatio_temporal', 'dropout'): 0.10066709273302211\n",
      "499\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9392083815648069\n",
      "500\n",
      "CKA('pool', 'spatio_temporal'): 0.10383584581967713\n",
      "501\n",
      "CKA('pool', 'pool'): 0.9950128519892897\n",
      "502\n",
      "CKA('pool', 'dropout'): 0.9950128519892897\n",
      "503\n",
      "CKA('pool', 'batch_norm'): 0.2571115701040783\n",
      "504\n",
      "CKA('dropout', 'spatio_temporal'): 0.10383584581967713\n",
      "505\n",
      "CKA('dropout', 'pool'): 0.9950128519892897\n",
      "506\n",
      "CKA('dropout', 'dropout'): 0.9950128519892897\n",
      "507\n",
      "CKA('dropout', 'batch_norm'): 0.2571115701040783\n",
      "508\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9520337242755433\n",
      "509\n",
      "CKA('batch_norm', 'pool'): 0.2510319363218041\n",
      "510\n",
      "CKA('batch_norm', 'dropout'): 0.2510319363218041\n",
      "511\n",
      "CKA('batch_norm', 'batch_norm'): 0.9961171989704233\n",
      "512\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.994095926708637\n",
      "513\n",
      "CKA('spatio_temporal', 'pool'): 0.0998141413914546\n",
      "514\n",
      "CKA('spatio_temporal', 'dropout'): 0.0998141413914546\n",
      "515\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9347470674360888\n",
      "516\n",
      "CKA('pool', 'spatio_temporal'): 0.10443162415601236\n",
      "517\n",
      "CKA('pool', 'pool'): 0.991729362593588\n",
      "518\n",
      "CKA('pool', 'dropout'): 0.991729362593588\n",
      "519\n",
      "CKA('pool', 'batch_norm'): 0.2588371002941339\n",
      "520\n",
      "CKA('dropout', 'spatio_temporal'): 0.10443162415601236\n",
      "521\n",
      "CKA('dropout', 'pool'): 0.991729362593588\n",
      "522\n",
      "CKA('dropout', 'dropout'): 0.991729362593588\n",
      "523\n",
      "CKA('dropout', 'batch_norm'): 0.2588371002941339\n",
      "524\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9534048932695757\n",
      "525\n",
      "CKA('batch_norm', 'pool'): 0.2498493088112519\n",
      "526\n",
      "CKA('batch_norm', 'dropout'): 0.2498493088112519\n",
      "527\n",
      "CKA('batch_norm', 'batch_norm'): 0.9936024486815925\n",
      "528\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9911179771475601\n",
      "529\n",
      "CKA('spatio_temporal', 'pool'): 0.09978948332419986\n",
      "530\n",
      "CKA('spatio_temporal', 'dropout'): 0.09978948332419986\n",
      "531\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9294510099470265\n",
      "532\n",
      "CKA('pool', 'spatio_temporal'): 0.10526300457911913\n",
      "533\n",
      "CKA('pool', 'pool'): 0.9868590659904478\n",
      "534\n",
      "CKA('pool', 'dropout'): 0.9868590659904478\n",
      "535\n",
      "CKA('pool', 'batch_norm'): 0.2594796473505844\n",
      "536\n",
      "CKA('dropout', 'spatio_temporal'): 0.10526300457911913\n",
      "537\n",
      "CKA('dropout', 'pool'): 0.9868590659904478\n",
      "538\n",
      "CKA('dropout', 'dropout'): 0.9868590659904478\n",
      "539\n",
      "CKA('dropout', 'batch_norm'): 0.2594796473505844\n",
      "540\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9544020035130208\n",
      "541\n",
      "CKA('batch_norm', 'pool'): 0.24933225800078015\n",
      "542\n",
      "CKA('batch_norm', 'dropout'): 0.24933225800078015\n",
      "543\n",
      "CKA('batch_norm', 'batch_norm'): 0.990618340139231\n",
      "544\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.988320428499012\n",
      "545\n",
      "CKA('spatio_temporal', 'pool'): 0.09939243226014774\n",
      "546\n",
      "CKA('spatio_temporal', 'dropout'): 0.09939243226014774\n",
      "547\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9251224525674688\n",
      "548\n",
      "CKA('pool', 'spatio_temporal'): 0.1054912078060223\n",
      "549\n",
      "CKA('pool', 'pool'): 0.9816437495671229\n",
      "550\n",
      "CKA('pool', 'dropout'): 0.9816437495671229\n",
      "551\n",
      "CKA('pool', 'batch_norm'): 0.26038482958014536\n",
      "552\n",
      "CKA('dropout', 'spatio_temporal'): 0.1054912078060223\n",
      "553\n",
      "CKA('dropout', 'pool'): 0.9816437495671229\n",
      "554\n",
      "CKA('dropout', 'dropout'): 0.9816437495671229\n",
      "555\n",
      "CKA('dropout', 'batch_norm'): 0.26038482958014536\n",
      "556\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9535804507679488\n",
      "557\n",
      "CKA('batch_norm', 'pool'): 0.24836226770321823\n",
      "558\n",
      "CKA('batch_norm', 'dropout'): 0.24836226770321823\n",
      "559\n",
      "CKA('batch_norm', 'batch_norm'): 0.9874190008741759\n",
      "560\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.998721957769577\n",
      "561\n",
      "CKA('spatio_temporal', 'pool'): 0.10156018169817334\n",
      "562\n",
      "CKA('spatio_temporal', 'dropout'): 0.10156018169817334\n",
      "563\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9430574654763225\n",
      "564\n",
      "CKA('pool', 'spatio_temporal'): 0.1034275372308564\n",
      "565\n",
      "CKA('pool', 'pool'): 0.9984271337526073\n",
      "566\n",
      "CKA('pool', 'dropout'): 0.9984271337526073\n",
      "567\n",
      "CKA('pool', 'batch_norm'): 0.2574649890144074\n",
      "568\n",
      "CKA('dropout', 'spatio_temporal'): 0.1034275372308564\n",
      "569\n",
      "CKA('dropout', 'pool'): 0.9984271337526073\n",
      "570\n",
      "CKA('dropout', 'dropout'): 0.9984271337526073\n",
      "571\n",
      "CKA('dropout', 'batch_norm'): 0.2574649890144074\n",
      "572\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9501266107837782\n",
      "573\n",
      "CKA('batch_norm', 'pool'): 0.25403319964612\n",
      "574\n",
      "CKA('batch_norm', 'dropout'): 0.25403319964612\n",
      "575\n",
      "CKA('batch_norm', 'batch_norm'): 0.9986437431013531\n",
      "576\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9973060590567948\n",
      "577\n",
      "CKA('spatio_temporal', 'pool'): 0.10072468914420837\n",
      "578\n",
      "CKA('spatio_temporal', 'dropout'): 0.10072468914420837\n",
      "579\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.939306631413227\n",
      "580\n",
      "CKA('pool', 'spatio_temporal'): 0.10405132095074342\n",
      "581\n",
      "CKA('pool', 'pool'): 0.9964437664855803\n",
      "582\n",
      "CKA('pool', 'dropout'): 0.9964437664855803\n",
      "583\n",
      "CKA('pool', 'batch_norm'): 0.25941961337731456\n",
      "584\n",
      "CKA('dropout', 'spatio_temporal'): 0.10405132095074342\n",
      "585\n",
      "CKA('dropout', 'pool'): 0.9964437664855803\n",
      "586\n",
      "CKA('dropout', 'dropout'): 0.9964437664855803\n",
      "587\n",
      "CKA('dropout', 'batch_norm'): 0.25941961337731456\n",
      "588\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9522215083421988\n",
      "589\n",
      "CKA('batch_norm', 'pool'): 0.25305911711213636\n",
      "590\n",
      "CKA('batch_norm', 'dropout'): 0.25305911711213636\n",
      "591\n",
      "CKA('batch_norm', 'batch_norm'): 0.997074561606257\n",
      "592\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9951643435027225\n",
      "593\n",
      "CKA('spatio_temporal', 'pool'): 0.10073418626489686\n",
      "594\n",
      "CKA('spatio_temporal', 'dropout'): 0.10073418626489686\n",
      "595\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9346519787744536\n",
      "596\n",
      "CKA('pool', 'spatio_temporal'): 0.1049102931426156\n",
      "597\n",
      "CKA('pool', 'pool'): 0.9931512583514998\n",
      "598\n",
      "CKA('pool', 'dropout'): 0.9931512583514998\n",
      "599\n",
      "CKA('pool', 'batch_norm'): 0.2603335922506581\n",
      "600\n",
      "CKA('dropout', 'spatio_temporal'): 0.1049102931426156\n",
      "601\n",
      "CKA('dropout', 'pool'): 0.9931512583514998\n",
      "602\n",
      "CKA('dropout', 'dropout'): 0.9931512583514998\n",
      "603\n",
      "CKA('dropout', 'batch_norm'): 0.2603335922506581\n",
      "604\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9539248038373513\n",
      "605\n",
      "CKA('batch_norm', 'pool'): 0.25279538621613595\n",
      "606\n",
      "CKA('batch_norm', 'dropout'): 0.25279538621613595\n",
      "607\n",
      "CKA('batch_norm', 'batch_norm'): 0.9950517741572615\n",
      "608\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9930808312017484\n",
      "609\n",
      "CKA('spatio_temporal', 'pool'): 0.10036087253492454\n",
      "610\n",
      "CKA('spatio_temporal', 'dropout'): 0.10036087253492454\n",
      "611\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.930945603892723\n",
      "612\n",
      "CKA('pool', 'spatio_temporal'): 0.10516543393479011\n",
      "613\n",
      "CKA('pool', 'pool'): 0.9893216067393639\n",
      "614\n",
      "CKA('pool', 'dropout'): 0.9893216067393639\n",
      "615\n",
      "CKA('pool', 'batch_norm'): 0.2614839901804629\n",
      "616\n",
      "CKA('dropout', 'spatio_temporal'): 0.10516543393479011\n",
      "617\n",
      "CKA('dropout', 'pool'): 0.9893216067393639\n",
      "618\n",
      "CKA('dropout', 'dropout'): 0.9893216067393639\n",
      "619\n",
      "CKA('dropout', 'batch_norm'): 0.2614839901804629\n",
      "620\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9537055723390536\n",
      "621\n",
      "CKA('batch_norm', 'pool'): 0.25204249051881034\n",
      "622\n",
      "CKA('batch_norm', 'dropout'): 0.25204249051881034\n",
      "623\n",
      "CKA('batch_norm', 'batch_norm'): 0.9926973593453186\n",
      "624\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9989607569250591\n",
      "625\n",
      "CKA('spatio_temporal', 'pool'): 0.10170194375346137\n",
      "626\n",
      "CKA('spatio_temporal', 'dropout'): 0.10170194375346137\n",
      "627\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9438831835550366\n",
      "628\n",
      "CKA('pool', 'spatio_temporal'): 0.1031674567905382\n",
      "629\n",
      "CKA('pool', 'pool'): 0.9989290353345092\n",
      "630\n",
      "CKA('pool', 'dropout'): 0.9989290353345092\n",
      "631\n",
      "CKA('pool', 'batch_norm'): 0.2591284912719221\n",
      "632\n",
      "CKA('dropout', 'spatio_temporal'): 0.1031674567905382\n",
      "633\n",
      "CKA('dropout', 'pool'): 0.9989290353345092\n",
      "634\n",
      "CKA('dropout', 'dropout'): 0.9989290353345092\n",
      "635\n",
      "CKA('dropout', 'batch_norm'): 0.2591284912719221\n",
      "636\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.949747061508594\n",
      "637\n",
      "CKA('batch_norm', 'pool'): 0.25619450612799705\n",
      "638\n",
      "CKA('batch_norm', 'dropout'): 0.25619450612799705\n",
      "639\n",
      "CKA('batch_norm', 'batch_norm'): 0.9987914240618981\n",
      "640\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9977336819748265\n",
      "641\n",
      "CKA('spatio_temporal', 'pool'): 0.10174416398530522\n",
      "642\n",
      "CKA('spatio_temporal', 'dropout'): 0.10174416398530522\n",
      "643\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9398125623886125\n",
      "644\n",
      "CKA('pool', 'spatio_temporal'): 0.10405033664338013\n",
      "645\n",
      "CKA('pool', 'pool'): 0.9970922482528867\n",
      "646\n",
      "CKA('pool', 'dropout'): 0.9970922482528867\n",
      "647\n",
      "CKA('pool', 'batch_norm'): 0.26028662330467406\n",
      "648\n",
      "CKA('dropout', 'spatio_temporal'): 0.10405033664338013\n",
      "649\n",
      "CKA('dropout', 'pool'): 0.9970922482528867\n",
      "650\n",
      "CKA('dropout', 'dropout'): 0.9970922482528867\n",
      "651\n",
      "CKA('dropout', 'batch_norm'): 0.26028662330467406\n",
      "652\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9520841861094603\n",
      "653\n",
      "CKA('batch_norm', 'pool'): 0.2561675162853676\n",
      "654\n",
      "CKA('batch_norm', 'dropout'): 0.2561675162853676\n",
      "655\n",
      "CKA('batch_norm', 'batch_norm'): 0.9976072521326447\n",
      "656\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9964263188620388\n",
      "657\n",
      "CKA('spatio_temporal', 'pool'): 0.10140182336713716\n",
      "658\n",
      "CKA('spatio_temporal', 'dropout'): 0.10140182336713716\n",
      "659\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.936715793631959\n",
      "660\n",
      "CKA('pool', 'spatio_temporal'): 0.10433410079103327\n",
      "661\n",
      "CKA('pool', 'pool'): 0.9945994810432263\n",
      "662\n",
      "CKA('pool', 'dropout'): 0.9945994810432263\n",
      "663\n",
      "CKA('pool', 'batch_norm'): 0.2616715303033815\n",
      "664\n",
      "CKA('dropout', 'spatio_temporal'): 0.10433410079103327\n",
      "665\n",
      "CKA('dropout', 'pool'): 0.9945994810432263\n",
      "666\n",
      "CKA('dropout', 'dropout'): 0.9945994810432263\n",
      "667\n",
      "CKA('dropout', 'batch_norm'): 0.2616715303033815\n",
      "668\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9524694608868938\n",
      "669\n",
      "CKA('batch_norm', 'pool'): 0.25563825906078225\n",
      "670\n",
      "CKA('batch_norm', 'dropout'): 0.25563825906078225\n",
      "671\n",
      "CKA('batch_norm', 'batch_norm'): 0.9960235974470318\n",
      "672\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9989815695414433\n",
      "673\n",
      "CKA('spatio_temporal', 'pool'): 0.10244207709068223\n",
      "674\n",
      "CKA('spatio_temporal', 'dropout'): 0.10244207709068223\n",
      "675\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9438249916739951\n",
      "676\n",
      "CKA('pool', 'spatio_temporal'): 0.10326379926828994\n",
      "677\n",
      "CKA('pool', 'pool'): 0.9986963572871002\n",
      "678\n",
      "CKA('pool', 'dropout'): 0.9986963572871002\n",
      "679\n",
      "CKA('pool', 'batch_norm'): 0.2599067000350374\n",
      "680\n",
      "CKA('dropout', 'spatio_temporal'): 0.10326379926828994\n",
      "681\n",
      "CKA('dropout', 'pool'): 0.9986963572871002\n",
      "682\n",
      "CKA('dropout', 'dropout'): 0.9986963572871002\n",
      "683\n",
      "CKA('dropout', 'batch_norm'): 0.2599067000350374\n",
      "684\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.950232355133316\n",
      "685\n",
      "CKA('batch_norm', 'pool'): 0.2587201297530737\n",
      "686\n",
      "CKA('batch_norm', 'dropout'): 0.2587201297530737\n",
      "687\n",
      "CKA('batch_norm', 'batch_norm'): 0.9988851675017427\n",
      "688\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9982172679445016\n",
      "689\n",
      "CKA('spatio_temporal', 'pool'): 0.10211466867268852\n",
      "690\n",
      "CKA('spatio_temporal', 'dropout'): 0.10211466867268852\n",
      "691\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9411300314382511\n",
      "692\n",
      "CKA('pool', 'spatio_temporal'): 0.10356152898564859\n",
      "693\n",
      "CKA('pool', 'pool'): 0.9971157943472039\n",
      "694\n",
      "CKA('pool', 'dropout'): 0.9971157943472039\n",
      "695\n",
      "CKA('pool', 'batch_norm'): 0.26144599201751906\n",
      "696\n",
      "CKA('dropout', 'spatio_temporal'): 0.10356152898564859\n",
      "697\n",
      "CKA('dropout', 'pool'): 0.9971157943472039\n",
      "698\n",
      "CKA('dropout', 'dropout'): 0.9971157943472039\n",
      "699\n",
      "CKA('dropout', 'batch_norm'): 0.26144599201751906\n",
      "700\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9510404829764678\n",
      "701\n",
      "CKA('batch_norm', 'pool'): 0.2583353281970836\n",
      "702\n",
      "CKA('batch_norm', 'dropout'): 0.2583353281970836\n",
      "703\n",
      "CKA('batch_norm', 'batch_norm'): 0.9979209465875581\n",
      "704\n",
      "CKA('spatio_temporal', 'spatio_temporal'): 0.9992441859079908\n",
      "705\n",
      "CKA('spatio_temporal', 'pool'): 0.10305408438493616\n",
      "706\n",
      "CKA('spatio_temporal', 'dropout'): 0.10305408438493616\n",
      "707\n",
      "CKA('spatio_temporal', 'batch_norm'): 0.9450851305045664\n",
      "708\n",
      "CKA('pool', 'spatio_temporal'): 0.10367991318509807\n",
      "709\n",
      "CKA('pool', 'pool'): 0.9988515110050131\n",
      "710\n",
      "CKA('pool', 'dropout'): 0.9988515110050131\n",
      "711\n",
      "CKA('pool', 'batch_norm'): 0.2620122424464485\n",
      "712\n",
      "CKA('dropout', 'spatio_temporal'): 0.10367991318509807\n",
      "713\n",
      "CKA('dropout', 'pool'): 0.9988515110050131\n",
      "714\n",
      "CKA('dropout', 'dropout'): 0.9988515110050131\n",
      "715\n",
      "CKA('dropout', 'batch_norm'): 0.2620122424464485\n",
      "716\n",
      "CKA('batch_norm', 'spatio_temporal'): 0.9485810658637267\n",
      "717\n",
      "CKA('batch_norm', 'pool'): 0.26008430122087506\n",
      "718\n",
      "CKA('batch_norm', 'dropout'): 0.26008430122087506\n",
      "719\n",
      "CKA('batch_norm', 'batch_norm'): 0.9989857646302956\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "kernel_list = [model_1_kernels, model_2_kernels, model_3_kernels, model_4_kernels,\n",
    "               model_5_kernels, model_6_kernels, model_7_kernels, model_8_kernels,\n",
    "               model_9_kernels, model_10_kernels]\n",
    "\n",
    "cka_results = OrderedDict()\n",
    "\n",
    "def compute_cka_pair(layer1, K_x, layer2, K_y):\n",
    "    cka_value = compute_CKA(K_x, K_y)\n",
    "    return (layer1, layer2), cka_value\n",
    "\n",
    "# Parallel computation\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for i, kernel_1 in enumerate(kernel_list):\n",
    "        print(\"Kernel so far: \", i)\n",
    "        for j, kernel_2 in enumerate(kernel_list[i+1:], start=i+1):  # Avoid repeated pairs\n",
    "            for layer1, K_x in kernel_1.items():\n",
    "                for layer2, K_y in kernel_2.items():\n",
    "                    futures.append(executor.submit(compute_cka_pair, layer1, K_x, layer2, K_y))\n",
    "\n",
    "    for i, future in enumerate(futures):\n",
    "        print(i)\n",
    "        pair, cka_value = future.result()\n",
    "        cka_results[pair] = cka_value\n",
    "        print(f\"CKA{pair}: {cka_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future at 0x118ad5744c0 state=finished returned tuple>,\n",
       " <Future at 0x11889903430 state=finished returned tuple>,\n",
       " <Future at 0x1194bec8d60 state=finished returned tuple>,\n",
       " <Future at 0x1194be98c70 state=finished returned tuple>,\n",
       " <Future at 0x1194beaa3b0 state=finished returned tuple>,\n",
       " <Future at 0x1194bebbdc0 state=finished returned tuple>,\n",
       " <Future at 0x1194beb8b80 state=finished returned tuple>,\n",
       " <Future at 0x1194bedd7e0 state=finished returned tuple>,\n",
       " <Future at 0x11891729bd0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf0d0f0 state=finished returned tuple>,\n",
       " <Future at 0x118c6e10a30 state=finished returned tuple>,\n",
       " <Future at 0x118916a9b70 state=finished returned tuple>,\n",
       " <Future at 0x118916abfa0 state=finished returned tuple>,\n",
       " <Future at 0x118916ab010 state=finished returned tuple>,\n",
       " <Future at 0x118916aa380 state=finished returned tuple>,\n",
       " <Future at 0x118916a9d20 state=finished returned tuple>,\n",
       " <Future at 0x118916a9390 state=finished returned tuple>,\n",
       " <Future at 0x118916a9210 state=finished returned tuple>,\n",
       " <Future at 0x118916a8dc0 state=finished returned tuple>,\n",
       " <Future at 0x118916a8be0 state=finished returned tuple>,\n",
       " <Future at 0x118916a9750 state=finished returned tuple>,\n",
       " <Future at 0x118916a97e0 state=finished returned tuple>,\n",
       " <Future at 0x118916a9870 state=finished returned tuple>,\n",
       " <Future at 0x118916a9990 state=finished returned tuple>,\n",
       " <Future at 0x118916aada0 state=finished returned tuple>,\n",
       " <Future at 0x118916abd00 state=finished returned tuple>,\n",
       " <Future at 0x118916a9b40 state=finished returned tuple>,\n",
       " <Future at 0x1194be6a800 state=finished returned tuple>,\n",
       " <Future at 0x1194be69bd0 state=finished returned tuple>,\n",
       " <Future at 0x1194be68460 state=finished returned tuple>,\n",
       " <Future at 0x1194be68280 state=finished returned tuple>,\n",
       " <Future at 0x1194be6b700 state=finished returned tuple>,\n",
       " <Future at 0x1194be69a50 state=finished returned tuple>,\n",
       " <Future at 0x118916819f0 state=finished returned tuple>,\n",
       " <Future at 0x11891681570 state=finished returned tuple>,\n",
       " <Future at 0x11891681870 state=finished returned tuple>,\n",
       " <Future at 0x118916816c0 state=finished returned tuple>,\n",
       " <Future at 0x11891681ea0 state=finished returned tuple>,\n",
       " <Future at 0x11891681f60 state=finished returned tuple>,\n",
       " <Future at 0x11891681fc0 state=finished returned tuple>,\n",
       " <Future at 0x11891682290 state=finished returned tuple>,\n",
       " <Future at 0x118916821a0 state=finished returned tuple>,\n",
       " <Future at 0x118916823b0 state=finished returned tuple>,\n",
       " <Future at 0x11891682410 state=finished returned tuple>,\n",
       " <Future at 0x118916822c0 state=finished returned tuple>,\n",
       " <Future at 0x11891682890 state=finished returned tuple>,\n",
       " <Future at 0x11891682b00 state=finished returned tuple>,\n",
       " <Future at 0x11891682b30 state=finished returned tuple>,\n",
       " <Future at 0x11891682ce0 state=finished returned tuple>,\n",
       " <Future at 0x11891682e30 state=finished returned tuple>,\n",
       " <Future at 0x11891682ec0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0ba00 state=finished returned tuple>,\n",
       " <Future at 0x1188be097e0 state=finished returned tuple>,\n",
       " <Future at 0x1188be098d0 state=finished returned tuple>,\n",
       " <Future at 0x1188be09a20 state=finished returned tuple>,\n",
       " <Future at 0x1188be09ae0 state=finished returned tuple>,\n",
       " <Future at 0x1188be09ba0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0bfd0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0a980 state=finished returned tuple>,\n",
       " <Future at 0x1188be0aa40 state=finished returned tuple>,\n",
       " <Future at 0x1188be0a650 state=finished returned tuple>,\n",
       " <Future at 0x1188be0a4d0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0a3e0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0a320 state=finished returned tuple>,\n",
       " <Future at 0x1188be0ba60 state=finished returned tuple>,\n",
       " <Future at 0x1188be0bb20 state=finished returned tuple>,\n",
       " <Future at 0x1188be0bee0 state=finished returned tuple>,\n",
       " <Future at 0x1188be09270 state=finished returned tuple>,\n",
       " <Future at 0x1188be09330 state=finished returned tuple>,\n",
       " <Future at 0x1188be08160 state=finished returned tuple>,\n",
       " <Future at 0x1188be080d0 state=finished returned tuple>,\n",
       " <Future at 0x1188be080a0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0ad10 state=finished returned tuple>,\n",
       " <Future at 0x1188be0ae30 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b070 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b040 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b100 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b1c0 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b280 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b340 state=finished returned tuple>,\n",
       " <Future at 0x1188be0b400 state=finished returned tuple>,\n",
       " <Future at 0x11891655480 state=finished returned tuple>,\n",
       " <Future at 0x11891655c30 state=finished returned tuple>,\n",
       " <Future at 0x11891655660 state=finished returned tuple>,\n",
       " <Future at 0x11891657eb0 state=finished returned tuple>,\n",
       " <Future at 0x11891655b10 state=finished returned tuple>,\n",
       " <Future at 0x11891657940 state=finished returned tuple>,\n",
       " <Future at 0x118916554e0 state=finished returned tuple>,\n",
       " <Future at 0x11891656e30 state=finished returned tuple>,\n",
       " <Future at 0x11891657730 state=finished returned tuple>,\n",
       " <Future at 0x11891655930 state=finished returned tuple>,\n",
       " <Future at 0x11891657880 state=finished returned tuple>,\n",
       " <Future at 0x11891654fa0 state=finished returned tuple>,\n",
       " <Future at 0x11891655570 state=finished returned tuple>,\n",
       " <Future at 0x11891657310 state=finished returned tuple>,\n",
       " <Future at 0x118916576d0 state=finished returned tuple>,\n",
       " <Future at 0x118916fc910 state=finished returned tuple>,\n",
       " <Future at 0x118916fc970 state=finished returned tuple>,\n",
       " <Future at 0x118916fcaf0 state=finished returned tuple>,\n",
       " <Future at 0x118916fcc40 state=finished returned tuple>,\n",
       " <Future at 0x118916fcd00 state=finished returned tuple>,\n",
       " <Future at 0x118916fcdc0 state=finished returned tuple>,\n",
       " <Future at 0x118916fce80 state=finished returned tuple>,\n",
       " <Future at 0x118916fcf40 state=finished returned tuple>,\n",
       " <Future at 0x118916fd000 state=finished returned tuple>,\n",
       " <Future at 0x118916fd0c0 state=finished returned tuple>,\n",
       " <Future at 0x118916fd180 state=finished returned tuple>,\n",
       " <Future at 0x118916fd240 state=finished returned tuple>,\n",
       " <Future at 0x118916fd300 state=finished returned tuple>,\n",
       " <Future at 0x118916fd3c0 state=finished returned tuple>,\n",
       " <Future at 0x118916fd480 state=finished returned tuple>,\n",
       " <Future at 0x118916fd600 state=finished returned tuple>,\n",
       " <Future at 0x118916fd6c0 state=finished returned tuple>,\n",
       " <Future at 0x118916fd780 state=finished returned tuple>,\n",
       " <Future at 0x118916fd840 state=finished returned tuple>,\n",
       " <Future at 0x118916fd900 state=finished returned tuple>,\n",
       " <Future at 0x118916fd9c0 state=finished returned tuple>,\n",
       " <Future at 0x118916fda80 state=finished returned tuple>,\n",
       " <Future at 0x118916fdb40 state=finished returned tuple>,\n",
       " <Future at 0x118916fdc00 state=finished returned tuple>,\n",
       " <Future at 0x118916fdcc0 state=finished returned tuple>,\n",
       " <Future at 0x118916fde70 state=finished returned tuple>,\n",
       " <Future at 0x118916fdf00 state=finished returned tuple>,\n",
       " <Future at 0x118916fdfc0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe080 state=finished returned tuple>,\n",
       " <Future at 0x118916fe1a0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe4d0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe4a0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe7a0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe8c0 state=finished returned tuple>,\n",
       " <Future at 0x118916fe9b0 state=finished returned tuple>,\n",
       " <Future at 0x118916feb00 state=finished returned tuple>,\n",
       " <Future at 0x118916fec20 state=finished returned tuple>,\n",
       " <Future at 0x118916fece0 state=finished returned tuple>,\n",
       " <Future at 0x118916feda0 state=finished returned tuple>,\n",
       " <Future at 0x118916fee60 state=finished returned tuple>,\n",
       " <Future at 0x118916fef20 state=finished returned tuple>,\n",
       " <Future at 0x118916fefe0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff0a0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff160 state=finished returned tuple>,\n",
       " <Future at 0x118916ff220 state=finished returned tuple>,\n",
       " <Future at 0x118916ff2e0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff3d0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff520 state=finished returned tuple>,\n",
       " <Future at 0x118916ff5e0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff6a0 state=finished returned tuple>,\n",
       " <Future at 0x118916ff760 state=finished returned tuple>,\n",
       " <Future at 0x118916ff820 state=finished returned tuple>,\n",
       " <Future at 0x118ad59c700 state=finished returned tuple>,\n",
       " <Future at 0x118ad59cac0 state=finished returned tuple>,\n",
       " <Future at 0x118ad59ed10 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f310 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f3d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f490 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f550 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f610 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f6d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f790 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f850 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f910 state=finished returned tuple>,\n",
       " <Future at 0x118ad59f9d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad59fb20 state=finished returned tuple>,\n",
       " <Future at 0x118ad59fc10 state=finished returned tuple>,\n",
       " <Future at 0x118ad59fcd0 state=finished returned tuple>,\n",
       " <Future at 0x118ad59fdf0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c40d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4370 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4280 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4520 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4640 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4790 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c48b0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4970 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4a30 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4af0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4bb0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4c70 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4d30 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4df0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4eb0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c4f70 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5030 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c50f0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5270 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5330 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c53f0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5540 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5570 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5630 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c56f0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c57b0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5870 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5930 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c59f0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5b70 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5c30 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5d20 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c5ea0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6290 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c61d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6470 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6560 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6680 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c67d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6890 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6950 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6a10 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6ad0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6b90 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6c50 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6d10 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6dd0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6e90 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6f50 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c6fe0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7190 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7250 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7310 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c73d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7490 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7550 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7610 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c76d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7790 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7850 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7910 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7a60 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7b50 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7c10 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7d30 state=finished returned tuple>,\n",
       " <Future at 0x118ad5c7fd0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ef550 state=finished returned tuple>,\n",
       " <Future at 0x118ad5edae0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec0d0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec0a0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec3a0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec4c0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec5b0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec700 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec820 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec8e0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ec9a0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5eca60 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecb20 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecbe0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecca0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecd60 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ece20 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecee0 state=finished returned tuple>,\n",
       " <Future at 0x118ad5ecfd0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346620 state=finished returned tuple>,\n",
       " <Future at 0x118c83466e0 state=finished returned tuple>,\n",
       " <Future at 0x118c83467a0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346860 state=finished returned tuple>,\n",
       " <Future at 0x118c8346920 state=finished returned tuple>,\n",
       " <Future at 0x118c83469e0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346aa0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346b60 state=finished returned tuple>,\n",
       " <Future at 0x118c8346c20 state=finished returned tuple>,\n",
       " <Future at 0x118c8346ce0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346da0 state=finished returned tuple>,\n",
       " <Future at 0x118c8346e60 state=finished returned tuple>,\n",
       " <Future at 0x118c8346f20 state=finished returned tuple>,\n",
       " <Future at 0x118c8346fe0 state=finished returned tuple>,\n",
       " <Future at 0x118c83470a0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347160 state=finished returned tuple>,\n",
       " <Future at 0x118c8347220 state=finished returned tuple>,\n",
       " <Future at 0x118c83472e0 state=finished returned tuple>,\n",
       " <Future at 0x118c83473a0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347460 state=finished returned tuple>,\n",
       " <Future at 0x118c8347520 state=finished returned tuple>,\n",
       " <Future at 0x118c83475e0 state=finished returned tuple>,\n",
       " <Future at 0x118c83476a0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347760 state=finished returned tuple>,\n",
       " <Future at 0x118c8347820 state=finished returned tuple>,\n",
       " <Future at 0x118c83478e0 state=finished returned tuple>,\n",
       " <Future at 0x118c83479a0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347a60 state=finished returned tuple>,\n",
       " <Future at 0x118c8347b20 state=finished returned tuple>,\n",
       " <Future at 0x118c8347be0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347ca0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347d60 state=finished returned tuple>,\n",
       " <Future at 0x118c8347e20 state=finished returned tuple>,\n",
       " <Future at 0x118c8347ee0 state=finished returned tuple>,\n",
       " <Future at 0x118c8347fa0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd87940 state=finished returned tuple>,\n",
       " <Future at 0x1194bd840a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84160 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84220 state=finished returned tuple>,\n",
       " <Future at 0x1194bd842e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd843a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84460 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84520 state=finished returned tuple>,\n",
       " <Future at 0x1194bd845e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd846a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84760 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84820 state=finished returned tuple>,\n",
       " <Future at 0x1194bd848e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd849a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84a60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84b20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84be0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84ca0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84d60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84e20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84ee0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd84fa0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85060 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85120 state=finished returned tuple>,\n",
       " <Future at 0x1194bd851e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd852a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85360 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85420 state=finished returned tuple>,\n",
       " <Future at 0x1194bd854e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd855a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85660 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85720 state=finished returned tuple>,\n",
       " <Future at 0x1194bd857e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd858a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85960 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85a20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85ae0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85ba0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85c60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85d20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85de0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85ea0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd85f60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86020 state=finished returned tuple>,\n",
       " <Future at 0x1194bd860e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd861a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86260 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86320 state=finished returned tuple>,\n",
       " <Future at 0x1194bd863e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd864a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86560 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86620 state=finished returned tuple>,\n",
       " <Future at 0x1194bd866e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd867a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86860 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86920 state=finished returned tuple>,\n",
       " <Future at 0x1194bd869e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86aa0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86b60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86c20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86ce0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86da0 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86e60 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86f20 state=finished returned tuple>,\n",
       " <Future at 0x1194bd86fe0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7220 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb5390 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb65f0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7340 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7400 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb74c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7580 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7640 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7700 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb77c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7880 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7940 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7a00 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7ac0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7b80 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7c40 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7d00 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7dc0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7e80 state=finished returned tuple>,\n",
       " <Future at 0x1194bdb7f40 state=finished returned tuple>,\n",
       " <Future at 0x1194bdcb3a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdcab60 state=finished returned tuple>,\n",
       " <Future at 0x1194bdcb400 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc80a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8160 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8220 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc82e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc83a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8460 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8520 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc85e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc86a0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8760 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8820 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8910 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc89d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8a90 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8b50 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8c10 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8cd0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8d90 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8e50 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8f10 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc8fd0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9090 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9150 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9210 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc92d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9390 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9450 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9510 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc95d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9690 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9750 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9810 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc98d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9990 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9a50 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9b10 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9bd0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9c90 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9d50 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9e10 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9ed0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc9f90 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca050 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca110 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca1d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca290 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca350 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca410 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca4d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca590 state=finished returned tuple>,\n",
       " <Future at 0x1194bdca5f0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2d8a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2d030 state=finished returned tuple>,\n",
       " <Future at 0x1194be2e3b0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2e5f0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2e830 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ea70 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ec80 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ed40 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ee00 state=finished returned tuple>,\n",
       " <Future at 0x1194be2eec0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ef80 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f040 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f100 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f1c0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f280 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f340 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f400 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f4c0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f580 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f640 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f700 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f7c0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f880 state=finished returned tuple>,\n",
       " <Future at 0x1194be2f940 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fa00 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fac0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fb80 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fc40 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fd00 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fdc0 state=finished returned tuple>,\n",
       " <Future at 0x1194be2fe80 state=finished returned tuple>,\n",
       " <Future at 0x1194be2ff40 state=finished returned tuple>,\n",
       " <Future at 0x1194be5ba60 state=finished returned tuple>,\n",
       " <Future at 0x1194be5bdc0 state=finished returned tuple>,\n",
       " <Future at 0x1194be5be20 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a680 state=finished returned tuple>,\n",
       " <Future at 0x1194be580a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58160 state=finished returned tuple>,\n",
       " <Future at 0x1194be58220 state=finished returned tuple>,\n",
       " <Future at 0x1194be582e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be583a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58460 state=finished returned tuple>,\n",
       " <Future at 0x1194be58520 state=finished returned tuple>,\n",
       " <Future at 0x1194be585e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be586a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58760 state=finished returned tuple>,\n",
       " <Future at 0x1194be58820 state=finished returned tuple>,\n",
       " <Future at 0x1194be588e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be589a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58a60 state=finished returned tuple>,\n",
       " <Future at 0x1194be58b20 state=finished returned tuple>,\n",
       " <Future at 0x1194be58be0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58ca0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58d60 state=finished returned tuple>,\n",
       " <Future at 0x1194be58e20 state=finished returned tuple>,\n",
       " <Future at 0x1194be58ee0 state=finished returned tuple>,\n",
       " <Future at 0x1194be58fa0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59060 state=finished returned tuple>,\n",
       " <Future at 0x1194be59120 state=finished returned tuple>,\n",
       " <Future at 0x1194be591e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be592a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59360 state=finished returned tuple>,\n",
       " <Future at 0x1194be59420 state=finished returned tuple>,\n",
       " <Future at 0x1194be594e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be595a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59660 state=finished returned tuple>,\n",
       " <Future at 0x1194be59720 state=finished returned tuple>,\n",
       " <Future at 0x1194be597e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be598a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59960 state=finished returned tuple>,\n",
       " <Future at 0x1194be59a20 state=finished returned tuple>,\n",
       " <Future at 0x1194be59ae0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59ba0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59c60 state=finished returned tuple>,\n",
       " <Future at 0x1194be59d20 state=finished returned tuple>,\n",
       " <Future at 0x1194be59de0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59ea0 state=finished returned tuple>,\n",
       " <Future at 0x1194be59f60 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a020 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a0e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a1a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a260 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a320 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a3e0 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a4a0 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a560 state=finished returned tuple>,\n",
       " <Future at 0x1194be5a620 state=finished returned tuple>,\n",
       " <Future at 0x1194bf341f0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf34be0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf342b0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35180 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35240 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35300 state=finished returned tuple>,\n",
       " <Future at 0x1194bf353c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35480 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35540 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35600 state=finished returned tuple>,\n",
       " <Future at 0x1194bf356c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35780 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35840 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35900 state=finished returned tuple>,\n",
       " <Future at 0x1194bf359c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35a80 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35b40 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35c00 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35cc0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35d80 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35e40 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35f00 state=finished returned tuple>,\n",
       " <Future at 0x1194bf35fc0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36080 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36140 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36200 state=finished returned tuple>,\n",
       " <Future at 0x1194bf362c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36380 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36440 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36500 state=finished returned tuple>,\n",
       " <Future at 0x1194bf365c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36680 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36740 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36800 state=finished returned tuple>,\n",
       " <Future at 0x1194bf368c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36980 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36a40 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36b00 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36bc0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36c80 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36d40 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36e00 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36ec0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf36f80 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37040 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37100 state=finished returned tuple>,\n",
       " <Future at 0x1194bf371c0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37280 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37340 state=finished returned tuple>,\n",
       " <Future at 0x1194bdc88e0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37490 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37550 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37610 state=finished returned tuple>,\n",
       " <Future at 0x1194bf376d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37790 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37850 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37910 state=finished returned tuple>,\n",
       " <Future at 0x1194bf379d0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37a90 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37b50 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37c10 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37cd0 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37d90 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37e50 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37f10 state=finished returned tuple>,\n",
       " <Future at 0x1194bf37fd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc700d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70190 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70250 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70310 state=finished returned tuple>,\n",
       " <Future at 0x1194cc703d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70490 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70550 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70610 state=finished returned tuple>,\n",
       " <Future at 0x1194cc706d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70790 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70850 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70910 state=finished returned tuple>,\n",
       " <Future at 0x1194cc709d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70a90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70b50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70c10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70cd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70d90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70e50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70f10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc70fd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71090 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71150 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71210 state=finished returned tuple>,\n",
       " <Future at 0x1194cc712d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71390 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71450 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71510 state=finished returned tuple>,\n",
       " <Future at 0x1194cc715d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71690 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71750 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71810 state=finished returned tuple>,\n",
       " <Future at 0x1194cc718d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71990 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71a50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71b10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71bd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71c90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71d50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71e10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71ed0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc71f90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72050 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72110 state=finished returned tuple>,\n",
       " <Future at 0x1194cc721d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72290 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72350 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72410 state=finished returned tuple>,\n",
       " <Future at 0x1194cc724d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72590 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72650 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72710 state=finished returned tuple>,\n",
       " <Future at 0x1194cc727d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72890 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72950 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72a10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72ad0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72b90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72c50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72d10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72dd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72e90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc72f50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73010 state=finished returned tuple>,\n",
       " <Future at 0x1194cc730d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73190 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73250 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73310 state=finished returned tuple>,\n",
       " <Future at 0x1194cc733d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73490 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73550 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73610 state=finished returned tuple>,\n",
       " <Future at 0x1194cc736d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73790 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73850 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73910 state=finished returned tuple>,\n",
       " <Future at 0x1194cc739d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73a90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73b50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73c10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73cd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73d90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73e50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73f10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc73fd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc940d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94190 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94250 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94310 state=finished returned tuple>,\n",
       " <Future at 0x1194cc943d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94490 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94550 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94610 state=finished returned tuple>,\n",
       " <Future at 0x1194cc946d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94790 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94850 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94910 state=finished returned tuple>,\n",
       " <Future at 0x1194cc949d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94a90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94b50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94c10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94cd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94d90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94e50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94f10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc94fd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95090 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95150 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95210 state=finished returned tuple>,\n",
       " <Future at 0x1194cc952d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95390 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95450 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95510 state=finished returned tuple>,\n",
       " <Future at 0x1194cc955d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95690 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95750 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95810 state=finished returned tuple>,\n",
       " <Future at 0x1194cc958d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95990 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95a50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95b10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95bd0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95c90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95d50 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95e10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95ed0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc95f90 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96050 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96110 state=finished returned tuple>,\n",
       " <Future at 0x1194cc961d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96290 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96350 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96410 state=finished returned tuple>,\n",
       " <Future at 0x1194cc964d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96590 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96650 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96710 state=finished returned tuple>,\n",
       " <Future at 0x1194cc967d0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96890 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96950 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96a10 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96ad0 state=finished returned tuple>,\n",
       " <Future at 0x1194cc96b90 state=finished returned tuple>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future at 0x1becc024610 state=finished returned tuple>,\n",
       " <Future at 0x1becc024ac0 state=finished returned tuple>,\n",
       " <Future at 0x1becc041570 state=finished returned tuple>,\n",
       " <Future at 0x1becc0406a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc052230 state=finished returned tuple>,\n",
       " <Future at 0x1becc07a3e0 state=finished returned tuple>,\n",
       " <Future at 0x1be09eff2b0 state=finished returned tuple>,\n",
       " <Future at 0x1be09eff910 state=finished returned tuple>,\n",
       " <Future at 0x1be547b0610 state=finished returned tuple>,\n",
       " <Future at 0x1be6f280550 state=finished returned tuple>,\n",
       " <Future at 0x1becc0aa680 state=finished returned tuple>,\n",
       " <Future at 0x1becc031c00 state=finished returned tuple>,\n",
       " <Future at 0x1be5472e830 state=finished returned tuple>,\n",
       " <Future at 0x1be5472e800 state=finished returned tuple>,\n",
       " <Future at 0x1be5472fb50 state=finished returned tuple>,\n",
       " <Future at 0x1be5472dc00 state=finished returned tuple>,\n",
       " <Future at 0x1be5472f520 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d5a0 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d1e0 state=finished returned tuple>,\n",
       " <Future at 0x1be5472cd30 state=finished returned tuple>,\n",
       " <Future at 0x1be5472cb50 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d2d0 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d540 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d870 state=finished returned tuple>,\n",
       " <Future at 0x1be5472d8a0 state=finished returned tuple>,\n",
       " <Future at 0x1be5472eda0 state=finished returned tuple>,\n",
       " <Future at 0x1be5472ec80 state=finished returned tuple>,\n",
       " <Future at 0x1be5472fbe0 state=finished returned tuple>,\n",
       " <Future at 0x1becc006b90 state=finished returned tuple>,\n",
       " <Future at 0x1becc0062c0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0054b0 state=finished returned tuple>,\n",
       " <Future at 0x1becc004970 state=finished returned tuple>,\n",
       " <Future at 0x1becc004490 state=finished returned tuple>,\n",
       " <Future at 0x1becc0072b0 state=finished returned tuple>,\n",
       " <Future at 0x1be54700eb0 state=finished returned tuple>,\n",
       " <Future at 0x1be547019f0 state=finished returned tuple>,\n",
       " <Future at 0x1be54700580 state=finished returned tuple>,\n",
       " <Future at 0x1be54703ac0 state=finished returned tuple>,\n",
       " <Future at 0x1be54701c90 state=finished returned tuple>,\n",
       " <Future at 0x1be54701d20 state=finished returned tuple>,\n",
       " <Future at 0x1be54701e40 state=finished returned tuple>,\n",
       " <Future at 0x1be54701f60 state=finished returned tuple>,\n",
       " <Future at 0x1be54701fc0 state=finished returned tuple>,\n",
       " <Future at 0x1be54702260 state=finished returned tuple>,\n",
       " <Future at 0x1be547022c0 state=finished returned tuple>,\n",
       " <Future at 0x1be547021a0 state=finished returned tuple>,\n",
       " <Future at 0x1be54702500 state=finished returned tuple>,\n",
       " <Future at 0x1be547028f0 state=finished returned tuple>,\n",
       " <Future at 0x1be54702950 state=finished returned tuple>,\n",
       " <Future at 0x1be54702ad0 state=finished returned tuple>,\n",
       " <Future at 0x1be54702bc0 state=finished returned tuple>,\n",
       " <Future at 0x1be54702c50 state=finished returned tuple>,\n",
       " <Future at 0x1be5119c310 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f550 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d7e0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d870 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f2b0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f370 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f460 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ffd0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ead0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e650 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e590 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e470 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e3b0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e290 state=finished returned tuple>,\n",
       " <Future at 0x1be5119fbb0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119fc70 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d240 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d300 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ce80 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d210 state=finished returned tuple>,\n",
       " <Future at 0x1be5119d1e0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119e2c0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ea70 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ed10 state=finished returned tuple>,\n",
       " <Future at 0x1be5119ee90 state=finished returned tuple>,\n",
       " <Future at 0x1be5119efe0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f0a0 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f160 state=finished returned tuple>,\n",
       " <Future at 0x1be5119f220 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9060 state=finished returned tuple>,\n",
       " <Future at 0x1be546d8070 state=finished returned tuple>,\n",
       " <Future at 0x1be546da080 state=finished returned tuple>,\n",
       " <Future at 0x1be546db550 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9bd0 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9810 state=finished returned tuple>,\n",
       " <Future at 0x1be546daa10 state=finished returned tuple>,\n",
       " <Future at 0x1be546d85e0 state=finished returned tuple>,\n",
       " <Future at 0x1be546d8eb0 state=finished returned tuple>,\n",
       " <Future at 0x1be546db3d0 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9630 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9ae0 state=finished returned tuple>,\n",
       " <Future at 0x1be546d94b0 state=finished returned tuple>,\n",
       " <Future at 0x1be546dbb20 state=finished returned tuple>,\n",
       " <Future at 0x1be546d8a30 state=finished returned tuple>,\n",
       " <Future at 0x1be546d9600 state=finished returned tuple>,\n",
       " <Future at 0x1be54784970 state=finished returned tuple>,\n",
       " <Future at 0x1be54784a60 state=finished returned tuple>,\n",
       " <Future at 0x1be54784bb0 state=finished returned tuple>,\n",
       " <Future at 0x1be54784cd0 state=finished returned tuple>,\n",
       " <Future at 0x1be54784d90 state=finished returned tuple>,\n",
       " <Future at 0x1be54784e50 state=finished returned tuple>,\n",
       " <Future at 0x1be54784f10 state=finished returned tuple>,\n",
       " <Future at 0x1be54784fd0 state=finished returned tuple>,\n",
       " <Future at 0x1be54785090 state=finished returned tuple>,\n",
       " <Future at 0x1be54785150 state=finished returned tuple>,\n",
       " <Future at 0x1be54785210 state=finished returned tuple>,\n",
       " <Future at 0x1be547852d0 state=finished returned tuple>,\n",
       " <Future at 0x1be54785390 state=finished returned tuple>,\n",
       " <Future at 0x1be54785480 state=finished returned tuple>,\n",
       " <Future at 0x1be547855d0 state=finished returned tuple>,\n",
       " <Future at 0x1be547856c0 state=finished returned tuple>,\n",
       " <Future at 0x1be54785750 state=finished returned tuple>,\n",
       " <Future at 0x1be54785810 state=finished returned tuple>,\n",
       " <Future at 0x1be547858d0 state=finished returned tuple>,\n",
       " <Future at 0x1be54785990 state=finished returned tuple>,\n",
       " <Future at 0x1be54785a50 state=finished returned tuple>,\n",
       " <Future at 0x1be54785b10 state=finished returned tuple>,\n",
       " <Future at 0x1be54785bd0 state=finished returned tuple>,\n",
       " <Future at 0x1be54785c90 state=finished returned tuple>,\n",
       " <Future at 0x1be54785d50 state=finished returned tuple>,\n",
       " <Future at 0x1be54785e70 state=finished returned tuple>,\n",
       " <Future at 0x1be54785f90 state=finished returned tuple>,\n",
       " <Future at 0x1be54786050 state=finished returned tuple>,\n",
       " <Future at 0x1be54786170 state=finished returned tuple>,\n",
       " <Future at 0x1be54786230 state=finished returned tuple>,\n",
       " <Future at 0x1be547866b0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786650 state=finished returned tuple>,\n",
       " <Future at 0x1be547868c0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786920 state=finished returned tuple>,\n",
       " <Future at 0x1be54786aa0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786bf0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786cb0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786d70 state=finished returned tuple>,\n",
       " <Future at 0x1be54786e30 state=finished returned tuple>,\n",
       " <Future at 0x1be54786ef0 state=finished returned tuple>,\n",
       " <Future at 0x1be54786fb0 state=finished returned tuple>,\n",
       " <Future at 0x1be54787070 state=finished returned tuple>,\n",
       " <Future at 0x1be54787130 state=finished returned tuple>,\n",
       " <Future at 0x1be547871f0 state=finished returned tuple>,\n",
       " <Future at 0x1be547872b0 state=finished returned tuple>,\n",
       " <Future at 0x1be54787370 state=finished returned tuple>,\n",
       " <Future at 0x1be54787430 state=finished returned tuple>,\n",
       " <Future at 0x1be547875b0 state=finished returned tuple>,\n",
       " <Future at 0x1be54787670 state=finished returned tuple>,\n",
       " <Future at 0x1be54787730 state=finished returned tuple>,\n",
       " <Future at 0x1be547877f0 state=finished returned tuple>,\n",
       " <Future at 0x1be547878b0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dc7f0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dcb50 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2deda0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df3a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df460 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df520 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df5e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df6a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df760 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df820 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df8e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2df9a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dfa60 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dfbe0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dfca0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dfd90 state=finished returned tuple>,\n",
       " <Future at 0x1be6f2dff10 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c340 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c280 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c520 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c610 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c730 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c880 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30c940 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ca00 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cac0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cb80 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cc40 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cd00 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cdc0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ce80 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30cf40 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d000 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d090 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d240 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d300 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d3c0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d480 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d5d0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d600 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d6c0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d780 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d840 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d900 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30d9c0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30db10 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30dc00 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30dcc0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30dde0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e080 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e320 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e230 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e4d0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e5f0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e740 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e860 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e920 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30e9e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30eaa0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30eb60 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ec20 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ece0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30eda0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ee60 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30ef20 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30efe0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f0a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f220 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f2e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f3a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f460 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f520 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f5e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f6a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f760 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f820 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f8e0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30f9a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30fb20 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30fbe0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30fcd0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f30fe50 state=finished returned tuple>,\n",
       " <Future at 0x1be6f336d70 state=finished returned tuple>,\n",
       " <Future at 0x1be6f335060 state=finished returned tuple>,\n",
       " <Future at 0x1be6f336b00 state=finished returned tuple>,\n",
       " <Future at 0x1be6f3342b0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334250 state=finished returned tuple>,\n",
       " <Future at 0x1be6f3344c0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334520 state=finished returned tuple>,\n",
       " <Future at 0x1be6f3346a0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f3347f0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f3348b0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334970 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334a30 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334af0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334bb0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334c70 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334d30 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334df0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334eb0 state=finished returned tuple>,\n",
       " <Future at 0x1be6f334f70 state=finished returned tuple>,\n",
       " <Future at 0x1be6f335030 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f966b0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96770 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96830 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f968f0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f969b0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96a70 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96b30 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96bf0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96cb0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96d70 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96e30 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96ef0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f96fb0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97070 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97130 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f971f0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f972b0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97370 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97430 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f974f0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f975b0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97670 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97730 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f977f0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f978b0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97970 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97a30 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97af0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97bb0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97c70 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97d30 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97df0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97eb0 state=finished returned tuple>,\n",
       " <Future at 0x1beb1f97f70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf23ee0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20070 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20130 state=finished returned tuple>,\n",
       " <Future at 0x1becbf201f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf202b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20370 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20430 state=finished returned tuple>,\n",
       " <Future at 0x1becbf204f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf205b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20670 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20730 state=finished returned tuple>,\n",
       " <Future at 0x1becbf207f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf208b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20970 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20a30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20af0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20bb0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20c70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20d30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20df0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20eb0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf20f70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21030 state=finished returned tuple>,\n",
       " <Future at 0x1becbf210f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf211b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21270 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21330 state=finished returned tuple>,\n",
       " <Future at 0x1becbf213f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf214b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21570 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21630 state=finished returned tuple>,\n",
       " <Future at 0x1becbf216f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf217b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21870 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21930 state=finished returned tuple>,\n",
       " <Future at 0x1becbf219f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21ab0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21b70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21c30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21cf0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21db0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21e70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21f30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf21ff0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf220b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22170 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22230 state=finished returned tuple>,\n",
       " <Future at 0x1becbf222f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf223b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22470 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22530 state=finished returned tuple>,\n",
       " <Future at 0x1becbf225f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf226b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22770 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22830 state=finished returned tuple>,\n",
       " <Future at 0x1becbf228f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf229b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22a70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22b30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22bf0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22cb0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22d70 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22e30 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22ef0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf22fb0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf23070 state=finished returned tuple>,\n",
       " <Future at 0x1becbf532b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf51420 state=finished returned tuple>,\n",
       " <Future at 0x1becbf52680 state=finished returned tuple>,\n",
       " <Future at 0x1becbf533d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53490 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53550 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53610 state=finished returned tuple>,\n",
       " <Future at 0x1becbf536d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53790 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53850 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53910 state=finished returned tuple>,\n",
       " <Future at 0x1becbf539d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53a90 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53b50 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53c10 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53cd0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53d90 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53e50 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53f10 state=finished returned tuple>,\n",
       " <Future at 0x1becbf53fd0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6ab60 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6ad10 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68070 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68130 state=finished returned tuple>,\n",
       " <Future at 0x1becbf681f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf682b0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68370 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68430 state=finished returned tuple>,\n",
       " <Future at 0x1becbf684f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf685b0 state=finished returned tuple>,\n",
       " <Future at 0x1be09ec40a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf686d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68790 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68880 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68940 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68a00 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68ac0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68b80 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68c40 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68d00 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68dc0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68e80 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68f40 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69000 state=finished returned tuple>,\n",
       " <Future at 0x1becbf690c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69180 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69240 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69300 state=finished returned tuple>,\n",
       " <Future at 0x1becbf693c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69480 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69540 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69600 state=finished returned tuple>,\n",
       " <Future at 0x1becbf696c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69780 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69840 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69900 state=finished returned tuple>,\n",
       " <Future at 0x1becbf699c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69a80 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69b40 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69c00 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69cc0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69d80 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69e40 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69f00 state=finished returned tuple>,\n",
       " <Future at 0x1becbf69fc0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a080 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a140 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a200 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a2c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a380 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a440 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a500 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a5c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf6a680 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd1930 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd10c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2440 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2680 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd28c0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2b00 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2d10 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2dd0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2e90 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd2f50 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3010 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd30d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3190 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3250 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3310 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd33d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3490 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3550 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3610 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd36d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3790 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3850 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3910 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd39d0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3a90 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3b50 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3c10 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3cd0 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3d90 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3e50 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3f10 state=finished returned tuple>,\n",
       " <Future at 0x1becbfd3fd0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2fe0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff31f0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2ad0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff00a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0160 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0220 state=finished returned tuple>,\n",
       " <Future at 0x1becbff02e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff03a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0460 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0520 state=finished returned tuple>,\n",
       " <Future at 0x1becbff05e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff06a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0760 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0820 state=finished returned tuple>,\n",
       " <Future at 0x1becbff08e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff09a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0a60 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0b20 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0be0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0ca0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0d60 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0e20 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0ee0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff0fa0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1060 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1120 state=finished returned tuple>,\n",
       " <Future at 0x1becbff11e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff12a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1360 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1420 state=finished returned tuple>,\n",
       " <Future at 0x1becbff14e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff15a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1660 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1720 state=finished returned tuple>,\n",
       " <Future at 0x1becbff17e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff18a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1960 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1a20 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1ae0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1ba0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1c60 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1d20 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1de0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1ea0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff1f60 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2020 state=finished returned tuple>,\n",
       " <Future at 0x1becbff20e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff21a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2260 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2320 state=finished returned tuple>,\n",
       " <Future at 0x1becbff23e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff24a0 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2560 state=finished returned tuple>,\n",
       " <Future at 0x1becbff2620 state=finished returned tuple>,\n",
       " <Future at 0x1becbff26e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d0640 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d0af0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1000 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d11e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d12a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1360 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1420 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d14e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d15a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1660 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1720 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d17e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d18a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1960 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1a20 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1ae0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1ba0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1c60 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1d20 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1de0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1ea0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d1f60 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2020 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d20e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d21a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2260 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2320 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d23e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d24a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2560 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2620 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d26e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d27a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2860 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2920 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d29e0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2aa0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2b60 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2c20 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2ce0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2da0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2e60 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2f20 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d2fe0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d30a0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3160 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3220 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d32e0 state=finished returned tuple>,\n",
       " <Future at 0x1becbf68850 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3430 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d34f0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d35b0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3670 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3730 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d37f0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d38b0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3970 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3a30 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3af0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3bb0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3c70 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3d30 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3df0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3eb0 state=finished returned tuple>,\n",
       " <Future at 0x1becc0d3f70 state=finished returned tuple>,\n",
       " <Future at 0x1becce18070 state=finished returned tuple>,\n",
       " <Future at 0x1becce18130 state=finished returned tuple>,\n",
       " <Future at 0x1becce181f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce182b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18370 state=finished returned tuple>,\n",
       " <Future at 0x1becce18430 state=finished returned tuple>,\n",
       " <Future at 0x1becce184f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce185b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18670 state=finished returned tuple>,\n",
       " <Future at 0x1becce18730 state=finished returned tuple>,\n",
       " <Future at 0x1becce187f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce188b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18970 state=finished returned tuple>,\n",
       " <Future at 0x1becce18a30 state=finished returned tuple>,\n",
       " <Future at 0x1becce18af0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18bb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18c70 state=finished returned tuple>,\n",
       " <Future at 0x1becce18d30 state=finished returned tuple>,\n",
       " <Future at 0x1becce18df0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18eb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce18f70 state=finished returned tuple>,\n",
       " <Future at 0x1becce19030 state=finished returned tuple>,\n",
       " <Future at 0x1becce190f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce191b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19270 state=finished returned tuple>,\n",
       " <Future at 0x1becce19330 state=finished returned tuple>,\n",
       " <Future at 0x1becce193f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce194b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19570 state=finished returned tuple>,\n",
       " <Future at 0x1becce19630 state=finished returned tuple>,\n",
       " <Future at 0x1becce196f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce197b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19870 state=finished returned tuple>,\n",
       " <Future at 0x1becce19930 state=finished returned tuple>,\n",
       " <Future at 0x1becce199f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19ab0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19b70 state=finished returned tuple>,\n",
       " <Future at 0x1becce19c30 state=finished returned tuple>,\n",
       " <Future at 0x1becce19cf0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19db0 state=finished returned tuple>,\n",
       " <Future at 0x1becce19e70 state=finished returned tuple>,\n",
       " <Future at 0x1becce19f30 state=finished returned tuple>,\n",
       " <Future at 0x1becce19ff0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a0b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a170 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a230 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a2f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a3b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a470 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a530 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a5f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a6b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a770 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a830 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a8f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1a9b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1aa70 state=finished returned tuple>,\n",
       " <Future at 0x1becce1ab30 state=finished returned tuple>,\n",
       " <Future at 0x1becce1abf0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1acb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1ad70 state=finished returned tuple>,\n",
       " <Future at 0x1becce1ae30 state=finished returned tuple>,\n",
       " <Future at 0x1becce1aef0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1afb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b070 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b130 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b1f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b2b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b370 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b430 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b4f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b5b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b670 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b730 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b7f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b8b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1b970 state=finished returned tuple>,\n",
       " <Future at 0x1becce1ba30 state=finished returned tuple>,\n",
       " <Future at 0x1becce1baf0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1bbb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1bc70 state=finished returned tuple>,\n",
       " <Future at 0x1becce1bd30 state=finished returned tuple>,\n",
       " <Future at 0x1becce1bdf0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1beb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce1bf70 state=finished returned tuple>,\n",
       " <Future at 0x1becce40070 state=finished returned tuple>,\n",
       " <Future at 0x1becce40130 state=finished returned tuple>,\n",
       " <Future at 0x1becce401f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce402b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40370 state=finished returned tuple>,\n",
       " <Future at 0x1becce40430 state=finished returned tuple>,\n",
       " <Future at 0x1becce404f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce405b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40670 state=finished returned tuple>,\n",
       " <Future at 0x1becce40730 state=finished returned tuple>,\n",
       " <Future at 0x1becce407f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce408b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40970 state=finished returned tuple>,\n",
       " <Future at 0x1becce40a30 state=finished returned tuple>,\n",
       " <Future at 0x1becce40af0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40bb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40c70 state=finished returned tuple>,\n",
       " <Future at 0x1becce40d30 state=finished returned tuple>,\n",
       " <Future at 0x1becce40df0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40eb0 state=finished returned tuple>,\n",
       " <Future at 0x1becce40f70 state=finished returned tuple>,\n",
       " <Future at 0x1becce41030 state=finished returned tuple>,\n",
       " <Future at 0x1becce410f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce411b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41270 state=finished returned tuple>,\n",
       " <Future at 0x1becce41330 state=finished returned tuple>,\n",
       " <Future at 0x1becce413f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce414b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41570 state=finished returned tuple>,\n",
       " <Future at 0x1becce41630 state=finished returned tuple>,\n",
       " <Future at 0x1becce416f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce417b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41870 state=finished returned tuple>,\n",
       " <Future at 0x1becce41930 state=finished returned tuple>,\n",
       " <Future at 0x1becce419f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41ab0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41b70 state=finished returned tuple>,\n",
       " <Future at 0x1becce41c30 state=finished returned tuple>,\n",
       " <Future at 0x1becce41cf0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41db0 state=finished returned tuple>,\n",
       " <Future at 0x1becce41e70 state=finished returned tuple>,\n",
       " <Future at 0x1becce41f30 state=finished returned tuple>,\n",
       " <Future at 0x1becce41ff0 state=finished returned tuple>,\n",
       " <Future at 0x1becce420b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce42170 state=finished returned tuple>,\n",
       " <Future at 0x1becce42230 state=finished returned tuple>,\n",
       " <Future at 0x1becce422f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce423b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce42470 state=finished returned tuple>,\n",
       " <Future at 0x1becce42530 state=finished returned tuple>,\n",
       " <Future at 0x1becce425f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce426b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce42770 state=finished returned tuple>,\n",
       " <Future at 0x1becce42830 state=finished returned tuple>,\n",
       " <Future at 0x1becce428f0 state=finished returned tuple>,\n",
       " <Future at 0x1becce429b0 state=finished returned tuple>,\n",
       " <Future at 0x1becce42a70 state=finished returned tuple>,\n",
       " <Future at 0x1becce42b30 state=finished returned tuple>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [future.result() for future in futures]\n",
    "\n",
    "# Assuming the result of each future is a tuple (pair, cka_value), where:\n",
    "# - pair is a tuple (Layer1, Layer2)\n",
    "# - cka_value is the CKA value associated with that pair\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame([(pair[0], pair[1], cka_value) for pair, cka_value in results],\n",
    "                  columns=['Layer1', 'Layer2', 'CKA_Value'])\n",
    "\n",
    "df.to_csv(\"CKA_Collapsed_Shallow.csv\", sep =\"\\t\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_layers = len(layer_names_model1)# + len(layer_names_model2)\n",
    "matrix = np.zeros((n_layers, n_layers))\n",
    "\n",
    "\n",
    "for (layer1, layer2), similarity in cka_results.items():\n",
    "    i = layer_names_model1.index(layer1) if layer1 in layer_names_model1 else len(layer_names_model1) + layer_names_model2.index(layer1)\n",
    "    j = layer_names_model2.index(layer2) if layer2 in layer_names_model2 else len(layer_names_model2) + layer_names_model1.index(layer2)\n",
    "    \n",
    "    matrix[i, j] = similarity\n",
    "    matrix[j, i] = similarity  # Symmetric matrix\n",
    "layer_names = [\"conv_time\",\"conv_spat\", \"pool\"]\n",
    "df = pd.DataFrame(matrix, index=layer_names, columns=layer_names)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df, annot=True)#, cmap='magma', fmt='.2f', square=True)#, linewidths=0.5, cbar=True, vmin=0, vmax=1, xticklabels=layer_names, yticklabels=layer_names)\n",
    "\n",
    "plt.title('Average CKA Similarity Heatmap')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Layer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

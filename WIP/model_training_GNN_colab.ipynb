{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Vbwzg32ZhZ",
        "outputId": "9d47305a-e670-4cbb-b79f-6774ed7b1671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running in Google Colab. Checking required libraries...\n",
            "Installing missing libraries: moabb, braindecode, torch_geometric\n",
            "Collecting moabb\n",
            "  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting braindecode\n",
            "  Downloading braindecode-0.8.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (6.0.2)\n",
            "Collecting coverage<8.0.0,>=7.0.1 (from moabb)\n",
            "  Downloading coverage-7.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting edfio<0.5.0,>=0.4.2 (from moabb)\n",
            "  Downloading edfio-0.4.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting edflib-python<2.0.0,>=1.0.6 (from moabb)\n",
            "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.13.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.10.0)\n",
            "Collecting memory-profiler<0.62.0,>=0.61.0 (from moabb)\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting mne<2.0.0,>=1.7.0 (from moabb)\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting mne-bids>=0.14 (from moabb)\n",
            "  Downloading mne_bids-0.16.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting numpy<2.0,>=1.22 (from moabb)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.2.2)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.8.2)\n",
            "Collecting pyriemann<0.8,>=0.7 (from moabb)\n",
            "  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.32.3)\n",
            "Collecting scikit-learn<1.6 (from moabb)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.14.1)\n",
            "Collecting seaborn<0.13.0,>=0.12.1 (from moabb)\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (4.67.1)\n",
            "Collecting urllib3<2.0.0,>=1.26.15 (from moabb)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skorch (from braindecode)\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from braindecode) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from braindecode) (0.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.4.2)\n",
            "Collecting torchinfo (from braindecode)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting docstring-inheritance (from braindecode)\n",
            "  Downloading docstring_inheritance-2.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->braindecode)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->braindecode)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->braindecode)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->braindecode)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->braindecode)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->braindecode)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->braindecode)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->braindecode) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.17.0)\n",
            "Downloading moabb-1.2.0-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braindecode-0.8.1-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.2/165.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edfio-0.4.7-py3-none-any.whl (27 kB)\n",
            "Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne_bids-0.16.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docstring_inheritance-2.2.2-py3-none-any.whl (24 kB)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/211.5 MB\u001b[0m \u001b[31m159.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "import subprocess\n",
        "\n",
        "def install_if_colab():\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Running in Google Colab. Checking required libraries...\")\n",
        "\n",
        "        packages = [\"moabb\", \"braindecode\",\"torch_geometric\"]  # Add required libraries\n",
        "        missing_packages = [pkg for pkg in packages if importlib.util.find_spec(pkg) is None]\n",
        "\n",
        "        if missing_packages:\n",
        "            print(f\"Installing missing libraries: {', '.join(missing_packages)}\")\n",
        "            !pip install {\" \".join(missing_packages)}\n",
        "        else:\n",
        "            print(\"All required libraries are already installed.\")\n",
        "    else:\n",
        "        print(\"Not running in Google Colab. No installation needed.\")\n",
        "\n",
        "install_if_colab()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_sHCnT22v9k"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1osynJth26to"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(path+'EEG_data/test_set.pkl', 'rb') as f_test:\n",
        "    test_set = pickle.load(f_test)\n",
        "\n",
        "import pickle\n",
        "with open(path+'EEG_data/train_set.pkl', 'rb') as f_train:\n",
        "    train_set = pickle.load(f_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31OCpWX8DcWY"
      },
      "outputs": [],
      "source": [
        "print(train_set[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boUgL8BBDd3R"
      },
      "outputs": [],
      "source": [
        "print(test_set[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xba9vjnO2Zhg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#from shallow_fbcsp import ShallowFBCSPNet\n",
        "from braindecode.util import set_random_seeds\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
        "device = \"cuda\" if cuda else \"cpu\"\n",
        "if cuda:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed = 11999\n",
        "set_random_seeds(seed=seed, cuda=cuda)\n",
        "\n",
        "n_classes = 4\n",
        "classes = list(range(n_classes))\n",
        "# Extract number of chans and time steps from dataset\n",
        "n_channels = 22\n",
        "input_window_samples = 1125\n",
        "\n",
        "print(\"n_classes: \", n_classes)\n",
        "print(\"n_channels:\", n_channels)\n",
        "print(\"input_window_samples size:\", input_window_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3wPzn3X2Zhh"
      },
      "outputs": [],
      "source": [
        "#from models_fbscp import CollapsedShallowNet\n",
        "# The ShallowFBCSPNet is a `nn.Sequential` model\n",
        "import importlib\n",
        "from weight_init import init_weights\n",
        "import GIN_model\n",
        "importlib.reload(GIN_model)\n",
        "from GIN_model import ShallowGNNNet\n",
        "model = ShallowGNNNet(\n",
        "    n_chans=22,\n",
        "    n_outputs=n_classes,\n",
        "    n_times=input_window_samples,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "#model.apply(init_weights)\n",
        "\n",
        "# Display torchinfo table describing the model\n",
        "print(model)\n",
        "\n",
        "# Send model to GPU\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Eii9TH2Zhi"
      },
      "outputs": [],
      "source": [
        "# splitted = windows_dataset.split(\"session\")\n",
        "# train_set = splitted['0train']  # Session train\n",
        "# test_set = splitted['1test']  # Session evaluation\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.optim.lr_scheduler import LRScheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#lr = 1e-4\n",
        "#weight_decay = 1e-4\n",
        "#batch_size = 64\n",
        "#n_epochs = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlgtbF-r2Zhj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "# Define a method for training one epoch\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "        dataloader: DataLoader, model: Module, loss_fn, optimizer,\n",
        "        scheduler: LRScheduler, epoch: int, device, print_batch_stats=True\n",
        "):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss, correct = 0, 0\n",
        "\n",
        "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader),\n",
        "                        disable=not print_batch_stats)\n",
        "\n",
        "    for batch_idx, (X, y, _) in progress_bar:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        #print(X.shape)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        print(f\"Adjacency Matrix Gradient: {model.gnn.edge_weights.grad}\")\n",
        "        optimizer.step()  # update the model weights\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        #if print_batch_stats:\n",
        "        #    progress_bar.set_description(\n",
        "        #        f\"Epoch {epoch}/{n_epochs}, \"\n",
        "        #        f\"Batch {batch_idx + 1}/{len(dataloader)}, \"\n",
        "        #        f\"Loss: {loss.item():.6f}\"\n",
        "        #    )\n",
        "\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    correct /= len(dataloader.dataset)\n",
        "    return train_loss / len(dataloader), correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1S-1vTK2Zhk"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(dataloader: DataLoader, model: torch.nn.Module, loss_fn, print_batch_stats=True):\n",
        "    device = next(model.parameters()).device  # Get model device\n",
        "    size = len(dataloader.dataset)\n",
        "    n_batches = len(dataloader)\n",
        "    model.eval()  # Switch to evaluation mode\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Initialize dictionaries for per-class tracking\n",
        "    class_correct = defaultdict(int)\n",
        "    class_total = defaultdict(int)\n",
        "\n",
        "    # Lists to store true and predicted labels for confusion matrix\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    if print_batch_stats:\n",
        "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    else:\n",
        "        progress_bar = enumerate(dataloader)\n",
        "\n",
        "    for batch_idx, (X, y, _) in progress_bar:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        batch_loss = loss_fn(pred, y).item()\n",
        "\n",
        "        test_loss += batch_loss\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        # Store predictions and true labels for confusion matrix\n",
        "        all_preds.append(pred.argmax(1).cpu())\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "        # Compute per-class accuracy\n",
        "        preds_labels = pred.argmax(1)\n",
        "        for label, pred_label in zip(y, preds_labels):\n",
        "            class_total[label.item()] += 1\n",
        "            class_correct[label.item()] += (label == pred_label).item()\n",
        "\n",
        "        if print_batch_stats:\n",
        "            progress_bar.set_description(\n",
        "                f\"Batch {batch_idx + 1}/{len(dataloader)}, Loss: {batch_loss:.6f}\"\n",
        "            )\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "\n",
        "    # Compute per-class accuracy\n",
        "    class_accuracies = {\n",
        "        cls: (class_correct[cls] / class_total[cls]) * 100 if class_total[cls] > 0 else 0\n",
        "        for cls in class_total\n",
        "    }\n",
        "\n",
        "    # Compute overall accuracy\n",
        "    test_loss /= n_batches\n",
        "    overall_accuracy = (correct / size) * 100\n",
        "\n",
        "    # Print per-class accuracy\n",
        "    print(\"\\nClass-wise Accuracy:\")\n",
        "    for cls, acc in class_accuracies.items():\n",
        "        print(f\"  Class {cls}: {acc:.2f}%\")\n",
        "\n",
        "    print(f\"Test Accuracy: {overall_accuracy:.1f}%, Test Loss: {test_loss:.6f}\\n\")\n",
        "\n",
        "    return test_loss, overall_accuracy, class_accuracies, all_preds, all_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn58-cmZ2Zhl"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDUBctmi2Zhl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"Master Thesis\", name=f\"GIN {seed}\")\n",
        "\n",
        "# Define hyperparameters\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "batch_size = 64  # Start with 124\n",
        "n_epochs = 100\n",
        "patience = 30  # Patience for early stopping\n",
        "\n",
        "final_acc = 0.0\n",
        "\n",
        "# Log hyperparameters to wandb\n",
        "wandb.config.update({\n",
        "    \"learning_rate\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": n_epochs\n",
        "})\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs - 1)\n",
        "\n",
        "# Define loss function\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "# Initialize lists to store all predictions & targets\n",
        "all_preds, all_targets = [], []\n",
        "\n",
        "# Early Stopping setup\n",
        "best_val_acc = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{n_epochs}: \", end=\"\")\n",
        "\n",
        "    train_loss, train_accuracy = train_one_epoch(\n",
        "        train_loader, model, loss_fn, optimizer, scheduler, epoch, device\n",
        "    )\n",
        "\n",
        "    test_loss, test_accuracy, class_accuracies, batch_preds, batch_targets = test_model(test_loader, model, loss_fn)\n",
        "    final_acc = test_accuracy\n",
        "\n",
        "    # Store predictions & labels for confusion matrix\n",
        "    all_preds.extend(batch_preds)\n",
        "    all_targets.extend(batch_targets)\n",
        "\n",
        "    # Print class-wise accuracy\n",
        "    print(\"\\nClass-wise Accuracy:\")\n",
        "    for class_idx, acc in class_accuracies.items():\n",
        "        print(f\"  Class {class_idx}: {acc:.2f}%\")\n",
        "\n",
        "    adj_matrix = model.edge_weights.detach().cpu().numpy().reshape(22,22)\n",
        "\n",
        "    # Create a plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    cax = ax.matshow(adj_matrix, cmap='viridis', interpolation='nearest')  # Adjust color map\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Save the adjacency matrix as an image (not as a graph)\n",
        "    plt.tight_layout()\n",
        "    img_path = f\"adj_matrix_epoch_{epoch}.png\"\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Log results to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_accuracy * 100,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_accuracy\": test_accuracy,\n",
        "        \"learning_rate\": scheduler.get_last_lr()[0],\n",
        "        **{f\"class_{class_idx}_accuracy\": acc for class_idx, acc in class_accuracies.items()},\n",
        "        \"adj_matrix\": wandb.Image(img_path),\n",
        "    })\n",
        "\n",
        "    print(\n",
        "        f\"Train Accuracy: {100 * train_accuracy:.2f}%, \"\n",
        "        f\"Average Train Loss: {train_loss:.6f}, \"\n",
        "        f\"Test Accuracy: {test_accuracy:.2f}%, \"\n",
        "        f\"Average Test Loss: {test_loss:.6f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Early stopping check\n",
        "    if test_accuracy > best_val_acc:\n",
        "        best_val_acc = test_accuracy\n",
        "        epochs_without_improvement = 0  # Reset counter if we have improvement\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    # If no improvement for 'patience' epochs, stop training early\n",
        "    if epochs_without_improvement >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_targets = np.array(all_targets)\n",
        "\n",
        "# Save predictions & true labels for later use (confusion matrix)\n",
        "wandb.log({\"all_preds\": all_preds.tolist(), \"all_targets\": all_targets.tolist()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SWJejiBDSPP"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r25kGBA32Zhm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "print(seed)\n",
        "# Assuming 'model' is your trained Braindecode model\n",
        "torch.save(model, f\"GIN_{math.ceil(final_acc)}_{seed}.pth\")\n",
        "torch.save(model.state_dict(), f\"GIN_{math.ceil(final_acc)}_{seed}_state.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFUwHkQWPqUL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

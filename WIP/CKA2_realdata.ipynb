{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shallow_fbcsp import ShallowFBCSPNet\n",
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X):\n",
    "    \"\"\"Computes the linear kernel matrix for X.\"\"\"\n",
    "    return torch.matmul(X,X.T)  # Dot product\n",
    "\n",
    "def centering_matrix(K):\n",
    "    \"\"\"Centers the kernel matrix K.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    H = np.eye(n,dtype=K.dtype) - (1 / n) * np.ones((n, n), dtype=K.dtype)\n",
    "    return H # Equivalent to HKH\n",
    "\n",
    "def compute_hsic(X, Y, kernel_X = linear_kernel, kernel_Y = linear_kernel):\n",
    "    \"\"\"\n",
    "    Computes the Hilbert-Schmidt Independence Criterion (HSIC).\n",
    "    \n",
    "    Parameters:\n",
    "    - X: (n_samples, n_features_X) numpy array\n",
    "    - Y: (n_samples, n_features_Y) numpy array\n",
    "    - kernel_X: function to compute the kernel matrix for X\n",
    "    - kernel_Y: function to compute the kernel matrix for Y\n",
    "    \n",
    "    Returns:\n",
    "    - HSIC value (float)\n",
    "    \"\"\"\n",
    "    X = X.to(torch.float32)\n",
    "    Y = Y.to(torch.float32)\n",
    "    \n",
    "    K = kernel_X(X)\n",
    "    L = kernel_Y(Y)\n",
    "    \n",
    "    K = K.cpu().numpy()\n",
    "    L = L.cpu().numpy()\n",
    "    \n",
    "    H = centering_matrix(K)\n",
    "\n",
    "    Kxy_centered = K @ H @ L @ H\n",
    "    \n",
    "    hsic_value = np.trace(Kxy_centered) / ((X.shape[0] - 1) ** 2)\n",
    "    return hsic_value.item()\n",
    "  \n",
    "def compute_CKA(X,Y,kernel_X = linear_kernel,kernel_Y = linear_kernel):\n",
    "  \"\"\"\n",
    "  compute CKA between two X,Y activations\n",
    "  \n",
    "  Parameters:\n",
    "  - X: (n_samples, x_features)\n",
    "  - Y: (n_samples, y_features)\n",
    "  - kernel_X: kernel for X\n",
    "  - kernel_Y: kernel for Y  \n",
    "  \"\"\"\n",
    "  HSIC_KL = compute_hsic(X,Y,kernel_X,kernel_Y) \n",
    "  HSIC_KK = compute_hsic(X,X,kernel_X,kernel_X)\n",
    "  HSIC_LL = compute_hsic(Y,Y,kernel_Y, kernel_Y)\n",
    "  \n",
    "  return HSIC_KL/(np.sqrt(HSIC_KK * HSIC_LL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "in_chans = 22\n",
    "n_classes = 4\n",
    "n_channels = 22\n",
    "input_window_samples = 1000\n",
    "# Load two models for comparison\n",
    "model= torch.load(\"braindecode_model_temponly_1.pth\",weights_only = False,map_location=torch.device('cpu'))\n",
    "model2 =ShallowFBCSPNet(in_chans, n_classes, input_window_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 22, 1125]             [1, 4]                    --                        --\n",
      "├─SafeLog (pool_nonlin_exp): 1-1         [1, 22, 1125]             [1, 22, 1125]             --                        --\n",
      "├─Ensure4d (ensuredims): 1-2             [1, 22, 1125]             [1, 22, 1125, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-3            [1, 22, 1125, 1]          [1, 1, 1125, 22]          --                        --\n",
      "├─Conv2d (conv_time): 1-4                [1, 1, 1125, 22]          [1, 40, 1101, 22]         1,040                     [25, 1]\n",
      "├─Conv2d (conv_spat): 1-5                [1, 40, 1101, 22]         [1, 40, 1101, 1]          35,200                    [1, 22]\n",
      "├─BatchNorm2d (bnorm): 1-6               [1, 40, 1101, 1]          [1, 40, 1101, 1]          80                        --\n",
      "├─Expression (conv_nonlin_exp): 1-7      [1, 40, 1101, 1]          [1, 40, 1101, 1]          --                        --\n",
      "├─AvgPool2d (pool): 1-8                  [1, 40, 1101, 1]          [1, 40, 69, 1]            --                        [75, 1]\n",
      "├─SafeLog (pool_nonlin_exp): 1-9         [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Dropout (drop): 1-10                   [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-11         [1, 40, 69, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 69, 1]            [1, 4, 1, 1]              11,044                    [69, 1]\n",
      "│    └─Expression (squeeze): 2-2         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 47,364\n",
      "Trainable params: 47,364\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 63.96\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 8.46\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 8.74\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_activations(model, input_tensor):\n",
    "    activations = OrderedDict()\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks\n",
    "    for name, layer in model.named_modules():\n",
    "        if(name == \"conv_time\" or name == \"conv_spat\"):\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "\n",
    "    # Run forward pass AFTER registering hooks\n",
    "    model.eval()\n",
    "   \n",
    "    _ = model(input_tensor)  \n",
    "\n",
    "    return activations  # Return collected activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def extract_model_activations(model, input_tensor, output_dir, batch_size=128):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    activations = OrderedDict()\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks for specific layers\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == \"conv_time\" or name == \"conv_spat\":  # Modify as per your layer names\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, input_tensor.shape[0], batch_size):\n",
    "            batch = input_tensor[i:i + batch_size]  # Select current batch\n",
    "            _ = model(batch)  # Forward pass through the model\n",
    "\n",
    "            # Save activations after each batch\n",
    "            for name, activation in activations.items():\n",
    "                batch_idx = i // batch_size + 1  # This determines the batch number\n",
    "                print(f\"saving: {name}_batch_{batch_idx}.pt\")\n",
    "                torch.save(activation, os.path.join(output_dir, f\"{name}_batch_{batch_idx}.pt\"))\n",
    "            \n",
    "            # Clear activations list after saving\n",
    "            activations.clear()\n",
    "            torch.cuda.empty_cache()  # Optional: Clear GPU memory after each batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Datasets/test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2592, 22, 1125])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X = torch.stack([torch.from_numpy(test_set[i][0]) for i in range(len(test_set))])\n",
    "\n",
    "\n",
    "print(X.shape)  # Verify the tensor shape\n",
    "print(type(X))  # Should output <class 'torch.Tensor'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(model.conv_time.weight.device)  # Check the device of the conv_time layer\n",
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "save_every_n_batches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: conv_time_batch_1.pt\n",
      "saving: conv_spat_batch_1.pt\n",
      "saving: conv_time_batch_2.pt\n",
      "saving: conv_spat_batch_2.pt\n",
      "saving: conv_time_batch_3.pt\n",
      "saving: conv_spat_batch_3.pt\n",
      "saving: conv_time_batch_4.pt\n",
      "saving: conv_spat_batch_4.pt\n",
      "saving: conv_time_batch_5.pt\n",
      "saving: conv_spat_batch_5.pt\n",
      "saving: conv_time_batch_6.pt\n",
      "saving: conv_spat_batch_6.pt\n",
      "saving: conv_time_batch_7.pt\n",
      "saving: conv_spat_batch_7.pt\n",
      "saving: conv_time_batch_8.pt\n",
      "saving: conv_spat_batch_8.pt\n",
      "saving: conv_time_batch_9.pt\n",
      "saving: conv_spat_batch_9.pt\n",
      "saving: conv_time_batch_10.pt\n",
      "saving: conv_spat_batch_10.pt\n",
      "saving: conv_time_batch_11.pt\n",
      "saving: conv_spat_batch_11.pt\n",
      "saving: conv_time_batch_12.pt\n",
      "saving: conv_spat_batch_12.pt\n",
      "saving: conv_time_batch_13.pt\n",
      "saving: conv_spat_batch_13.pt\n",
      "saving: conv_time_batch_14.pt\n",
      "saving: conv_spat_batch_14.pt\n",
      "saving: conv_time_batch_15.pt\n",
      "saving: conv_spat_batch_15.pt\n",
      "saving: conv_time_batch_16.pt\n",
      "saving: conv_spat_batch_16.pt\n",
      "saving: conv_time_batch_17.pt\n",
      "saving: conv_spat_batch_17.pt\n",
      "saving: conv_time_batch_18.pt\n",
      "saving: conv_spat_batch_18.pt\n",
      "saving: conv_time_batch_19.pt\n",
      "saving: conv_spat_batch_19.pt\n",
      "saving: conv_time_batch_20.pt\n",
      "saving: conv_spat_batch_20.pt\n",
      "saving: conv_time_batch_21.pt\n",
      "saving: conv_spat_batch_21.pt\n",
      "saving: conv_time_batch_22.pt\n",
      "saving: conv_spat_batch_22.pt\n",
      "saving: conv_time_batch_23.pt\n",
      "saving: conv_spat_batch_23.pt\n",
      "saving: conv_time_batch_24.pt\n",
      "saving: conv_spat_batch_24.pt\n",
      "saving: conv_time_batch_25.pt\n",
      "saving: conv_spat_batch_25.pt\n",
      "saving: conv_time_batch_26.pt\n",
      "saving: conv_spat_batch_26.pt\n",
      "saving: conv_time_batch_27.pt\n",
      "saving: conv_spat_batch_27.pt\n",
      "saving: conv_time_batch_28.pt\n",
      "saving: conv_spat_batch_28.pt\n",
      "saving: conv_time_batch_29.pt\n",
      "saving: conv_spat_batch_29.pt\n",
      "saving: conv_time_batch_30.pt\n",
      "saving: conv_spat_batch_30.pt\n",
      "saving: conv_time_batch_31.pt\n",
      "saving: conv_spat_batch_31.pt\n",
      "saving: conv_time_batch_32.pt\n",
      "saving: conv_spat_batch_32.pt\n",
      "saving: conv_time_batch_33.pt\n",
      "saving: conv_spat_batch_33.pt\n",
      "saving: conv_time_batch_34.pt\n",
      "saving: conv_spat_batch_34.pt\n",
      "saving: conv_time_batch_35.pt\n",
      "saving: conv_spat_batch_35.pt\n",
      "saving: conv_time_batch_36.pt\n",
      "saving: conv_spat_batch_36.pt\n",
      "saving: conv_time_batch_37.pt\n",
      "saving: conv_spat_batch_37.pt\n",
      "saving: conv_time_batch_38.pt\n",
      "saving: conv_spat_batch_38.pt\n",
      "saving: conv_time_batch_39.pt\n",
      "saving: conv_spat_batch_39.pt\n",
      "saving: conv_time_batch_40.pt\n",
      "saving: conv_spat_batch_40.pt\n",
      "saving: conv_time_batch_41.pt\n",
      "saving: conv_spat_batch_41.pt\n"
     ]
    }
   ],
   "source": [
    "extract_model_activations(model,X,output_dir=\"Datasets/activations/model1/\",batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: conv_time_batch_1.pt\n",
      "saving: conv_spat_batch_1.pt\n",
      "saving: conv_time_batch_2.pt\n",
      "saving: conv_spat_batch_2.pt\n",
      "saving: conv_time_batch_3.pt\n",
      "saving: conv_spat_batch_3.pt\n",
      "saving: conv_time_batch_4.pt\n",
      "saving: conv_spat_batch_4.pt\n",
      "saving: conv_time_batch_5.pt\n",
      "saving: conv_spat_batch_5.pt\n",
      "saving: conv_time_batch_6.pt\n",
      "saving: conv_spat_batch_6.pt\n",
      "saving: conv_time_batch_7.pt\n",
      "saving: conv_spat_batch_7.pt\n",
      "saving: conv_time_batch_8.pt\n",
      "saving: conv_spat_batch_8.pt\n",
      "saving: conv_time_batch_9.pt\n",
      "saving: conv_spat_batch_9.pt\n",
      "saving: conv_time_batch_10.pt\n",
      "saving: conv_spat_batch_10.pt\n",
      "saving: conv_time_batch_11.pt\n",
      "saving: conv_spat_batch_11.pt\n",
      "saving: conv_time_batch_12.pt\n",
      "saving: conv_spat_batch_12.pt\n",
      "saving: conv_time_batch_13.pt\n",
      "saving: conv_spat_batch_13.pt\n",
      "saving: conv_time_batch_14.pt\n",
      "saving: conv_spat_batch_14.pt\n",
      "saving: conv_time_batch_15.pt\n",
      "saving: conv_spat_batch_15.pt\n",
      "saving: conv_time_batch_16.pt\n",
      "saving: conv_spat_batch_16.pt\n",
      "saving: conv_time_batch_17.pt\n",
      "saving: conv_spat_batch_17.pt\n",
      "saving: conv_time_batch_18.pt\n",
      "saving: conv_spat_batch_18.pt\n",
      "saving: conv_time_batch_19.pt\n",
      "saving: conv_spat_batch_19.pt\n",
      "saving: conv_time_batch_20.pt\n",
      "saving: conv_spat_batch_20.pt\n",
      "saving: conv_time_batch_21.pt\n",
      "saving: conv_spat_batch_21.pt\n",
      "saving: conv_time_batch_22.pt\n",
      "saving: conv_spat_batch_22.pt\n",
      "saving: conv_time_batch_23.pt\n",
      "saving: conv_spat_batch_23.pt\n",
      "saving: conv_time_batch_24.pt\n",
      "saving: conv_spat_batch_24.pt\n",
      "saving: conv_time_batch_25.pt\n",
      "saving: conv_spat_batch_25.pt\n",
      "saving: conv_time_batch_26.pt\n",
      "saving: conv_spat_batch_26.pt\n",
      "saving: conv_time_batch_27.pt\n",
      "saving: conv_spat_batch_27.pt\n",
      "saving: conv_time_batch_28.pt\n",
      "saving: conv_spat_batch_28.pt\n",
      "saving: conv_time_batch_29.pt\n",
      "saving: conv_spat_batch_29.pt\n",
      "saving: conv_time_batch_30.pt\n",
      "saving: conv_spat_batch_30.pt\n",
      "saving: conv_time_batch_31.pt\n",
      "saving: conv_spat_batch_31.pt\n",
      "saving: conv_time_batch_32.pt\n",
      "saving: conv_spat_batch_32.pt\n",
      "saving: conv_time_batch_33.pt\n",
      "saving: conv_spat_batch_33.pt\n",
      "saving: conv_time_batch_34.pt\n",
      "saving: conv_spat_batch_34.pt\n",
      "saving: conv_time_batch_35.pt\n",
      "saving: conv_spat_batch_35.pt\n",
      "saving: conv_time_batch_36.pt\n",
      "saving: conv_spat_batch_36.pt\n",
      "saving: conv_time_batch_37.pt\n",
      "saving: conv_spat_batch_37.pt\n",
      "saving: conv_time_batch_38.pt\n",
      "saving: conv_spat_batch_38.pt\n",
      "saving: conv_time_batch_39.pt\n",
      "saving: conv_spat_batch_39.pt\n",
      "saving: conv_time_batch_40.pt\n",
      "saving: conv_spat_batch_40.pt\n",
      "saving: conv_time_batch_41.pt\n",
      "saving: conv_spat_batch_41.pt\n"
     ]
    }
   ],
   "source": [
    "extract_model_activations(model2,X,output_dir=\"Datasets/activations/model2/\",batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 40, 1101, 22])\n"
     ]
    }
   ],
   "source": [
    "len = torch.load(f\"Datasets/activations/model1/conv_time_batch_{3}.pt\")\n",
    "print(len.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv_time', 'conv_spat']\n",
      "['conv_time', 'conv_spat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Use OrderedDict to preserve the order of layer names\n",
    "layer_names_model1 = ['conv_time', 'conv_spat']\n",
    "layer_names_model2 = layer_names_model1\n",
    "\n",
    "\n",
    "print(layer_names_model1)\n",
    "print(layer_names_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "batch_nr = X.shape[0] /batch_size\n",
    "\n",
    "batch_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer conv_time (batch 1)\n",
      "cka score: 0.9981855898709294\n",
      "cka score: 0.9946553066113416\n",
      "Processing layer conv_spat (batch 1)\n",
      "cka score: 0.9729664115123107\n",
      "cka score: 0.9702039629189194\n",
      "Processing layer conv_time (batch 2)\n",
      "cka score: 0.9981085299251141\n",
      "cka score: 0.9946001746610357\n",
      "Processing layer conv_spat (batch 2)\n",
      "cka score: 0.9730804609726298\n",
      "cka score: 0.9712006789976095\n",
      "Processing layer conv_time (batch 3)\n",
      "cka score: 0.9979505645343671\n",
      "cka score: 0.9952355499042429\n",
      "Processing layer conv_spat (batch 3)\n",
      "cka score: 0.9748745379927689\n",
      "cka score: 0.973738462854181\n",
      "Processing layer conv_time (batch 4)\n",
      "cka score: 0.9979191137858031\n",
      "cka score: 0.9943232442062301\n",
      "Processing layer conv_spat (batch 4)\n",
      "cka score: 0.9751846802944475\n",
      "cka score: 0.9726522147892205\n",
      "Processing layer conv_time (batch 5)\n",
      "cka score: 0.9971241933303283\n",
      "cka score: 0.9941771775729712\n",
      "Processing layer conv_spat (batch 5)\n",
      "cka score: 0.977711197094353\n",
      "cka score: 0.9785039565885231\n",
      "Processing layer conv_time (batch 6)\n",
      "cka score: 0.996904352818224\n",
      "cka score: 0.9919181541127906\n",
      "Processing layer conv_spat (batch 6)\n",
      "cka score: 0.9761733019592641\n",
      "cka score: 0.976300783115298\n",
      "Processing layer conv_time (batch 7)\n",
      "cka score: 0.9977121362914205\n",
      "cka score: 0.9925049396989583\n",
      "Processing layer conv_spat (batch 7)\n",
      "cka score: 0.9754402537786555\n",
      "cka score: 0.97581463258869\n",
      "Processing layer conv_time (batch 8)\n",
      "cka score: 0.9976849971425585\n",
      "cka score: 0.9928282870303288\n",
      "Processing layer conv_spat (batch 8)\n",
      "cka score: 0.9742687626681289\n",
      "cka score: 0.9753259305902424\n",
      "Processing layer conv_time (batch 9)\n",
      "cka score: 0.9974403019692624\n",
      "cka score: 0.9929697834423002\n",
      "Processing layer conv_spat (batch 9)\n",
      "cka score: 0.9757875603669984\n",
      "cka score: 0.976270044184284\n",
      "Processing layer conv_time (batch 10)\n",
      "cka score: 0.9955786071407617\n",
      "cka score: 0.9945107922527361\n",
      "Processing layer conv_spat (batch 10)\n",
      "cka score: 0.980037795432567\n",
      "cka score: 0.9799058762297049\n",
      "Processing layer conv_time (batch 11)\n",
      "cka score: 0.9954455364509415\n",
      "cka score: 0.994697289566273\n",
      "Processing layer conv_spat (batch 11)\n",
      "cka score: 0.9839467166292674\n",
      "cka score: 0.983798227133824\n",
      "Processing layer conv_time (batch 12)\n",
      "cka score: 0.9964108209162993\n",
      "cka score: 0.9949385294713696\n",
      "Processing layer conv_spat (batch 12)\n",
      "cka score: 0.9807898503042276\n",
      "cka score: 0.9802312734483536\n",
      "Processing layer conv_time (batch 13)\n",
      "cka score: 0.9954932384087791\n",
      "cka score: 0.9943428129588828\n",
      "Processing layer conv_spat (batch 13)\n",
      "cka score: 0.9826586375940483\n",
      "cka score: 0.9830797547071726\n",
      "Processing layer conv_time (batch 14)\n",
      "cka score: 0.9966187301476115\n",
      "cka score: 0.9947221876562894\n",
      "Processing layer conv_spat (batch 14)\n",
      "cka score: 0.9821126726052467\n",
      "cka score: 0.9817908160418092\n",
      "Processing layer conv_time (batch 15)\n",
      "cka score: 0.9981598638516469\n",
      "cka score: 0.9944758630732299\n",
      "Processing layer conv_spat (batch 15)\n",
      "cka score: 0.9790705057376449\n",
      "cka score: 0.9766938473249398\n",
      "Processing layer conv_time (batch 16)\n",
      "cka score: 0.9979055349686435\n",
      "cka score: 0.994424348196092\n",
      "Processing layer conv_spat (batch 16)\n",
      "cka score: 0.978595592945937\n",
      "cka score: 0.9762357924414302\n",
      "Processing layer conv_time (batch 17)\n",
      "cka score: 0.9981795377523237\n",
      "cka score: 0.9942766399822194\n",
      "Processing layer conv_spat (batch 17)\n",
      "cka score: 0.9780623156732012\n",
      "cka score: 0.9753867098140931\n",
      "Processing layer conv_time (batch 18)\n",
      "cka score: 0.9980533109586688\n",
      "cka score: 0.9943052477480364\n",
      "Processing layer conv_spat (batch 18)\n",
      "cka score: 0.9776099261650671\n",
      "cka score: 0.9753500285713766\n",
      "Processing layer conv_time (batch 19)\n",
      "cka score: 0.9982989972647488\n",
      "cka score: 0.9933846722728599\n",
      "Processing layer conv_spat (batch 19)\n",
      "cka score: 0.9746910614901487\n",
      "cka score: 0.9669221475068037\n",
      "Processing layer conv_time (batch 20)\n",
      "cka score: 0.9984843552687325\n",
      "cka score: 0.9944682115891237\n",
      "Processing layer conv_spat (batch 20)\n",
      "cka score: 0.9748083123297074\n",
      "cka score: 0.968514192183405\n",
      "Processing layer conv_time (batch 21)\n",
      "cka score: 0.998247532121656\n",
      "cka score: 0.9938833491746619\n",
      "Processing layer conv_spat (batch 21)\n",
      "cka score: 0.9760334073700044\n",
      "cka score: 0.9695209779133691\n",
      "Processing layer conv_time (batch 22)\n",
      "cka score: 0.997861948360119\n",
      "cka score: 0.9942496727832133\n",
      "Processing layer conv_spat (batch 22)\n",
      "cka score: 0.978485891292457\n",
      "cka score: 0.971859103304427\n",
      "Processing layer conv_time (batch 23)\n",
      "cka score: 0.9982331768118974\n",
      "cka score: 0.9937291147465988\n",
      "Processing layer conv_spat (batch 23)\n",
      "cka score: 0.9639498886007896\n",
      "cka score: 0.9573285615913609\n",
      "Processing layer conv_time (batch 24)\n",
      "cka score: 0.9984648756497063\n",
      "cka score: 0.9939436001107458\n",
      "Processing layer conv_spat (batch 24)\n",
      "cka score: 0.9666048900137498\n",
      "cka score: 0.9608370539005069\n",
      "Processing layer conv_time (batch 25)\n",
      "cka score: 0.9978793464522592\n",
      "cka score: 0.9943750706500215\n",
      "Processing layer conv_spat (batch 25)\n",
      "cka score: 0.9753981709904433\n",
      "cka score: 0.9715710090941083\n",
      "Processing layer conv_time (batch 26)\n",
      "cka score: 0.9981106899391736\n",
      "cka score: 0.9948067662739853\n",
      "Processing layer conv_spat (batch 26)\n",
      "cka score: 0.9727149765240549\n",
      "cka score: 0.9680847087578903\n",
      "Processing layer conv_time (batch 27)\n",
      "cka score: 0.9982572995067222\n",
      "cka score: 0.994123826500865\n",
      "Processing layer conv_spat (batch 27)\n",
      "cka score: 0.9669042401885454\n",
      "cka score: 0.9617061980335604\n",
      "Processing layer conv_time (batch 28)\n",
      "cka score: 0.9984035202348654\n",
      "cka score: 0.9946077479489555\n",
      "Processing layer conv_spat (batch 28)\n",
      "cka score: 0.9755880789246874\n",
      "cka score: 0.9723019662027488\n",
      "Processing layer conv_time (batch 29)\n",
      "cka score: 0.9983187018641875\n",
      "cka score: 0.9941831902171776\n",
      "Processing layer conv_spat (batch 29)\n",
      "cka score: 0.9750334683615344\n",
      "cka score: 0.9714751621788008\n",
      "Processing layer conv_time (batch 30)\n",
      "cka score: 0.9982747280864614\n",
      "cka score: 0.9942634130589433\n",
      "Processing layer conv_spat (batch 30)\n",
      "cka score: 0.9737372012371375\n",
      "cka score: 0.9701283380208812\n",
      "Processing layer conv_time (batch 31)\n",
      "cka score: 0.9981547994809258\n",
      "cka score: 0.9941796117362016\n",
      "Processing layer conv_spat (batch 31)\n",
      "cka score: 0.9758951435228844\n",
      "cka score: 0.972375658401032\n",
      "Processing layer conv_time (batch 32)\n",
      "cka score: 0.9979121515434578\n",
      "cka score: 0.9935006258709534\n",
      "Processing layer conv_spat (batch 32)\n",
      "cka score: 0.9708688336159297\n",
      "cka score: 0.9707519947616788\n",
      "Processing layer conv_time (batch 33)\n",
      "cka score: 0.9968279769841769\n",
      "cka score: 0.9934969304122954\n",
      "Processing layer conv_spat (batch 33)\n",
      "cka score: 0.9761962178193123\n",
      "cka score: 0.9796162401588406\n",
      "Processing layer conv_time (batch 34)\n",
      "cka score: 0.9977202878090754\n",
      "cka score: 0.9930863433203673\n",
      "Processing layer conv_spat (batch 34)\n",
      "cka score: 0.9720976030512827\n",
      "cka score: 0.9759630863910467\n",
      "Processing layer conv_time (batch 35)\n",
      "cka score: 0.9980152391619282\n",
      "cka score: 0.9932058690583226\n",
      "Processing layer conv_spat (batch 35)\n",
      "cka score: 0.9665024034532614\n",
      "cka score: 0.9705528834898399\n",
      "Processing layer conv_time (batch 36)\n",
      "cka score: 0.9978481452401176\n",
      "cka score: 0.9937276218031537\n",
      "Processing layer conv_spat (batch 36)\n",
      "cka score: 0.9696917739827654\n",
      "cka score: 0.9737735567031977\n",
      "Processing layer conv_time (batch 37)\n",
      "cka score: 0.9980445207450818\n",
      "cka score: 0.9922426282493076\n",
      "Processing layer conv_spat (batch 37)\n",
      "cka score: 0.958004890334929\n",
      "cka score: 0.9574910786417943\n",
      "Processing layer conv_time (batch 38)\n",
      "cka score: 0.9979933249837597\n",
      "cka score: 0.992296598777517\n",
      "Processing layer conv_spat (batch 38)\n",
      "cka score: 0.9575854555041259\n",
      "cka score: 0.957442444257677\n",
      "Processing layer conv_time (batch 39)\n",
      "cka score: 0.9983256701295359\n",
      "cka score: 0.9926905895430357\n",
      "Processing layer conv_spat (batch 39)\n",
      "cka score: 0.9558276021118342\n",
      "cka score: 0.9554614818972783\n",
      "Processing layer conv_time (batch 40)\n",
      "cka score: 0.998211414823186\n",
      "cka score: 0.9932818370720136\n",
      "Processing layer conv_spat (batch 40)\n",
      "cka score: 0.9586097428138849\n",
      "cka score: 0.9598273876786815\n"
     ]
    }
   ],
   "source": [
    "cka_accumulated_scores = { (layer1, layer2): 0 for layer1 in layer_names_model1 for layer2 in layer_names_model2 }\n",
    "model_1_activations = OrderedDict()\n",
    "model_2_activations = OrderedDict()\n",
    "acum = 0\n",
    "l1 = (\"conv_time\",\"conv_time\")\n",
    "sum = 0.0\n",
    "# Compute CKA for each layer from all activations\n",
    "for batch_idx in range(1,math.ceil(batch_nr)):\n",
    "    # Get activations for the current batch\n",
    "    model_1_activations[layer_names_model1[0]] = torch.load(f\"Datasets/activations/model1/{layer_names_model1[0]}_batch_{batch_idx}.pt\")\n",
    "    model_1_activations[layer_names_model1[1]] = torch.load(f\"Datasets/activations/model1/{layer_names_model1[1]}_batch_{batch_idx}.pt\")\n",
    "    model_2_activations[layer_names_model1[0]] = torch.load(f\"Datasets/activations/model2/{layer_names_model1[0]}_batch_{batch_idx}.pt\")\n",
    "    model_2_activations[layer_names_model1[1]] = torch.load(f\"Datasets/activations/model2/{layer_names_model1[1]}_batch_{batch_idx}.pt\")\n",
    "    for layer1 in layer_names_model1:\n",
    "        print(f\"Processing layer {layer1} (batch {batch_idx})\")\n",
    "        for layer2 in layer_names_model2:\n",
    "            # Reshape activations to 2D for CKA computation\n",
    "            activations_x = model_1_activations[layer1].reshape(model_1_activations[layer1].shape[0], -1)\n",
    "            activations_y = model_2_activations[layer2].reshape(model_2_activations[layer2].shape[0], -1)\n",
    "\n",
    "            # Compute CKA score for the current layer pair\n",
    "            cka_score = compute_CKA(activations_x, activations_y)\n",
    "            print(\"cka score:\", cka_score)\n",
    "            if(layer1,layer2) == l1:\n",
    "                sum += cka_score\n",
    "            # Accumulate the CKA score for the current layer pair\n",
    "            cka_accumulated_scores[(layer1, layer2)] += cka_score\n",
    "            if (layer1,layer2) == l1:\n",
    "                acum +=1\n",
    "# Average the CKA scores across all batches\n",
    "for layer_pair in cka_accumulated_scores:\n",
    "    cka_accumulated_scores[layer_pair] = cka_accumulated_scores[layer_pair]/acum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40, 1101, 22])\n",
      "128\n",
      "torch.Size([128, 40, 1101, 22])\n",
      "128\n",
      "torch.Size([32, 40, 1101, 22])\n",
      "128\n",
      "288\n",
      "torch.Size([128, 40, 1101, 22])\n",
      "128\n",
      "torch.Size([128, 40, 1101, 22])\n",
      "128\n",
      "torch.Size([32, 40, 1101, 22])\n",
      "128\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "model_1_kernels = OrderedDict()\n",
    "model_2_kernels = OrderedDict()\n",
    "\n",
    "# Compute CKA for each layer from all activations\n",
    "for layer in layer_names_model1:\n",
    "    activations_list = []\n",
    "    for batch_idx in range(1,math.ceil(batch_nr)):\n",
    "    # Get activations for the current batch\n",
    "        batch_activations = torch.load(f\"Datasets/activations/model1/{layer_names_model1[0]}_batch_{batch_idx}.pt\")\n",
    "        print(batch_activations.shape)\n",
    "        activations_list.append(batch_activations)\n",
    "        print(len(activations_list[0]))\n",
    "    \n",
    "    # Concatenate the activations across all batches along the 0th dimension (samples)\n",
    "    model_1_kernels[layer] = torch.cat(activations_list, dim=0)\n",
    "    print(len(model_1_kernels[layer]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize a square matrix for the CKA similarities\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m n_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer_names_model1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# + len(layer_names_model2)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_layers, n_layers))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fill the matrix with the average CKA similarity values\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "# Initialize a square matrix for the CKA similarities\n",
    "n_layers = len(layer_names_model1)# + len(layer_names_model2)\n",
    "matrix = np.zeros((n_layers, n_layers))\n",
    "\n",
    "# Fill the matrix with the average CKA similarity values\n",
    "for (layer1, layer2), similarity in cka_accumulated_scores.items():\n",
    "    i = layer_names_model1.index(layer1) if layer1 in layer_names_model1 else len(layer_names_model1) + layer_names_model2.index(layer1)\n",
    "    j = layer_names_model2.index(layer2) if layer2 in layer_names_model2 else len(layer_names_model2) + layer_names_model1.index(layer2)\n",
    "    \n",
    "    matrix[i, j] = similarity\n",
    "    matrix[j, i] = similarity  # Symmetric matrix\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(matrix, index=layer_names_model1, columns=layer_names_model1)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df, annot=True, cmap='magma', fmt='.2f', square=True, linewidths=0.5, cbar=True, vmin=0, vmax=1)\n",
    "plt.title('Average CKA Similarity Heatmap')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Layer')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
